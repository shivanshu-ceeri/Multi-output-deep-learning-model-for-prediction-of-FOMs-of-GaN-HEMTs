{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, LSTM\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import hstack\n",
    "from numpy.random import rand\n",
    "from numpy.random import randn\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"DB_modified.csv\"\n",
    "dataset = pd.read_csv(filename, header=None)\n",
    "dataset =np.array(dataset)[1:-1]\n",
    "\n",
    "dataset=np.asfarray(dataset,float)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset[:,:7]\n",
    "# print(\"BeforeSTD:\", X)\n",
    "# X=(X-np.mean(X))/np.std(X)\n",
    "# X=dataset[:,2]\n",
    "X[:,1]=(X[:,1]-np.mean(X[:,1]))/np.std(X[:,1])\n",
    "X[:,2]=(X[:,2]-np.mean(X[:,2]))/np.std(X[:,2])\n",
    "X[:,3]=(X[:,3]-np.mean(X[:,3]))/np.std(X[:,3])\n",
    "# X[:,1]=X[:,1]/np.max(X[:,1])\n",
    "# y=dataset[:,6]\n",
    "# Vthin=dataset[:,-2]\n",
    "# np.concatenate((X, np.expand_dims(Vthin, 1)), 1)\n",
    "# print(X)\n",
    "# print(y.shape)\n",
    "# X=np.expand_dims(X, 1)\n",
    "# print(\"AfterSTD:\",X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(n_inputs=7):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer='he_uniform', input_dim=n_inputs))\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(latent_dim, n_outputs=7):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer='he_uniform', input_dim=latent_dim))\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(n_outputs, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(generator, discriminator):\n",
    "    # make weights in the discriminator not trainable\n",
    "    discriminator.trainable = False\n",
    "    # connect them\n",
    "    model = Sequential()\n",
    "    # add generator\n",
    "    model.add(generator)\n",
    "    # add the discriminator\n",
    "    model.add(discriminator)\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(n):\n",
    "    X_return = X[np.random.randint(0, X.shape[0], size=n)]\n",
    "    y = ones((n, 1))\n",
    "    return X_return, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, n):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    x_input = x_input.reshape(n, latent_dim)\n",
    "    return x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(generator, latent_dim, n):\n",
    "    # generate points in latent space\n",
    "    x_input = generate_latent_points(latent_dim, n)\n",
    "    # predict outputs\n",
    "    X = generator.predict(x_input)\n",
    "    # create class labels\n",
    "    y = zeros((n, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(epoch, generator, discriminator, latent_dim, n=100):\n",
    "    # prepare real samples\n",
    "    x_real, y_real = generate_real_samples(n)\n",
    "    # evaluate discriminator on real examples\n",
    "    _, acc_real = discriminator.evaluate(x_real, y_real, verbose=0)\n",
    "    # prepare fake examples\n",
    "    x_fake, y_fake = generate_fake_samples(generator, latent_dim, n)\n",
    "    # evaluate discriminator on fake examples\n",
    "    _, acc_fake = discriminator.evaluate(x_fake, y_fake, verbose=0)\n",
    "    # summarize discriminator performance\n",
    "    print(epoch, acc_real, acc_fake)\n",
    "    # scatter plot real and fake data points\n",
    "    pyplot.scatter(x_real[:, 3], x_real[:, 6], color='red')\n",
    "    pyplot.scatter(x_fake[:, 3], x_fake[:,6], color='blue')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, latent_dim, n_epochs=4000, n_batch=64, n_eval=50):\n",
    "    # determine half the size of one batch, for updating the discriminator\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_epochs):\n",
    "        # prepare real samples\n",
    "        x_real, y_real = generate_real_samples(half_batch)\n",
    "       \n",
    "        # prepare fake examples\n",
    "        x_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "        # update discriminator\n",
    "        d_model.train_on_batch(x_real, y_real)\n",
    "        d_model.train_on_batch(x_fake, y_fake)\n",
    "        # prepare points in latent space as input for the generator\n",
    "        x_gan = generate_latent_points(latent_dim, n_batch)\n",
    "        \n",
    "        # create inverted labels for the fake samples\n",
    "        y_gan = ones((n_batch, 1))\n",
    "#         print(x_gan.shape, y_gan.shape)\n",
    "        # update the generator via the discriminator's error\n",
    "        gan_model.train_on_batch(x_gan, y_gan)\n",
    "        # evaluate the model every n_eval epochs\n",
    "        if (i+1) % n_eval == 0:\n",
    "            summarize_performance(i, g_model, d_model, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 10\n",
    "# create the discriminator\n",
    "discriminator = define_discriminator()\n",
    "# create the generator\n",
    "generator = define_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = define_gan(generator, discriminator)\n",
    "# train model\n",
    "train(generator, discriminator, gan_model, latent_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

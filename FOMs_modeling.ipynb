{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Dropout, MaxPooling1D, Flatten, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "from keras.regularizers import l2\n",
    "import keras\n",
    "from keras.layers import LSTM, Dense,Input, Conv2D, Flatten, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2158, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename=\"DB_modified.csv\"\n",
    "dataset = pd.read_csv(filename)\n",
    "dataset\n",
    "# Q1 = dataset.quantile(0.25)\n",
    "# Q3 = dataset.quantile(0.75)\n",
    "# IQR = Q3 - Q1\n",
    "# # print(IQR)\n",
    "# # print(dataset.shape)\n",
    "# dataset = dataset[~((dataset < (Q1 - 1.5 * IQR)) |(dataset > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "# print(dataset.shape)\n",
    "dataset =np.array(dataset)[1:-1]\n",
    "dataset=np.asfarray(dataset,float)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0e+00 2.0e+16 1.5e-02 1.7e-01]\n",
      " [0.0e+00 2.0e+16 1.5e-02 1.9e-01]\n",
      " [0.0e+00 2.0e+16 1.5e-02 2.1e-01]\n",
      " ...\n",
      " [1.0e+00 1.0e+19 2.9e-02 2.5e-01]\n",
      " [1.0e+00 1.0e+19 2.9e-02 2.7e-01]\n",
      " [1.0e+00 1.0e+19 2.9e-02 2.9e-01]]\n",
      "(2158, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 38.9934 ,  82.224  ,  -0.716  ],\n",
       "        [ 58.829  ,  90.156  ,  -0.977  ],\n",
       "        [ 82.97375,  97.828  ,  -1.239  ],\n",
       "        ...,\n",
       "        [404.002  , 101.472  ,  -5.41   ],\n",
       "        [444.592  , 106.572  ,  -5.935  ],\n",
       "        [483.73   , 111.408  ,  -6.464  ]]),\n",
       " array([[-1.        , -0.69961252, -1.5284699 , -1.16264952],\n",
       "        [-1.        , -0.69961252, -1.5284699 , -0.77509968],\n",
       "        [-1.        , -0.69961252, -1.5284699 , -0.38754984],\n",
       "        ...,\n",
       "        [ 1.        ,  2.47781879,  1.5284699 ,  0.38754984],\n",
       "        [ 1.        ,  2.47781879,  1.5284699 ,  0.77509968],\n",
       "        [ 1.        ,  2.47781879,  1.5284699 ,  1.16264952]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=dataset[:,:4]\n",
    "print(X)\n",
    "# X=(X-np.mean(X))/np.std(X)\n",
    "\n",
    "# X=dataset[:,2]\n",
    "X[:,0]=(X[:,0]-np.mean(X[:,0]))/np.std(X[:,0])\n",
    "X[:,1]=(X[:,1]-np.mean(X[:,1]))/np.std(X[:,1])\n",
    "X[:,2]=(X[:,2]-np.mean(X[:,2]))/np.std(X[:,2])\n",
    "X[:,3]=(X[:,3]-np.mean(X[:,3]))/np.std(X[:,3])\n",
    "\n",
    "# X[:,1]=X[:,1]/np.max(X[:,1])\n",
    "y=dataset[:,4:7]\n",
    "# Vthin=dataset[:,-2]\n",
    "# np.concatenate((X, np.expand_dims(Vthin, 1)), 1)\n",
    "# print(X)\n",
    "print(y.shape)\n",
    "# X=np.expand_dims(X, 1)\n",
    "y,X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.6972414   1.4884295   0.51256835  0.5147029 ]\n",
      " [-1.0893219   1.1557536  -0.9450898   1.4321591 ]\n",
      " [ 0.9408671  -0.574       0.32613173  0.571942  ]\n",
      " ...\n",
      " [ 0.86686724 -0.25266343  0.79319525  1.412123  ]\n",
      " [-0.9377408  -0.06915441 -1.0210751  -1.4790384 ]\n",
      " [-0.735737    1.30408     0.27639705 -1.70117   ]]\n",
      "[[-0.85502875  1.10179663  0.58732684  0.50957876]\n",
      " [-1.29633887  0.79686945 -0.91004294  1.46655927]\n",
      " [ 0.98876059 -0.78860423  0.39581105  0.56928374]\n",
      " ...\n",
      " [ 0.90546931 -0.49407056  0.87559899  1.44566001]\n",
      " [-1.12572525 -0.32586815 -0.98809834 -1.57005355]\n",
      " [-0.89835786  0.93282385  0.34472142 -1.80175465]]\n"
     ]
    }
   ],
   "source": [
    "dfgan = pd.read_csv(\"fromGANwo-ve.csv\")\n",
    "# Q1 = dfgan.quantile(0.25)\n",
    "# Q3 = dfgan.quantile(0.75)\n",
    "# IQR = Q3 - Q1\n",
    "# print(IQR)\n",
    "# print(dfgan.shape)\n",
    "# dfgan = dfgan[~((dfgan < (Q1 - 1.5 * IQR)) |(dfgan > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "# print(dfgan.shape)\n",
    "dfgan =np.array(dfgan)\n",
    "\n",
    "dfgan=np.asfarray(dfgan,float)\n",
    "xGAN=dfgan[:,0:4]\n",
    "print(xGAN)\n",
    "xGAN[:,0]=(xGAN[:,0]-np.mean(xGAN[:,0]))/np.std(xGAN[:,0])\n",
    "xGAN[:,1]=(xGAN[:,1]-np.mean(xGAN[:,1]))/np.std(xGAN[:,1])\n",
    "xGAN[:,2]=(xGAN[:,2]-np.mean(xGAN[:,2]))/np.std(xGAN[:,2])\n",
    "xGAN[:,3]=(xGAN[:,3]-np.mean(xGAN[:,3]))/np.std(xGAN[:,3])\n",
    "yGAN=dfgan[:,4:7]\n",
    "print(xGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.         -0.69961252 -1.5284699  -1.16264952]\n",
      " [-1.         -0.69961252 -1.5284699  -0.77509968]\n",
      " [-1.         -0.69961252 -1.5284699  -0.38754984]\n",
      " ...\n",
      " [ 0.90546931 -0.49407056  0.87559899  1.44566001]\n",
      " [-1.12572525 -0.32586815 -0.98809834 -1.57005355]\n",
      " [-0.89835786  0.93282385  0.34472142 -1.80175465]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3111, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtotal=np.vstack((X, xGAN))\n",
    "ytotal=np.vstack((y, yGAN))\n",
    "print(xtotal)\n",
    "ytotal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2644, 4)\n",
      "(2247, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(xtotal, ytotal, test_size=0.15, random_state=42, shuffle=True)\n",
    "print(x_train.shape)\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(x_train, y_train, test_size=0.15, random_state=42, shuffle=True)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2247, 4)\n",
      "(2247, 3)\n",
      "(467, 4)\n",
      "(467, 3)\n",
      "(397, 4)\n",
      "(397, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_cv.shape)\n",
    "print(y_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #SVR\n",
    "# from sklearn.svm import SVR\n",
    "# regressor = SVR(kernel='poly', degree=20)\n",
    "# regressor.fit(x_train,y_train)\n",
    "# for i in range(50):\n",
    "#     y_pred = regressor.predict([x_test[i]])\n",
    "#     print(y_pred-y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.03335528  1.77847337 -0.30606683 -1.10101673]]\n",
      "\n",
      " [[ 0.86371599 -0.36184192 -0.95099599 -0.29728895]]\n",
      "\n",
      " [[-1.         -0.69961252 -1.5284699  -0.77509968]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.         -0.06922033 -0.65505853 -1.55019935]]\n",
      "\n",
      " [[-1.         -0.4512762   0.65505853  1.55019935]]\n",
      "\n",
      " [[ 1.         -0.67414212 -0.65505853  0.77509968]]]\n",
      "(2247, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "x_traindim =np.expand_dims(x_train, 1)\n",
    "y_traindim =np.expand_dims(y_train, 1)\n",
    "x_cvdim =np.expand_dims(x_cv, 1)\n",
    "y_cvdim =np.expand_dims(y_cv, 1)\n",
    "x_testdim =np.expand_dims(x_test, 1)\n",
    "y_testdim =np.expand_dims(y_test, 1)\n",
    "print(x_traindim)\n",
    "print(x_traindim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 1, 32)             4736      \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 1, 64)             24832     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 71,107\n",
      "Trainable params: 71,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1500\n",
      "139/141 [============================>.] - ETA: 0s - loss: 25950.9450 - MSE: 25950.9450"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-5e1879fae298>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m                     \u001b[0mfilepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"E:\\\\Simulations\\\\Silvaco\\\\\\\\2D HEMT\\\\EDL\\\\DATA for modeling\\\\modelLSTMvar_2D64_D3\\\\latestmodel.hdf5\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m                     \u001b[0mcheckpointer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m                     \u001b[0mhistory3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_traindim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_cvdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_cv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m                     \u001b[0mminloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                     \u001b[0mmodelfilepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"E:\\\\Simulations\\\\Silvaco\\\\\\\\2D HEMT\\\\EDL\\\\DATA for modeling\\\\modelLSTMvar_2D64_D3\\\\\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shivanshu mishra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1187\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1189\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1190\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shivanshu mishra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1462\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1463\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1464\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1465\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1466\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shivanshu mishra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shivanshu mishra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mc:\\users\\shivanshu mishra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shivanshu mishra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\shivanshu mishra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shivanshu mishra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for m in range(3):\n",
    "    for k in range(3):\n",
    "        for i in range(3):\n",
    "                c1=32*2**m\n",
    "                c2=32*2**k\n",
    "                c3=32*2**i\n",
    "#                 cnt=cnt+1\n",
    "                if(not((c1==32 and c2==32 and c3==32)or (c1==32 and c2==32 and c3==64)or(c1==32 and c2==64 and c3==32)or(c1==64 and c2==32 and c3==32)or (c1==32 and c2==32 and c3==128))):\n",
    "                    filename='L'+str(c1)+'L'+str(c2)+'L'+str(c3)\n",
    "                    \n",
    "                    modelfilepath=\"E:\\\\Simulations\\\\Silvaco\\\\\\\\2D HEMT\\\\EDL\\\\DATA for modeling\\\\modelLSTMvar_2D64_D3\\\\\"+filename\n",
    "                    \n",
    "                    model = Sequential()\n",
    "                    model.add(LSTM(c1, return_sequences=True, input_shape=(x_traindim[1].shape)))\n",
    "                    model.add(LSTM(c2, return_sequences=True))\n",
    "                    model.add(LSTM(c3, return_sequences=False))\n",
    "                    # model.add(LSTM(16, return_sequences=True))\n",
    "                    # model.add(LSTM(16, return_sequences=True))\n",
    "                    # model.add(LSTM(16, return_sequences=True))\n",
    "                    # model.add(LSTM(32, return_sequences=True))\n",
    "                    # model.add(LSTM(16))\n",
    "\n",
    "                    model.add(Dense(64, activation='relu'))\n",
    "                    model.add(Dense(64, activation='relu'))\n",
    "\n",
    "                    # model.add(Dense(64, activation='relu'))\n",
    "                    # # # model.add(BatchNormalization())\n",
    "                    # model.add(Dense(128, activation='relu'))\n",
    "                    # model.add(Dense(64, activation='relu'))\n",
    "                    # model.add(Dense(64, activation='relu'))\n",
    "                    # model.add(Dense(64, activation='relu'))\n",
    "                    # model.add(BatchNormalization())\n",
    "                    # model.add(Dense(64, activation='relu'))\n",
    "                    # model.add(Dense(128, activation='relu'))\n",
    "                    # model.add(Dense(512, activation='relu'))\n",
    "                    # model.add(Dense(128, activation='relu'))\n",
    "                    # model.add(Dense(64, activation='relu'))\n",
    "                    # model.add(Dense(128, activation='relu'))\n",
    "                    # model.add(Dense(64, activation='relu'))\n",
    "                    # model.add(Dense(64, activation='relu'))\n",
    "                    # model.add(Dropout(0.5))\n",
    "                    # model.add(Dense(64, activation='relu'))\n",
    "                    # model.add(Dense(64, activation='relu'))\n",
    "                    model.add(Dense(3, activation='linear'))\n",
    "#                     opt=keras.optimizers.adam(0.001)\n",
    "                    model.compile(loss='mean_squared_error', optimizer=\"adam\", metrics=['MSE'])\n",
    "                    model.summary()\n",
    "                    filepath=\"E:\\\\Simulations\\\\Silvaco\\\\\\\\2D HEMT\\\\EDL\\\\DATA for modeling\\\\modelLSTMvar_2D64_D3\\\\latestmodel.hdf5\"\n",
    "                    checkpointer = ModelCheckpoint( monitor='val_loss',filepath=filepath, verbose=1, save_best_only=True)\n",
    "                    history3=model.fit(x_traindim,y_train, validation_data=(x_cvdim, y_cv), epochs=1500, batch_size=16, callbacks=[checkpointer])\n",
    "                    minloss=round(min(history3.history['val_loss']), 1) \n",
    "                    modelfilepath=\"E:\\\\Simulations\\\\Silvaco\\\\\\\\2D HEMT\\\\EDL\\\\DATA for modeling\\\\modelLSTMvar_2D64_D3\\\\\"+filename+'_'+str(minloss)\n",
    "                    df=pd.DataFrame(history3.history)\n",
    "                    model.save(modelfilepath+'.h5')\n",
    "                    df.to_csv(modelfilepath+'.csv')\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 8,739\n",
      "Trainable params: 8,739\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model used for only actualdatabut now being testd for GAN too\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=(x_train[1].shape)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(3, activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['MSE'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "141/141 [==============================] - 4s 12ms/step - loss: 22664.3659 - MSE: 22664.3659 - val_loss: 1613.9600 - val_MSE: 1613.9600\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1613.95996, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 2/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1580.9779 - MSE: 1580.9779 - val_loss: 1180.8993 - val_MSE: 1180.8993\n",
      "\n",
      "Epoch 00002: val_loss improved from 1613.95996 to 1180.89929, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 3/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1066.4182 - MSE: 1066.4182 - val_loss: 1013.6926 - val_MSE: 1013.6926\n",
      "\n",
      "Epoch 00003: val_loss improved from 1180.89929 to 1013.69263, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 4/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 1086.4560 - MSE: 1086.4560 - val_loss: 899.8589 - val_MSE: 899.8589\n",
      "\n",
      "Epoch 00004: val_loss improved from 1013.69263 to 899.85895, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 5/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 859.0912 - MSE: 859.0912 - val_loss: 693.6315 - val_MSE: 693.6315\n",
      "\n",
      "Epoch 00005: val_loss improved from 899.85895 to 693.63153, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 6/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 672.2832 - MSE: 672.2832 - val_loss: 468.4207 - val_MSE: 468.4207\n",
      "\n",
      "Epoch 00006: val_loss improved from 693.63153 to 468.42075, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 7/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 557.8716 - MSE: 557.8716 - val_loss: 440.7289 - val_MSE: 440.7289\n",
      "\n",
      "Epoch 00007: val_loss improved from 468.42075 to 440.72894, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 8/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 487.9633 - MSE: 487.9633 - val_loss: 443.7765 - val_MSE: 443.7765\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 440.72894\n",
      "Epoch 9/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 598.2976 - MSE: 598.2976 - val_loss: 419.9820 - val_MSE: 419.9820\n",
      "\n",
      "Epoch 00009: val_loss improved from 440.72894 to 419.98203, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 10/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 442.8787 - MSE: 442.8787 - val_loss: 415.8254 - val_MSE: 415.8254\n",
      "\n",
      "Epoch 00010: val_loss improved from 419.98203 to 415.82538, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 11/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 491.2398 - MSE: 491.2398 - val_loss: 422.1259 - val_MSE: 422.1259\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 415.82538\n",
      "Epoch 12/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 378.8763 - MSE: 378.8763 - val_loss: 445.5946 - val_MSE: 445.5946\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 415.82538\n",
      "Epoch 13/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 424.1554 - MSE: 424.1554 - val_loss: 402.6937 - val_MSE: 402.6937\n",
      "\n",
      "Epoch 00013: val_loss improved from 415.82538 to 402.69366, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 14/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 487.2592 - MSE: 487.2592 - val_loss: 469.1033 - val_MSE: 469.1033\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 402.69366\n",
      "Epoch 15/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 484.9372 - MSE: 484.9372 - val_loss: 426.3032 - val_MSE: 426.3032\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 402.69366\n",
      "Epoch 16/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 461.0257 - MSE: 461.0257 - val_loss: 380.3709 - val_MSE: 380.3709\n",
      "\n",
      "Epoch 00016: val_loss improved from 402.69366 to 380.37091, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 17/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 401.6713 - MSE: 401.6713 - val_loss: 444.2552 - val_MSE: 444.2552\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 380.37091\n",
      "Epoch 18/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 439.3036 - MSE: 439.3036 - val_loss: 378.1895 - val_MSE: 378.1895\n",
      "\n",
      "Epoch 00018: val_loss improved from 380.37091 to 378.18951, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 19/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 484.1452 - MSE: 484.1452 - val_loss: 387.8748 - val_MSE: 387.8748\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 378.18951\n",
      "Epoch 20/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 391.7059 - MSE: 391.7059 - val_loss: 384.9974 - val_MSE: 384.9974\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 378.18951\n",
      "Epoch 21/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 383.4207 - MSE: 383.4207 - val_loss: 374.6734 - val_MSE: 374.6734\n",
      "\n",
      "Epoch 00021: val_loss improved from 378.18951 to 374.67340, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 22/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 384.1067 - MSE: 384.1067 - val_loss: 384.1411 - val_MSE: 384.1411\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 374.67340\n",
      "Epoch 23/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 449.7974 - MSE: 449.7974 - val_loss: 366.3892 - val_MSE: 366.3892\n",
      "\n",
      "Epoch 00023: val_loss improved from 374.67340 to 366.38922, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 24/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 413.2847 - MSE: 413.2847 - val_loss: 363.9603 - val_MSE: 363.9603\n",
      "\n",
      "Epoch 00024: val_loss improved from 366.38922 to 363.96030, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 25/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 345.7347 - MSE: 345.7347 - val_loss: 371.9765 - val_MSE: 371.9765\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 363.96030\n",
      "Epoch 26/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 389.4911 - MSE: 389.4911 - val_loss: 354.1434 - val_MSE: 354.1434\n",
      "\n",
      "Epoch 00026: val_loss improved from 363.96030 to 354.14343, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 27/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 386.9841 - MSE: 386.9841 - val_loss: 362.7262 - val_MSE: 362.7262\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 354.14343\n",
      "Epoch 28/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 371.3171 - MSE: 371.3171 - val_loss: 382.7035 - val_MSE: 382.7035\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 354.14343\n",
      "Epoch 29/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 405.4275 - MSE: 405.4275 - val_loss: 381.9697 - val_MSE: 381.9697\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 354.14343\n",
      "Epoch 30/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 444.1106 - MSE: 444.1106 - val_loss: 371.8873 - val_MSE: 371.8873\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 354.14343\n",
      "Epoch 31/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 367.4276 - MSE: 367.4276 - val_loss: 362.2806 - val_MSE: 362.2806\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 354.14343\n",
      "Epoch 32/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 336.9013 - MSE: 336.9013 - val_loss: 350.6582 - val_MSE: 350.6582\n",
      "\n",
      "Epoch 00032: val_loss improved from 354.14343 to 350.65817, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 33/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 371.6897 - MSE: 371.6897 - val_loss: 346.2288 - val_MSE: 346.2288\n",
      "\n",
      "Epoch 00033: val_loss improved from 350.65817 to 346.22879, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 349.7796 - MSE: 349.7796 - val_loss: 349.4695 - val_MSE: 349.4695\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 346.22879\n",
      "Epoch 35/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 399.8688 - MSE: 399.8688 - val_loss: 401.5255 - val_MSE: 401.5255\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 346.22879\n",
      "Epoch 36/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 356.8862 - MSE: 356.8862 - val_loss: 421.1308 - val_MSE: 421.1308\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 346.22879\n",
      "Epoch 37/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 374.5532 - MSE: 374.5532 - val_loss: 436.9595 - val_MSE: 436.9595\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 346.22879\n",
      "Epoch 38/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 424.6053 - MSE: 424.6053 - val_loss: 352.9364 - val_MSE: 352.9364\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 346.22879\n",
      "Epoch 39/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 350.9312 - MSE: 350.9312 - val_loss: 350.1908 - val_MSE: 350.1908\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 346.22879\n",
      "Epoch 40/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 374.2292 - MSE: 374.2292 - val_loss: 349.1299 - val_MSE: 349.1299\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 346.22879\n",
      "Epoch 41/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 333.5190 - MSE: 333.5190 - val_loss: 374.6684 - val_MSE: 374.6684\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 346.22879\n",
      "Epoch 42/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 385.7933 - MSE: 385.7933 - val_loss: 384.5922 - val_MSE: 384.5922\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 346.22879\n",
      "Epoch 43/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 358.7080 - MSE: 358.7080 - val_loss: 384.2282 - val_MSE: 384.2282\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 346.22879\n",
      "Epoch 44/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 334.6955 - MSE: 334.6955 - val_loss: 394.4067 - val_MSE: 394.4067\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 346.22879\n",
      "Epoch 45/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 315.9322 - MSE: 315.9322 - val_loss: 376.4289 - val_MSE: 376.4289\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 346.22879\n",
      "Epoch 46/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 299.4721 - MSE: 299.4721 - val_loss: 380.9807 - val_MSE: 380.9807\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 346.22879\n",
      "Epoch 47/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 335.4319 - MSE: 335.4319 - val_loss: 345.6581 - val_MSE: 345.6581\n",
      "\n",
      "Epoch 00047: val_loss improved from 346.22879 to 345.65814, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 48/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 360.2825 - MSE: 360.2825 - val_loss: 335.7361 - val_MSE: 335.7361\n",
      "\n",
      "Epoch 00048: val_loss improved from 345.65814 to 335.73611, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 49/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 376.8067 - MSE: 376.8067 - val_loss: 340.6425 - val_MSE: 340.6425\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 335.73611\n",
      "Epoch 50/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 344.8423 - MSE: 344.8423 - val_loss: 340.8336 - val_MSE: 340.8336\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 335.73611\n",
      "Epoch 51/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 340.5203 - MSE: 340.5203 - val_loss: 351.9610 - val_MSE: 351.9610\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 335.73611\n",
      "Epoch 52/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 374.9781 - MSE: 374.9781 - val_loss: 341.0395 - val_MSE: 341.0395\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 335.73611\n",
      "Epoch 53/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 369.9063 - MSE: 369.9063 - val_loss: 333.6115 - val_MSE: 333.6115\n",
      "\n",
      "Epoch 00053: val_loss improved from 335.73611 to 333.61145, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 54/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 305.3386 - MSE: 305.3386 - val_loss: 332.6482 - val_MSE: 332.6482\n",
      "\n",
      "Epoch 00054: val_loss improved from 333.61145 to 332.64819, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 55/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 336.2627 - MSE: 336.2627 - val_loss: 343.6870 - val_MSE: 343.6870\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 332.64819\n",
      "Epoch 56/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 317.7802 - MSE: 317.7802 - val_loss: 371.7964 - val_MSE: 371.7964\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 332.64819\n",
      "Epoch 57/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 322.1302 - MSE: 322.1302 - val_loss: 343.7925 - val_MSE: 343.7925\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 332.64819\n",
      "Epoch 58/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 327.5825 - MSE: 327.5825 - val_loss: 330.3832 - val_MSE: 330.3832\n",
      "\n",
      "Epoch 00058: val_loss improved from 332.64819 to 330.38318, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 59/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 372.7223 - MSE: 372.7223 - val_loss: 409.4642 - val_MSE: 409.4642\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 330.38318\n",
      "Epoch 60/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 317.5789 - MSE: 317.5789 - val_loss: 318.3366 - val_MSE: 318.3366\n",
      "\n",
      "Epoch 00060: val_loss improved from 330.38318 to 318.33658, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 61/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 334.8016 - MSE: 334.8016 - val_loss: 367.4807 - val_MSE: 367.4807\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 318.33658\n",
      "Epoch 62/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 321.7188 - MSE: 321.7188 - val_loss: 326.2048 - val_MSE: 326.2048\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 318.33658\n",
      "Epoch 63/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 249.9158 - MSE: 249.9158 - val_loss: 329.4845 - val_MSE: 329.4845\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 318.33658\n",
      "Epoch 64/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 283.6893 - MSE: 283.6893 - val_loss: 339.9262 - val_MSE: 339.9262\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 318.33658\n",
      "Epoch 65/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 339.8735 - MSE: 339.8735 - val_loss: 358.5139 - val_MSE: 358.5139\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 318.33658\n",
      "Epoch 66/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 283.9367 - MSE: 283.9367 - val_loss: 318.8127 - val_MSE: 318.8127\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 318.33658\n",
      "Epoch 67/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 300.9320 - MSE: 300.9320 - val_loss: 332.9153 - val_MSE: 332.9153\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 318.33658\n",
      "Epoch 68/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 280.7473 - MSE: 280.7473 - val_loss: 314.7842 - val_MSE: 314.7842\n",
      "\n",
      "Epoch 00068: val_loss improved from 318.33658 to 314.78421, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 69/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 289.9609 - MSE: 289.9609 - val_loss: 374.8403 - val_MSE: 374.8403\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 314.78421\n",
      "Epoch 70/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 337.2568 - MSE: 337.2568 - val_loss: 369.6369 - val_MSE: 369.6369\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 314.78421\n",
      "Epoch 71/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 301.5460 - MSE: 301.5460 - val_loss: 331.5361 - val_MSE: 331.5361\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 314.78421\n",
      "Epoch 72/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 8ms/step - loss: 319.0614 - MSE: 319.0614 - val_loss: 362.1568 - val_MSE: 362.1568\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 314.78421\n",
      "Epoch 73/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 282.1558 - MSE: 282.1558 - val_loss: 347.0042 - val_MSE: 347.0042\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 314.78421\n",
      "Epoch 74/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 295.3218 - MSE: 295.3218 - val_loss: 405.0544 - val_MSE: 405.0544\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 314.78421\n",
      "Epoch 75/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 296.2674 - MSE: 296.2674 - val_loss: 357.6578 - val_MSE: 357.6578\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 314.78421\n",
      "Epoch 76/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 271.0011 - MSE: 271.0011 - val_loss: 322.3716 - val_MSE: 322.3716\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 314.78421\n",
      "Epoch 77/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 282.6863 - MSE: 282.6863 - val_loss: 324.9820 - val_MSE: 324.9820\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 314.78421\n",
      "Epoch 78/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 269.2565 - MSE: 269.2565 - val_loss: 337.0429 - val_MSE: 337.0429\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 314.78421\n",
      "Epoch 79/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 262.9854 - MSE: 262.9854 - val_loss: 317.5422 - val_MSE: 317.5422\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 314.78421\n",
      "Epoch 80/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 268.4496 - MSE: 268.4496 - val_loss: 516.1873 - val_MSE: 516.1873\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 314.78421\n",
      "Epoch 81/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 321.9820 - MSE: 321.9820 - val_loss: 305.4528 - val_MSE: 305.4528\n",
      "\n",
      "Epoch 00081: val_loss improved from 314.78421 to 305.45276, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 82/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 281.9415 - MSE: 281.9415 - val_loss: 309.7095 - val_MSE: 309.7095\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 305.45276\n",
      "Epoch 83/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 291.1366 - MSE: 291.1366 - val_loss: 305.2390 - val_MSE: 305.2390\n",
      "\n",
      "Epoch 00083: val_loss improved from 305.45276 to 305.23895, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 84/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 278.0602 - MSE: 278.0602 - val_loss: 323.6866 - val_MSE: 323.6866\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 305.23895\n",
      "Epoch 85/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 310.5318 - MSE: 310.5318 - val_loss: 296.5712 - val_MSE: 296.5712\n",
      "\n",
      "Epoch 00085: val_loss improved from 305.23895 to 296.57117, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 86/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 281.1207 - MSE: 281.1207 - val_loss: 301.2384 - val_MSE: 301.2384\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 296.57117\n",
      "Epoch 87/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 234.6505 - MSE: 234.6505 - val_loss: 340.3806 - val_MSE: 340.3806\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 296.57117\n",
      "Epoch 88/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 256.2299 - MSE: 256.2299 - val_loss: 329.9828 - val_MSE: 329.9828\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 296.57117\n",
      "Epoch 89/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 276.2204 - MSE: 276.2204 - val_loss: 293.3186 - val_MSE: 293.3186\n",
      "\n",
      "Epoch 00089: val_loss improved from 296.57117 to 293.31860, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 90/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 271.6925 - MSE: 271.6925 - val_loss: 310.8585 - val_MSE: 310.8585\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 293.31860\n",
      "Epoch 91/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 278.8847 - MSE: 278.8847 - val_loss: 342.8762 - val_MSE: 342.8762\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 293.31860\n",
      "Epoch 92/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 278.3884 - MSE: 278.3884 - val_loss: 315.5743 - val_MSE: 315.5743\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 293.31860\n",
      "Epoch 93/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 291.4525 - MSE: 291.4525 - val_loss: 317.7982 - val_MSE: 317.7982\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 293.31860\n",
      "Epoch 94/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 306.1209 - MSE: 306.1209 - val_loss: 336.4068 - val_MSE: 336.4068\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 293.31860\n",
      "Epoch 95/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 229.9470 - MSE: 229.9470 - val_loss: 306.6320 - val_MSE: 306.6320\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 293.31860\n",
      "Epoch 96/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 252.2571 - MSE: 252.2571 - val_loss: 384.3926 - val_MSE: 384.3926\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 293.31860\n",
      "Epoch 97/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 224.5719 - MSE: 224.5719 - val_loss: 337.1333 - val_MSE: 337.1333\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 293.31860\n",
      "Epoch 98/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 259.3527 - MSE: 259.3527 - val_loss: 308.3453 - val_MSE: 308.3453\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 293.31860\n",
      "Epoch 99/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 240.3253 - MSE: 240.3253 - val_loss: 302.0292 - val_MSE: 302.0292\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 293.31860\n",
      "Epoch 100/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 255.3063 - MSE: 255.3063 - val_loss: 392.3217 - val_MSE: 392.3217\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 293.31860\n",
      "Epoch 101/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 266.9309 - MSE: 266.9309 - val_loss: 290.4320 - val_MSE: 290.4320\n",
      "\n",
      "Epoch 00101: val_loss improved from 293.31860 to 290.43204, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 102/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 257.1445 - MSE: 257.1445 - val_loss: 283.5323 - val_MSE: 283.5323\n",
      "\n",
      "Epoch 00102: val_loss improved from 290.43204 to 283.53229, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 103/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 241.3381 - MSE: 241.3381 - val_loss: 401.3151 - val_MSE: 401.3151\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 283.53229\n",
      "Epoch 104/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 261.9500 - MSE: 261.9500 - val_loss: 279.7776 - val_MSE: 279.7776\n",
      "\n",
      "Epoch 00104: val_loss improved from 283.53229 to 279.77762, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 105/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 240.7738 - MSE: 240.7738 - val_loss: 377.0785 - val_MSE: 377.0785\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 279.77762\n",
      "Epoch 106/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 253.1486 - MSE: 253.1486 - val_loss: 311.7746 - val_MSE: 311.7746\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 279.77762\n",
      "Epoch 107/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 212.6077 - MSE: 212.6077 - val_loss: 264.1992 - val_MSE: 264.1992\n",
      "\n",
      "Epoch 00107: val_loss improved from 279.77762 to 264.19922, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 108/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 297.1686 - MSE: 297.1686 - val_loss: 267.9201 - val_MSE: 267.9201\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 264.19922\n",
      "Epoch 109/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 234.4593 - MSE: 234.4593 - val_loss: 269.7905 - val_MSE: 269.7905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00109: val_loss did not improve from 264.19922\n",
      "Epoch 110/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 243.4889 - MSE: 243.4889 - val_loss: 266.5740 - val_MSE: 266.5740\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 264.19922\n",
      "Epoch 111/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 238.5181 - MSE: 238.5181 - val_loss: 319.9163 - val_MSE: 319.9163\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 264.19922\n",
      "Epoch 112/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 324.3174 - MSE: 324.3174 - val_loss: 316.0370 - val_MSE: 316.0370\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 264.19922\n",
      "Epoch 113/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 191.5289 - MSE: 191.5289 - val_loss: 306.6042 - val_MSE: 306.6042\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 264.19922\n",
      "Epoch 114/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 226.3404 - MSE: 226.3404 - val_loss: 316.1476 - val_MSE: 316.1476\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 264.19922\n",
      "Epoch 115/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 251.9011 - MSE: 251.9011 - val_loss: 256.6279 - val_MSE: 256.6279\n",
      "\n",
      "Epoch 00115: val_loss improved from 264.19922 to 256.62787, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 116/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 192.5585 - MSE: 192.5585 - val_loss: 257.8009 - val_MSE: 257.8009\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 256.62787\n",
      "Epoch 117/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 257.1372 - MSE: 257.1372 - val_loss: 280.6271 - val_MSE: 280.6271\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 256.62787\n",
      "Epoch 118/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 244.5941 - MSE: 244.5941 - val_loss: 286.4388 - val_MSE: 286.4388\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 256.62787\n",
      "Epoch 119/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 231.4249 - MSE: 231.4249 - val_loss: 253.3398 - val_MSE: 253.3398\n",
      "\n",
      "Epoch 00119: val_loss improved from 256.62787 to 253.33983, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 120/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 229.7612 - MSE: 229.7612 - val_loss: 260.0973 - val_MSE: 260.0973\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 253.33983\n",
      "Epoch 121/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 214.0781 - MSE: 214.0781 - val_loss: 249.1747 - val_MSE: 249.1747\n",
      "\n",
      "Epoch 00121: val_loss improved from 253.33983 to 249.17473, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 122/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 258.3246 - MSE: 258.3246 - val_loss: 268.0252 - val_MSE: 268.0252\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 249.17473\n",
      "Epoch 123/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 198.8025 - MSE: 198.8025 - val_loss: 287.1043 - val_MSE: 287.1043\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 249.17473\n",
      "Epoch 124/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 251.8020 - MSE: 251.8020 - val_loss: 259.7950 - val_MSE: 259.7950\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 249.17473\n",
      "Epoch 125/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 235.9593 - MSE: 235.9593 - val_loss: 252.2810 - val_MSE: 252.2810\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 249.17473\n",
      "Epoch 126/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 210.4631 - MSE: 210.4631 - val_loss: 389.9004 - val_MSE: 389.9004\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 249.17473\n",
      "Epoch 127/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 235.3046 - MSE: 235.3046 - val_loss: 254.5070 - val_MSE: 254.5070\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 249.17473\n",
      "Epoch 128/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 190.6817 - MSE: 190.6817 - val_loss: 336.3322 - val_MSE: 336.3322\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 249.17473\n",
      "Epoch 129/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 245.8659 - MSE: 245.8659 - val_loss: 298.9856 - val_MSE: 298.9856\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 249.17473\n",
      "Epoch 130/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 280.0259 - MSE: 280.0259 - val_loss: 310.3774 - val_MSE: 310.3774\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 249.17473\n",
      "Epoch 131/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 241.7258 - MSE: 241.7258 - val_loss: 287.0548 - val_MSE: 287.0548\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 249.17473\n",
      "Epoch 132/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 209.0819 - MSE: 209.0819 - val_loss: 261.1286 - val_MSE: 261.1286\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 249.17473\n",
      "Epoch 133/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 205.8234 - MSE: 205.8234 - val_loss: 291.0096 - val_MSE: 291.0096\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 249.17473\n",
      "Epoch 134/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 221.7250 - MSE: 221.7250 - val_loss: 281.4428 - val_MSE: 281.4428\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 249.17473\n",
      "Epoch 135/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 211.9809 - MSE: 211.9809 - val_loss: 294.4116 - val_MSE: 294.4116\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 249.17473\n",
      "Epoch 136/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 192.8696 - MSE: 192.8696 - val_loss: 317.2959 - val_MSE: 317.2959\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 249.17473\n",
      "Epoch 137/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 180.0014 - MSE: 180.0014 - val_loss: 233.0530 - val_MSE: 233.0530\n",
      "\n",
      "Epoch 00137: val_loss improved from 249.17473 to 233.05296, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 138/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 192.8766 - MSE: 192.8766 - val_loss: 234.9294 - val_MSE: 234.9294\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 233.05296\n",
      "Epoch 139/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 224.5926 - MSE: 224.5926 - val_loss: 230.1003 - val_MSE: 230.1003\n",
      "\n",
      "Epoch 00139: val_loss improved from 233.05296 to 230.10030, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 140/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 209.3174 - MSE: 209.3174 - val_loss: 258.8091 - val_MSE: 258.8091\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 230.10030\n",
      "Epoch 141/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 199.2603 - MSE: 199.2603 - val_loss: 287.5035 - val_MSE: 287.5035\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 230.10030\n",
      "Epoch 142/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 232.5336 - MSE: 232.5336 - val_loss: 239.4925 - val_MSE: 239.4925\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 230.10030\n",
      "Epoch 143/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 187.3407 - MSE: 187.3407 - val_loss: 229.1606 - val_MSE: 229.1606\n",
      "\n",
      "Epoch 00143: val_loss improved from 230.10030 to 229.16060, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 144/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 222.9290 - MSE: 222.9290 - val_loss: 286.2604 - val_MSE: 286.2604\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 229.16060\n",
      "Epoch 145/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 202.4516 - MSE: 202.4516 - val_loss: 222.6322 - val_MSE: 222.6322\n",
      "\n",
      "Epoch 00145: val_loss improved from 229.16060 to 222.63222, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 146/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 219.5459 - MSE: 219.5459 - val_loss: 278.0126 - val_MSE: 278.0126\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 222.63222\n",
      "Epoch 147/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 234.5975 - MSE: 234.5975 - val_loss: 268.6172 - val_MSE: 268.6172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00147: val_loss did not improve from 222.63222\n",
      "Epoch 148/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 224.3207 - MSE: 224.3207 - val_loss: 261.4983 - val_MSE: 261.4983\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 222.63222\n",
      "Epoch 149/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 184.3626 - MSE: 184.3626 - val_loss: 241.5697 - val_MSE: 241.5697\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 222.63222\n",
      "Epoch 150/1500\n",
      "141/141 [==============================] - ETA: 0s - loss: 250.7401 - MSE: 250.740 - 1s 8ms/step - loss: 250.3727 - MSE: 250.3727 - val_loss: 280.6692 - val_MSE: 280.6692\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 222.63222\n",
      "Epoch 151/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 194.7611 - MSE: 194.7611 - val_loss: 240.8976 - val_MSE: 240.8976\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 222.63222\n",
      "Epoch 152/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 170.1446 - MSE: 170.1446 - val_loss: 227.1636 - val_MSE: 227.1636\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 222.63222\n",
      "Epoch 153/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 207.2138 - MSE: 207.2138 - val_loss: 253.6713 - val_MSE: 253.6713\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 222.63222\n",
      "Epoch 154/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 190.7905 - MSE: 190.7905 - val_loss: 216.3139 - val_MSE: 216.3139\n",
      "\n",
      "Epoch 00154: val_loss improved from 222.63222 to 216.31395, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 155/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 206.8442 - MSE: 206.8442 - val_loss: 247.4621 - val_MSE: 247.4621\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 216.31395\n",
      "Epoch 156/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 194.4607 - MSE: 194.4607 - val_loss: 268.1818 - val_MSE: 268.1818\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 216.31395\n",
      "Epoch 157/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 197.9902 - MSE: 197.9902 - val_loss: 246.7124 - val_MSE: 246.7124\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 216.31395\n",
      "Epoch 158/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 158.7878 - MSE: 158.7878 - val_loss: 245.0992 - val_MSE: 245.0992\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 216.31395\n",
      "Epoch 159/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 216.9249 - MSE: 216.9249 - val_loss: 228.9219 - val_MSE: 228.9219\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 216.31395\n",
      "Epoch 160/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 180.4495 - MSE: 180.4495 - val_loss: 269.8607 - val_MSE: 269.8607\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 216.31395\n",
      "Epoch 161/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 225.0514 - MSE: 225.0514 - val_loss: 377.2959 - val_MSE: 377.2959\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 216.31395\n",
      "Epoch 162/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 172.5364 - MSE: 172.5364 - val_loss: 284.9956 - val_MSE: 284.9956\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 216.31395\n",
      "Epoch 163/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 217.6539 - MSE: 217.6539 - val_loss: 249.2360 - val_MSE: 249.2360\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 216.31395\n",
      "Epoch 164/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 160.5108 - MSE: 160.5108 - val_loss: 222.3200 - val_MSE: 222.3200\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 216.31395\n",
      "Epoch 165/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 222.9271 - MSE: 222.9271 - val_loss: 274.5712 - val_MSE: 274.5712\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 216.31395\n",
      "Epoch 166/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 218.6363 - MSE: 218.6363 - val_loss: 201.9999 - val_MSE: 201.9999\n",
      "\n",
      "Epoch 00166: val_loss improved from 216.31395 to 201.99994, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 167/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 173.4932 - MSE: 173.4932 - val_loss: 255.0104 - val_MSE: 255.0104\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 201.99994\n",
      "Epoch 168/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 189.3349 - MSE: 189.3349 - val_loss: 231.2565 - val_MSE: 231.2565\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 201.99994\n",
      "Epoch 169/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 201.0707 - MSE: 201.0707 - val_loss: 202.1686 - val_MSE: 202.1686\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 201.99994\n",
      "Epoch 170/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 253.6568 - MSE: 253.6568 - val_loss: 260.1669 - val_MSE: 260.1669\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 201.99994\n",
      "Epoch 171/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 161.8779 - MSE: 161.8779 - val_loss: 229.8718 - val_MSE: 229.8718\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 201.99994\n",
      "Epoch 172/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 189.6055 - MSE: 189.6055 - val_loss: 280.6214 - val_MSE: 280.6214\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 201.99994\n",
      "Epoch 173/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 173.2617 - MSE: 173.2617 - val_loss: 189.7437 - val_MSE: 189.7437\n",
      "\n",
      "Epoch 00173: val_loss improved from 201.99994 to 189.74370, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 174/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 196.3748 - MSE: 196.3748 - val_loss: 300.1166 - val_MSE: 300.1166\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 189.74370\n",
      "Epoch 175/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 227.5662 - MSE: 227.5662 - val_loss: 225.0313 - val_MSE: 225.0313\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 189.74370\n",
      "Epoch 176/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 189.8246 - MSE: 189.8246 - val_loss: 200.8905 - val_MSE: 200.8905\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 189.74370\n",
      "Epoch 177/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 198.4875 - MSE: 198.4875 - val_loss: 222.9581 - val_MSE: 222.9581\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 189.74370\n",
      "Epoch 178/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 198.9505 - MSE: 198.9505 - val_loss: 255.9541 - val_MSE: 255.9541\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 189.74370\n",
      "Epoch 179/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 170.9876 - MSE: 170.9876 - val_loss: 236.0185 - val_MSE: 236.0185\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 189.74370\n",
      "Epoch 180/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 224.4909 - MSE: 224.4909 - val_loss: 226.9613 - val_MSE: 226.9613\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 189.74370\n",
      "Epoch 181/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 199.7518 - MSE: 199.7518 - val_loss: 241.6197 - val_MSE: 241.6197\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 189.74370\n",
      "Epoch 182/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 224.7529 - MSE: 224.7529 - val_loss: 228.6268 - val_MSE: 228.6268\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 189.74370\n",
      "Epoch 183/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 178.0057 - MSE: 178.0057 - val_loss: 208.4803 - val_MSE: 208.4803\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 189.74370\n",
      "Epoch 184/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 196.8860 - MSE: 196.8860 - val_loss: 231.6184 - val_MSE: 231.6184\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 189.74370\n",
      "Epoch 185/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 156.5717 - MSE: 156.5717 - val_loss: 181.1978 - val_MSE: 181.1978\n",
      "\n",
      "Epoch 00185: val_loss improved from 189.74370 to 181.19783, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 186/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 179.4091 - MSE: 179.4091 - val_loss: 243.8254 - val_MSE: 243.8254\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 181.19783\n",
      "Epoch 187/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 8ms/step - loss: 174.8680 - MSE: 174.8680 - val_loss: 318.1040 - val_MSE: 318.1040\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 181.19783\n",
      "Epoch 188/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 185.7338 - MSE: 185.7338 - val_loss: 221.6294 - val_MSE: 221.6294\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 181.19783\n",
      "Epoch 189/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 167.2354 - MSE: 167.2354 - val_loss: 201.5054 - val_MSE: 201.5054\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 181.19783\n",
      "Epoch 190/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 190.8117 - MSE: 190.8117 - val_loss: 227.4471 - val_MSE: 227.4471\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 181.19783\n",
      "Epoch 191/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 192.0672 - MSE: 192.0672 - val_loss: 220.2886 - val_MSE: 220.2886\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 181.19783\n",
      "Epoch 192/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 194.7143 - MSE: 194.7143 - val_loss: 203.4506 - val_MSE: 203.4506\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 181.19783\n",
      "Epoch 193/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 185.0598 - MSE: 185.0598 - val_loss: 234.6065 - val_MSE: 234.6065\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 181.19783\n",
      "Epoch 194/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 186.3256 - MSE: 186.3256 - val_loss: 280.3012 - val_MSE: 280.3012\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 181.19783\n",
      "Epoch 195/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 194.5229 - MSE: 194.5229 - val_loss: 262.9877 - val_MSE: 262.9877\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 181.19783\n",
      "Epoch 196/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 197.8941 - MSE: 197.8941 - val_loss: 341.5748 - val_MSE: 341.5748\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 181.19783\n",
      "Epoch 197/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 258.6146 - MSE: 258.6146 - val_loss: 229.2178 - val_MSE: 229.2178\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 181.19783\n",
      "Epoch 198/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 194.4398 - MSE: 194.4398 - val_loss: 309.0614 - val_MSE: 309.0614\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 181.19783\n",
      "Epoch 199/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 225.0442 - MSE: 225.0442 - val_loss: 186.0842 - val_MSE: 186.0842\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 181.19783\n",
      "Epoch 200/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 163.7052 - MSE: 163.7052 - val_loss: 212.2219 - val_MSE: 212.2219\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 181.19783\n",
      "Epoch 201/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 178.6350 - MSE: 178.6350 - val_loss: 190.6448 - val_MSE: 190.6448\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 181.19783\n",
      "Epoch 202/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 174.2717 - MSE: 174.2717 - val_loss: 236.6440 - val_MSE: 236.6440\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 181.19783\n",
      "Epoch 203/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 196.9192 - MSE: 196.9192 - val_loss: 291.5436 - val_MSE: 291.5436\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 181.19783\n",
      "Epoch 204/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 173.3070 - MSE: 173.3070 - val_loss: 230.1385 - val_MSE: 230.1385\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 181.19783\n",
      "Epoch 205/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 182.0772 - MSE: 182.0772 - val_loss: 197.7325 - val_MSE: 197.7325\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 181.19783\n",
      "Epoch 206/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 158.8587 - MSE: 158.8587 - val_loss: 211.6828 - val_MSE: 211.6828\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 181.19783\n",
      "Epoch 207/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 162.1247 - MSE: 162.1247 - val_loss: 186.5066 - val_MSE: 186.5066\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 181.19783\n",
      "Epoch 208/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 178.8269 - MSE: 178.8269 - val_loss: 192.7006 - val_MSE: 192.7006\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 181.19783\n",
      "Epoch 209/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 196.9766 - MSE: 196.9766 - val_loss: 199.3203 - val_MSE: 199.3203\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 181.19783\n",
      "Epoch 210/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 187.7929 - MSE: 187.7929 - val_loss: 227.5701 - val_MSE: 227.5701\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 181.19783\n",
      "Epoch 211/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 184.7056 - MSE: 184.7056 - val_loss: 203.8416 - val_MSE: 203.8416\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 181.19783\n",
      "Epoch 212/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 166.9597 - MSE: 166.9597 - val_loss: 213.7560 - val_MSE: 213.7560\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 181.19783\n",
      "Epoch 213/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 198.3751 - MSE: 198.3751 - val_loss: 196.9656 - val_MSE: 196.9656\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 181.19783\n",
      "Epoch 214/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 177.4067 - MSE: 177.4067 - val_loss: 253.0750 - val_MSE: 253.0750\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 181.19783\n",
      "Epoch 215/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 239.0456 - MSE: 239.0456 - val_loss: 163.1476 - val_MSE: 163.1476\n",
      "\n",
      "Epoch 00215: val_loss improved from 181.19783 to 163.14760, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 216/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 193.6080 - MSE: 193.6080 - val_loss: 211.1180 - val_MSE: 211.1180\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 163.14760\n",
      "Epoch 217/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 150.5889 - MSE: 150.5889 - val_loss: 231.8794 - val_MSE: 231.8794\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 163.14760\n",
      "Epoch 218/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 159.6798 - MSE: 159.6798 - val_loss: 185.7246 - val_MSE: 185.7246\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 163.14760\n",
      "Epoch 219/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 193.6769 - MSE: 193.6769 - val_loss: 230.6371 - val_MSE: 230.6371\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 163.14760\n",
      "Epoch 220/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 187.8421 - MSE: 187.8421 - val_loss: 184.2378 - val_MSE: 184.2378\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 163.14760\n",
      "Epoch 221/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 159.3354 - MSE: 159.3354 - val_loss: 199.7778 - val_MSE: 199.7778\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 163.14760\n",
      "Epoch 222/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 148.7190 - MSE: 148.7190 - val_loss: 212.4212 - val_MSE: 212.4212\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 163.14760\n",
      "Epoch 223/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 163.1084 - MSE: 163.1084 - val_loss: 178.0891 - val_MSE: 178.0891\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 163.14760\n",
      "Epoch 224/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 160.1624 - MSE: 160.1624 - val_loss: 223.5551 - val_MSE: 223.5551\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 163.14760\n",
      "Epoch 225/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 194.0896 - MSE: 194.0896 - val_loss: 188.1940 - val_MSE: 188.1940\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 163.14760\n",
      "Epoch 226/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 201.1345 - MSE: 201.1345 - val_loss: 195.9674 - val_MSE: 195.9674\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 163.14760\n",
      "Epoch 227/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 188.9400 - MSE: 188.9400 - val_loss: 201.5942 - val_MSE: 201.5942\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 163.14760\n",
      "Epoch 228/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 8ms/step - loss: 162.2959 - MSE: 162.2959 - val_loss: 226.1335 - val_MSE: 226.1335\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 163.14760\n",
      "Epoch 229/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 162.9530 - MSE: 162.9530 - val_loss: 196.8195 - val_MSE: 196.8195\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 163.14760\n",
      "Epoch 230/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 129.7944 - MSE: 129.7944 - val_loss: 200.9496 - val_MSE: 200.9496\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 163.14760\n",
      "Epoch 231/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 162.1828 - MSE: 162.1828 - val_loss: 193.8827 - val_MSE: 193.8827\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 163.14760\n",
      "Epoch 232/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 150.4208 - MSE: 150.4208 - val_loss: 249.6333 - val_MSE: 249.6333\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 163.14760\n",
      "Epoch 233/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 174.5712 - MSE: 174.5712 - val_loss: 232.0951 - val_MSE: 232.0951\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 163.14760\n",
      "Epoch 234/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 171.4709 - MSE: 171.4709 - val_loss: 201.7087 - val_MSE: 201.7087\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 163.14760\n",
      "Epoch 235/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 159.2632 - MSE: 159.2632 - val_loss: 199.6366 - val_MSE: 199.6366\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 163.14760\n",
      "Epoch 236/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 169.7465 - MSE: 169.7465 - val_loss: 208.6886 - val_MSE: 208.6886\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 163.14760\n",
      "Epoch 237/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 172.0497 - MSE: 172.0497 - val_loss: 178.8719 - val_MSE: 178.8719\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 163.14760\n",
      "Epoch 238/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 156.2200 - MSE: 156.2200 - val_loss: 188.2632 - val_MSE: 188.2632\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 163.14760\n",
      "Epoch 239/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 191.6103 - MSE: 191.6103 - val_loss: 178.0313 - val_MSE: 178.0313\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 163.14760\n",
      "Epoch 240/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 174.7462 - MSE: 174.7462 - val_loss: 255.9271 - val_MSE: 255.9271\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 163.14760\n",
      "Epoch 241/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 212.0905 - MSE: 212.0905 - val_loss: 214.8543 - val_MSE: 214.8543\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 163.14760\n",
      "Epoch 242/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 162.7613 - MSE: 162.7613 - val_loss: 204.9683 - val_MSE: 204.9683\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 163.14760\n",
      "Epoch 243/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 188.3177 - MSE: 188.3177 - val_loss: 174.1783 - val_MSE: 174.1783\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 163.14760\n",
      "Epoch 244/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 177.6931 - MSE: 177.6931 - val_loss: 178.8156 - val_MSE: 178.8156\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 163.14760\n",
      "Epoch 245/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 168.5383 - MSE: 168.5383 - val_loss: 188.1441 - val_MSE: 188.1441\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 163.14760\n",
      "Epoch 246/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 166.0864 - MSE: 166.0864 - val_loss: 177.9726 - val_MSE: 177.9726\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 163.14760\n",
      "Epoch 247/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 145.1563 - MSE: 145.1563 - val_loss: 197.7165 - val_MSE: 197.7165\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 163.14760\n",
      "Epoch 248/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 181.5093 - MSE: 181.5093 - val_loss: 176.8632 - val_MSE: 176.8632\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 163.14760\n",
      "Epoch 249/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 160.1514 - MSE: 160.1514 - val_loss: 228.8141 - val_MSE: 228.8141\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 163.14760\n",
      "Epoch 250/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 160.0061 - MSE: 160.0061 - val_loss: 184.1722 - val_MSE: 184.1722\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 163.14760\n",
      "Epoch 251/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 176.6973 - MSE: 176.6973 - val_loss: 184.7781 - val_MSE: 184.7781\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 163.14760\n",
      "Epoch 252/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 206.8526 - MSE: 206.8526 - val_loss: 177.2727 - val_MSE: 177.2727\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 163.14760\n",
      "Epoch 253/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 165.9973 - MSE: 165.9973 - val_loss: 193.1595 - val_MSE: 193.1595\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 163.14760\n",
      "Epoch 254/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 184.4153 - MSE: 184.4153 - val_loss: 186.6571 - val_MSE: 186.6571\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 163.14760\n",
      "Epoch 255/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 154.7889 - MSE: 154.7889 - val_loss: 205.3507 - val_MSE: 205.3507\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 163.14760\n",
      "Epoch 256/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 181.7965 - MSE: 181.7965 - val_loss: 156.2669 - val_MSE: 156.2669\n",
      "\n",
      "Epoch 00256: val_loss improved from 163.14760 to 156.26691, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 257/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 180.3927 - MSE: 180.3927 - val_loss: 154.4010 - val_MSE: 154.4010\n",
      "\n",
      "Epoch 00257: val_loss improved from 156.26691 to 154.40105, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 258/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 196.1892 - MSE: 196.1892 - val_loss: 209.4801 - val_MSE: 209.4801\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 154.40105\n",
      "Epoch 259/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 202.3060 - MSE: 202.3060 - val_loss: 167.4210 - val_MSE: 167.4210\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 154.40105\n",
      "Epoch 260/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 209.5739 - MSE: 209.5739 - val_loss: 232.7509 - val_MSE: 232.7509\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 154.40105\n",
      "Epoch 261/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 169.5790 - MSE: 169.5790 - val_loss: 183.8937 - val_MSE: 183.8937\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 154.40105\n",
      "Epoch 262/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 143.0832 - MSE: 143.0832 - val_loss: 157.3788 - val_MSE: 157.3788\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 154.40105\n",
      "Epoch 263/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 176.8097 - MSE: 176.8097 - val_loss: 217.6721 - val_MSE: 217.6721\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 154.40105\n",
      "Epoch 264/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 149.2770 - MSE: 149.2770 - val_loss: 215.1013 - val_MSE: 215.1013\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 154.40105\n",
      "Epoch 265/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 165.1840 - MSE: 165.1840 - val_loss: 169.0493 - val_MSE: 169.0493\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 154.40105\n",
      "Epoch 266/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 175.7426 - MSE: 175.7426 - val_loss: 207.6829 - val_MSE: 207.6829\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 154.40105\n",
      "Epoch 267/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 211.0562 - MSE: 211.0562 - val_loss: 233.2945 - val_MSE: 233.2945\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 154.40105\n",
      "Epoch 268/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 8ms/step - loss: 175.5344 - MSE: 175.5344 - val_loss: 202.7453 - val_MSE: 202.7453\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 154.40105\n",
      "Epoch 269/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 207.1835 - MSE: 207.1835 - val_loss: 220.4677 - val_MSE: 220.4677\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 154.40105\n",
      "Epoch 270/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 197.1005 - MSE: 197.1005 - val_loss: 187.9164 - val_MSE: 187.9164\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 154.40105\n",
      "Epoch 271/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 178.0662 - MSE: 178.0662 - val_loss: 294.3171 - val_MSE: 294.3171\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 154.40105\n",
      "Epoch 272/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 192.7538 - MSE: 192.7538 - val_loss: 173.1228 - val_MSE: 173.1228\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 154.40105\n",
      "Epoch 273/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 217.4186 - MSE: 217.4186 - val_loss: 246.7661 - val_MSE: 246.7661\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 154.40105\n",
      "Epoch 274/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 247.1400 - MSE: 247.1400 - val_loss: 209.5889 - val_MSE: 209.5889\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 154.40105\n",
      "Epoch 275/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 174.2206 - MSE: 174.2206 - val_loss: 183.2124 - val_MSE: 183.2124\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 154.40105\n",
      "Epoch 276/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 154.8063 - MSE: 154.8063 - val_loss: 168.9518 - val_MSE: 168.9518\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 154.40105\n",
      "Epoch 277/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 173.7723 - MSE: 173.7723 - val_loss: 198.4211 - val_MSE: 198.4211\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 154.40105\n",
      "Epoch 278/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 218.1222 - MSE: 218.1222 - val_loss: 196.5070 - val_MSE: 196.5070\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 154.40105\n",
      "Epoch 279/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 139.5050 - MSE: 139.5050 - val_loss: 170.9856 - val_MSE: 170.9856\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 154.40105\n",
      "Epoch 280/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 170.5559 - MSE: 170.5559 - val_loss: 166.7737 - val_MSE: 166.7737\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 154.40105\n",
      "Epoch 281/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 180.4889 - MSE: 180.4889 - val_loss: 156.3730 - val_MSE: 156.3730\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 154.40105\n",
      "Epoch 282/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 133.3019 - MSE: 133.3019 - val_loss: 171.8213 - val_MSE: 171.8213\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 154.40105\n",
      "Epoch 283/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 204.4045 - MSE: 204.4045 - val_loss: 148.1739 - val_MSE: 148.1739\n",
      "\n",
      "Epoch 00283: val_loss improved from 154.40105 to 148.17386, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 284/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 155.2927 - MSE: 155.2927 - val_loss: 231.8359 - val_MSE: 231.8359\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 148.17386\n",
      "Epoch 285/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 220.6570 - MSE: 220.6570 - val_loss: 183.2464 - val_MSE: 183.2464\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 148.17386\n",
      "Epoch 286/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 198.1453 - MSE: 198.1453 - val_loss: 186.6798 - val_MSE: 186.6798\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 148.17386\n",
      "Epoch 287/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 198.0812 - MSE: 198.0812 - val_loss: 176.8847 - val_MSE: 176.8847\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 148.17386\n",
      "Epoch 288/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 174.3366 - MSE: 174.3366 - val_loss: 168.5228 - val_MSE: 168.5228\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 148.17386\n",
      "Epoch 289/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 148.1884 - MSE: 148.1884 - val_loss: 216.5647 - val_MSE: 216.5647\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 148.17386\n",
      "Epoch 290/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 153.9965 - MSE: 153.9965 - val_loss: 174.5133 - val_MSE: 174.5133\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 148.17386\n",
      "Epoch 291/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 178.0274 - MSE: 178.0274 - val_loss: 173.1811 - val_MSE: 173.1811\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 148.17386\n",
      "Epoch 292/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 134.0844 - MSE: 134.0844 - val_loss: 276.6991 - val_MSE: 276.6991\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 148.17386\n",
      "Epoch 293/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 213.5383 - MSE: 213.5383 - val_loss: 221.8441 - val_MSE: 221.8441\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 148.17386\n",
      "Epoch 294/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 200.0784 - MSE: 200.0784 - val_loss: 194.8064 - val_MSE: 194.8064\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 148.17386\n",
      "Epoch 295/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 148.5283 - MSE: 148.5283 - val_loss: 183.6156 - val_MSE: 183.6156\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 148.17386\n",
      "Epoch 296/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 170.2398 - MSE: 170.2398 - val_loss: 205.5592 - val_MSE: 205.5592\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 148.17386\n",
      "Epoch 297/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 169.8813 - MSE: 169.8813 - val_loss: 185.1652 - val_MSE: 185.1652\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 148.17386\n",
      "Epoch 298/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 169.5572 - MSE: 169.5572 - val_loss: 146.4139 - val_MSE: 146.4139\n",
      "\n",
      "Epoch 00298: val_loss improved from 148.17386 to 146.41393, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 299/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 109.6210 - MSE: 109.6210 - val_loss: 179.5535 - val_MSE: 179.5535\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 146.41393\n",
      "Epoch 300/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 188.8539 - MSE: 188.8539 - val_loss: 217.5524 - val_MSE: 217.5524\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 146.41393\n",
      "Epoch 301/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 150.5861 - MSE: 150.5861 - val_loss: 230.1242 - val_MSE: 230.1242\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 146.41393\n",
      "Epoch 302/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 166.3603 - MSE: 166.3603 - val_loss: 203.3037 - val_MSE: 203.3037\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 146.41393\n",
      "Epoch 303/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 164.5661 - MSE: 164.5661 - val_loss: 178.9203 - val_MSE: 178.9203\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 146.41393\n",
      "Epoch 304/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 114.7599 - MSE: 114.7599 - val_loss: 165.0677 - val_MSE: 165.0677\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 146.41393\n",
      "Epoch 305/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 155.9066 - MSE: 155.9066 - val_loss: 227.4057 - val_MSE: 227.4057\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 146.41393\n",
      "Epoch 306/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 233.4492 - MSE: 233.4492 - val_loss: 170.1674 - val_MSE: 170.1674\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 146.41393\n",
      "Epoch 307/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 124.9439 - MSE: 124.9439 - val_loss: 214.9774 - val_MSE: 214.9774\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 146.41393\n",
      "Epoch 308/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 8ms/step - loss: 166.9449 - MSE: 166.9449 - val_loss: 213.0608 - val_MSE: 213.0608\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 146.41393\n",
      "Epoch 309/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 132.7566 - MSE: 132.7566 - val_loss: 190.5056 - val_MSE: 190.5056\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 146.41393\n",
      "Epoch 310/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 151.7111 - MSE: 151.7111 - val_loss: 239.1732 - val_MSE: 239.1732\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 146.41393\n",
      "Epoch 311/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 170.6134 - MSE: 170.6134 - val_loss: 200.9582 - val_MSE: 200.9582\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 146.41393\n",
      "Epoch 312/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 195.4904 - MSE: 195.4904 - val_loss: 199.6565 - val_MSE: 199.6565\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 146.41393\n",
      "Epoch 313/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 177.2601 - MSE: 177.2601 - val_loss: 168.4776 - val_MSE: 168.4776\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 146.41393\n",
      "Epoch 314/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 179.9652 - MSE: 179.9652 - val_loss: 151.5742 - val_MSE: 151.5742\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 146.41393\n",
      "Epoch 315/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 200.9996 - MSE: 200.9996 - val_loss: 230.3064 - val_MSE: 230.3064\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 146.41393\n",
      "Epoch 316/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 158.6673 - MSE: 158.6673 - val_loss: 184.8886 - val_MSE: 184.8886\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 146.41393\n",
      "Epoch 317/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 168.1271 - MSE: 168.1271 - val_loss: 208.4854 - val_MSE: 208.4854\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 146.41393\n",
      "Epoch 318/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 174.9200 - MSE: 174.9200 - val_loss: 224.1484 - val_MSE: 224.1484\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 146.41393\n",
      "Epoch 319/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 137.9298 - MSE: 137.9298 - val_loss: 221.1040 - val_MSE: 221.1040\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 146.41393\n",
      "Epoch 320/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 172.3743 - MSE: 172.3743 - val_loss: 203.3991 - val_MSE: 203.3991\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 146.41393\n",
      "Epoch 321/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 155.7945 - MSE: 155.7945 - val_loss: 204.8877 - val_MSE: 204.8877\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 146.41393\n",
      "Epoch 322/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 148.0874 - MSE: 148.0874 - val_loss: 236.3248 - val_MSE: 236.3248\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 146.41393\n",
      "Epoch 323/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 181.2866 - MSE: 181.2866 - val_loss: 155.0946 - val_MSE: 155.0946\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 146.41393\n",
      "Epoch 324/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 172.0731 - MSE: 172.0731 - val_loss: 230.1944 - val_MSE: 230.1944\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 146.41393\n",
      "Epoch 325/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 143.3026 - MSE: 143.3026 - val_loss: 163.9233 - val_MSE: 163.9233\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 146.41393\n",
      "Epoch 326/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 167.1685 - MSE: 167.1685 - val_loss: 205.7826 - val_MSE: 205.7826\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 146.41393\n",
      "Epoch 327/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 160.4262 - MSE: 160.4262 - val_loss: 244.2241 - val_MSE: 244.2241\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 146.41393\n",
      "Epoch 328/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 177.3889 - MSE: 177.3889 - val_loss: 242.9577 - val_MSE: 242.9577\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 146.41393\n",
      "Epoch 329/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 162.2768 - MSE: 162.2768 - val_loss: 191.4639 - val_MSE: 191.4639\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 146.41393\n",
      "Epoch 330/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 126.8705 - MSE: 126.8705 - val_loss: 224.1653 - val_MSE: 224.1653\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 146.41393\n",
      "Epoch 331/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 169.3333 - MSE: 169.3333 - val_loss: 191.9474 - val_MSE: 191.9474\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 146.41393\n",
      "Epoch 332/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 136.0031 - MSE: 136.0031 - val_loss: 195.3363 - val_MSE: 195.3363\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 146.41393\n",
      "Epoch 333/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 124.3752 - MSE: 124.3752 - val_loss: 177.4631 - val_MSE: 177.4631\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 146.41393\n",
      "Epoch 334/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 170.5919 - MSE: 170.5919 - val_loss: 176.4153 - val_MSE: 176.4153\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 146.41393\n",
      "Epoch 335/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 187.5703 - MSE: 187.5703 - val_loss: 196.2033 - val_MSE: 196.2033\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 146.41393\n",
      "Epoch 336/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 157.5584 - MSE: 157.5584 - val_loss: 191.0832 - val_MSE: 191.0832\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 146.41393\n",
      "Epoch 337/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 158.2209 - MSE: 158.2209 - val_loss: 199.3650 - val_MSE: 199.3650\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 146.41393\n",
      "Epoch 338/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 142.2950 - MSE: 142.2950 - val_loss: 159.3779 - val_MSE: 159.3779\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 146.41393\n",
      "Epoch 339/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 149.1360 - MSE: 149.1360 - val_loss: 175.9538 - val_MSE: 175.9537\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 146.41393\n",
      "Epoch 340/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 176.1238 - MSE: 176.1238 - val_loss: 172.3425 - val_MSE: 172.3425\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 146.41393\n",
      "Epoch 341/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 155.7546 - MSE: 155.7546 - val_loss: 165.1289 - val_MSE: 165.1289\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 146.41393\n",
      "Epoch 342/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 156.6690 - MSE: 156.6690 - val_loss: 176.5597 - val_MSE: 176.5597\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 146.41393\n",
      "Epoch 343/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 140.9637 - MSE: 140.9637 - val_loss: 186.3741 - val_MSE: 186.3741\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 146.41393\n",
      "Epoch 344/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 129.8644 - MSE: 129.8644 - val_loss: 192.1690 - val_MSE: 192.1690\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 146.41393\n",
      "Epoch 345/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 155.7467 - MSE: 155.7467 - val_loss: 133.4921 - val_MSE: 133.4921\n",
      "\n",
      "Epoch 00345: val_loss improved from 146.41393 to 133.49208, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 346/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 132.1570 - MSE: 132.1570 - val_loss: 197.8041 - val_MSE: 197.8041\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 133.49208\n",
      "Epoch 347/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 251.1230 - MSE: 251.1230 - val_loss: 216.1516 - val_MSE: 216.1516\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 133.49208\n",
      "Epoch 348/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 159.9131 - MSE: 159.9131 - val_loss: 260.0897 - val_MSE: 260.0897\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 133.49208\n",
      "Epoch 349/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 9ms/step - loss: 196.0507 - MSE: 196.0507 - val_loss: 197.4653 - val_MSE: 197.4653\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 133.49208\n",
      "Epoch 350/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 182.7682 - MSE: 182.7682 - val_loss: 162.4552 - val_MSE: 162.4552\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 133.49208\n",
      "Epoch 351/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 204.1739 - MSE: 204.1739 - val_loss: 209.6387 - val_MSE: 209.6387\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 133.49208\n",
      "Epoch 352/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 145.0096 - MSE: 145.0096 - val_loss: 189.2544 - val_MSE: 189.2544\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 133.49208\n",
      "Epoch 353/1500\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 205.2094 - MSE: 205.2094 - val_loss: 190.2306 - val_MSE: 190.2306\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 133.49208\n",
      "Epoch 354/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 127.7469 - MSE: 127.7469 - val_loss: 186.6123 - val_MSE: 186.6123\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 133.49208\n",
      "Epoch 355/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 160.3215 - MSE: 160.3215 - val_loss: 188.2860 - val_MSE: 188.2860\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 133.49208\n",
      "Epoch 356/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 196.9747 - MSE: 196.9747 - val_loss: 166.3528 - val_MSE: 166.3528\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 133.49208\n",
      "Epoch 357/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 160.3604 - MSE: 160.3604 - val_loss: 211.5639 - val_MSE: 211.5639\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 133.49208\n",
      "Epoch 358/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 162.1219 - MSE: 162.1219 - val_loss: 207.6559 - val_MSE: 207.6559\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 133.49208\n",
      "Epoch 359/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 168.1584 - MSE: 168.1584 - val_loss: 140.0681 - val_MSE: 140.0681\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 133.49208\n",
      "Epoch 360/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 177.2620 - MSE: 177.2620 - val_loss: 168.2438 - val_MSE: 168.2438\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 133.49208\n",
      "Epoch 361/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 198.9628 - MSE: 198.9628 - val_loss: 187.4225 - val_MSE: 187.4225\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 133.49208\n",
      "Epoch 362/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 152.3487 - MSE: 152.3487 - val_loss: 192.1972 - val_MSE: 192.1972\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 133.49208\n",
      "Epoch 363/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 150.3750 - MSE: 150.3750 - val_loss: 224.8034 - val_MSE: 224.8034\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 133.49208\n",
      "Epoch 364/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 153.8580 - MSE: 153.8580 - val_loss: 192.5583 - val_MSE: 192.5583\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 133.49208\n",
      "Epoch 365/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 182.1211 - MSE: 182.1211 - val_loss: 194.5108 - val_MSE: 194.5108\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 133.49208\n",
      "Epoch 366/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 169.5933 - MSE: 169.5933 - val_loss: 192.1842 - val_MSE: 192.1842\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 133.49208\n",
      "Epoch 367/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 123.7986 - MSE: 123.7986 - val_loss: 212.1167 - val_MSE: 212.1167\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 133.49208\n",
      "Epoch 368/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 160.0722 - MSE: 160.0722 - val_loss: 162.7107 - val_MSE: 162.7107\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 133.49208\n",
      "Epoch 369/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 159.4685 - MSE: 159.4685 - val_loss: 277.2916 - val_MSE: 277.2916\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 133.49208\n",
      "Epoch 370/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 177.1535 - MSE: 177.1535 - val_loss: 124.0572 - val_MSE: 124.0572\n",
      "\n",
      "Epoch 00370: val_loss improved from 133.49208 to 124.05721, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 371/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 124.1893 - MSE: 124.1893 - val_loss: 151.0201 - val_MSE: 151.0201\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 124.05721\n",
      "Epoch 372/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 148.6219 - MSE: 148.6219 - val_loss: 159.6860 - val_MSE: 159.6860\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 124.05721\n",
      "Epoch 373/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 138.4107 - MSE: 138.4107 - val_loss: 148.1085 - val_MSE: 148.1085\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 124.05721\n",
      "Epoch 374/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 113.4909 - MSE: 113.4909 - val_loss: 218.4551 - val_MSE: 218.4551\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 124.05721\n",
      "Epoch 375/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 158.2668 - MSE: 158.2668 - val_loss: 160.8528 - val_MSE: 160.8528\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 124.05721\n",
      "Epoch 376/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 135.8583 - MSE: 135.8583 - val_loss: 139.7233 - val_MSE: 139.7233\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 124.05721\n",
      "Epoch 377/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 160.0029 - MSE: 160.0029 - val_loss: 144.1583 - val_MSE: 144.1583\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 124.05721\n",
      "Epoch 378/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 135.7400 - MSE: 135.7400 - val_loss: 183.5998 - val_MSE: 183.5998\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 124.05721\n",
      "Epoch 379/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 144.5095 - MSE: 144.5095 - val_loss: 192.2443 - val_MSE: 192.2443\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 124.05721\n",
      "Epoch 380/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 114.7621 - MSE: 114.7621 - val_loss: 184.0655 - val_MSE: 184.0655\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 124.05721\n",
      "Epoch 381/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 169.9449 - MSE: 169.9449 - val_loss: 150.2613 - val_MSE: 150.2613\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 124.05721\n",
      "Epoch 382/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 158.0376 - MSE: 158.0376 - val_loss: 168.4667 - val_MSE: 168.4667\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 124.05721\n",
      "Epoch 383/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 147.0708 - MSE: 147.0708 - val_loss: 214.2830 - val_MSE: 214.2830\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 124.05721\n",
      "Epoch 384/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 126.7436 - MSE: 126.7436 - val_loss: 219.2352 - val_MSE: 219.2352\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 124.05721\n",
      "Epoch 385/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 144.5394 - MSE: 144.5394 - val_loss: 245.8159 - val_MSE: 245.8159\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 124.05721\n",
      "Epoch 386/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 224.1274 - MSE: 224.1274 - val_loss: 138.2285 - val_MSE: 138.2285\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 124.05721\n",
      "Epoch 387/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 144.1891 - MSE: 144.1891 - val_loss: 156.2230 - val_MSE: 156.2230\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 124.05721\n",
      "Epoch 388/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 142.5822 - MSE: 142.5822 - val_loss: 169.1279 - val_MSE: 169.1279\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 124.05721\n",
      "Epoch 389/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 143.9938 - MSE: 143.9938 - val_loss: 160.7206 - val_MSE: 160.7206\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 124.05721\n",
      "Epoch 390/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 10ms/step - loss: 198.9722 - MSE: 198.9722 - val_loss: 162.1755 - val_MSE: 162.1755\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 124.05721\n",
      "Epoch 391/1500\n",
      "141/141 [==============================] - 1s 11ms/step - loss: 160.9477 - MSE: 160.9477 - val_loss: 205.9639 - val_MSE: 205.9639\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 124.05721\n",
      "Epoch 392/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 169.1507 - MSE: 169.1507 - val_loss: 157.2379 - val_MSE: 157.2379\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 124.05721\n",
      "Epoch 393/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 169.1686 - MSE: 169.1686 - val_loss: 161.3883 - val_MSE: 161.3883\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 124.05721\n",
      "Epoch 394/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 159.7484 - MSE: 159.7484 - val_loss: 171.9056 - val_MSE: 171.9056\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 124.05721\n",
      "Epoch 395/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 152.6147 - MSE: 152.6147 - val_loss: 188.6959 - val_MSE: 188.6959\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 124.05721\n",
      "Epoch 396/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 176.7772 - MSE: 176.7772 - val_loss: 155.0599 - val_MSE: 155.0599\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 124.05721\n",
      "Epoch 397/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 158.3649 - MSE: 158.3649 - val_loss: 162.7693 - val_MSE: 162.7693\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 124.05721\n",
      "Epoch 398/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 127.9436 - MSE: 127.9436 - val_loss: 133.2116 - val_MSE: 133.2116\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 124.05721\n",
      "Epoch 399/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 156.9961 - MSE: 156.9961 - val_loss: 212.7787 - val_MSE: 212.7787\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 124.05721\n",
      "Epoch 400/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 155.1439 - MSE: 155.1439 - val_loss: 179.9077 - val_MSE: 179.9077\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 124.05721\n",
      "Epoch 401/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 153.8408 - MSE: 153.8408 - val_loss: 184.8227 - val_MSE: 184.8227\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 124.05721\n",
      "Epoch 402/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 105.6753 - MSE: 105.6753 - val_loss: 171.0110 - val_MSE: 171.0110\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 124.05721\n",
      "Epoch 403/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 140.7269 - MSE: 140.7269 - val_loss: 189.9034 - val_MSE: 189.9034\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 124.05721\n",
      "Epoch 404/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 215.9484 - MSE: 215.9484 - val_loss: 301.0274 - val_MSE: 301.0274\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 124.05721\n",
      "Epoch 405/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 175.2551 - MSE: 175.2551 - val_loss: 298.7180 - val_MSE: 298.7180\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 124.05721\n",
      "Epoch 406/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 158.8510 - MSE: 158.8510 - val_loss: 146.0762 - val_MSE: 146.0762\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 124.05721\n",
      "Epoch 407/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 102.2026 - MSE: 102.2026 - val_loss: 158.6836 - val_MSE: 158.6836\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 124.05721\n",
      "Epoch 408/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 186.0365 - MSE: 186.0365 - val_loss: 149.0951 - val_MSE: 149.0951\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 124.05721\n",
      "Epoch 409/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 124.0731 - MSE: 124.0731 - val_loss: 203.3666 - val_MSE: 203.3666\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 124.05721\n",
      "Epoch 410/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 112.0717 - MSE: 112.0717 - val_loss: 165.2298 - val_MSE: 165.2298\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 124.05721\n",
      "Epoch 411/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 110.2833 - MSE: 110.2833 - val_loss: 181.2843 - val_MSE: 181.2843\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 124.05721\n",
      "Epoch 412/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 152.5683 - MSE: 152.5683 - val_loss: 190.6582 - val_MSE: 190.6582\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 124.05721\n",
      "Epoch 413/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 123.9931 - MSE: 123.9931 - val_loss: 160.5047 - val_MSE: 160.5047\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 124.05721\n",
      "Epoch 414/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 130.5331 - MSE: 130.5331 - val_loss: 168.5147 - val_MSE: 168.5147\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 124.05721\n",
      "Epoch 415/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 174.7351 - MSE: 174.7351 - val_loss: 162.3434 - val_MSE: 162.3434\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 124.05721\n",
      "Epoch 416/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 169.0955 - MSE: 169.0955 - val_loss: 157.7431 - val_MSE: 157.7431\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 124.05721\n",
      "Epoch 417/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 123.1859 - MSE: 123.1859 - val_loss: 168.8113 - val_MSE: 168.8113\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 124.05721\n",
      "Epoch 418/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 112.5907 - MSE: 112.5907 - val_loss: 157.8751 - val_MSE: 157.8751\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 124.05721\n",
      "Epoch 419/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 153.6487 - MSE: 153.6487 - val_loss: 163.2244 - val_MSE: 163.2244\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 124.05721\n",
      "Epoch 420/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 118.7723 - MSE: 118.7723 - val_loss: 167.3069 - val_MSE: 167.3069\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 124.05721\n",
      "Epoch 421/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 135.5793 - MSE: 135.5793 - val_loss: 156.4607 - val_MSE: 156.4607\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 124.05721\n",
      "Epoch 422/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 143.5972 - MSE: 143.5972 - val_loss: 161.1412 - val_MSE: 161.1412\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 124.05721\n",
      "Epoch 423/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 149.8544 - MSE: 149.8544 - val_loss: 181.9622 - val_MSE: 181.9622\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 124.05721\n",
      "Epoch 424/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 128.6413 - MSE: 128.6413 - val_loss: 204.1787 - val_MSE: 204.1787\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 124.05721\n",
      "Epoch 425/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 101.2995 - MSE: 101.2995 - val_loss: 145.0855 - val_MSE: 145.0855\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 124.05721\n",
      "Epoch 426/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 127.0092 - MSE: 127.0092 - val_loss: 190.8195 - val_MSE: 190.8195\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 124.05721\n",
      "Epoch 427/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 147.4970 - MSE: 147.4970 - val_loss: 161.2888 - val_MSE: 161.2888\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 124.05721\n",
      "Epoch 428/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 163.0920 - MSE: 163.0920 - val_loss: 150.4341 - val_MSE: 150.4341\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 124.05721\n",
      "Epoch 429/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 133.4531 - MSE: 133.4531 - val_loss: 121.1638 - val_MSE: 121.1638\n",
      "\n",
      "Epoch 00429: val_loss improved from 124.05721 to 121.16376, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 430/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 121.7133 - MSE: 121.7133 - val_loss: 129.5248 - val_MSE: 129.5248\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 121.16376\n",
      "Epoch 431/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 8ms/step - loss: 170.2589 - MSE: 170.2589 - val_loss: 164.6813 - val_MSE: 164.6813\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 121.16376\n",
      "Epoch 432/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 128.7353 - MSE: 128.7353 - val_loss: 158.2454 - val_MSE: 158.2454\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 121.16376\n",
      "Epoch 433/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 145.7481 - MSE: 145.7481 - val_loss: 150.6102 - val_MSE: 150.6102\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 121.16376\n",
      "Epoch 434/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 159.7560 - MSE: 159.7560 - val_loss: 163.0621 - val_MSE: 163.0621\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 121.16376\n",
      "Epoch 435/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 136.1892 - MSE: 136.1892 - val_loss: 125.0570 - val_MSE: 125.0570\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 121.16376\n",
      "Epoch 436/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 168.8352 - MSE: 168.8352 - val_loss: 199.1783 - val_MSE: 199.1783\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 121.16376\n",
      "Epoch 437/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 177.6728 - MSE: 177.6728 - val_loss: 267.2563 - val_MSE: 267.2563\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 121.16376\n",
      "Epoch 438/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 165.1448 - MSE: 165.1448 - val_loss: 152.0359 - val_MSE: 152.0359\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 121.16376\n",
      "Epoch 439/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 123.1278 - MSE: 123.1278 - val_loss: 281.0338 - val_MSE: 281.0338\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 121.16376\n",
      "Epoch 440/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 171.2046 - MSE: 171.2046 - val_loss: 184.0143 - val_MSE: 184.0143\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 121.16376\n",
      "Epoch 441/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 130.6451 - MSE: 130.6451 - val_loss: 157.8158 - val_MSE: 157.8158\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 121.16376\n",
      "Epoch 442/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 149.4915 - MSE: 149.4915 - val_loss: 171.8300 - val_MSE: 171.8300\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 121.16376\n",
      "Epoch 443/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 165.2854 - MSE: 165.2854 - val_loss: 188.6760 - val_MSE: 188.6760\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 121.16376\n",
      "Epoch 444/1500\n",
      "141/141 [==============================] - ETA: 0s - loss: 180.3574 - MSE: 180.357 - 1s 8ms/step - loss: 177.4124 - MSE: 177.4124 - val_loss: 187.2593 - val_MSE: 187.2593\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 121.16376\n",
      "Epoch 445/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 89.5628 - MSE: 89.5628 - val_loss: 133.6510 - val_MSE: 133.6510\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 121.16376\n",
      "Epoch 446/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 122.3069 - MSE: 122.3069 - val_loss: 122.6081 - val_MSE: 122.6081\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 121.16376\n",
      "Epoch 447/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 220.1908 - MSE: 220.1908 - val_loss: 162.3875 - val_MSE: 162.3875\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 121.16376\n",
      "Epoch 448/1500\n",
      "141/141 [==============================] - ETA: 0s - loss: 129.5252 - MSE: 129.525 - 1s 8ms/step - loss: 130.4296 - MSE: 130.4296 - val_loss: 148.5872 - val_MSE: 148.5872\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 121.16376\n",
      "Epoch 449/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117.8169 - MSE: 117.8169 - val_loss: 211.5995 - val_MSE: 211.5995\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 121.16376\n",
      "Epoch 450/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 112.3936 - MSE: 112.3936 - val_loss: 185.2196 - val_MSE: 185.2196\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 121.16376\n",
      "Epoch 451/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 155.2632 - MSE: 155.2632 - val_loss: 154.1538 - val_MSE: 154.1538\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 121.16376\n",
      "Epoch 452/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 144.5323 - MSE: 144.5323 - val_loss: 134.0713 - val_MSE: 134.0713\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 121.16376\n",
      "Epoch 453/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 115.8249 - MSE: 115.8249 - val_loss: 160.9506 - val_MSE: 160.9506\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 121.16376\n",
      "Epoch 454/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 149.1529 - MSE: 149.1529 - val_loss: 130.7540 - val_MSE: 130.7540\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 121.16376\n",
      "Epoch 455/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 137.0208 - MSE: 137.0208 - val_loss: 136.3535 - val_MSE: 136.3535\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 121.16376\n",
      "Epoch 456/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 131.6504 - MSE: 131.6504 - val_loss: 154.9147 - val_MSE: 154.9147\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 121.16376\n",
      "Epoch 457/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 102.3693 - MSE: 102.3693 - val_loss: 203.5335 - val_MSE: 203.5335\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 121.16376\n",
      "Epoch 458/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 121.3531 - MSE: 121.3531 - val_loss: 163.4606 - val_MSE: 163.4606\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 121.16376\n",
      "Epoch 459/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 152.9067 - MSE: 152.9067 - val_loss: 187.7493 - val_MSE: 187.7493\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 121.16376\n",
      "Epoch 460/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 213.3693 - MSE: 213.3693 - val_loss: 169.0945 - val_MSE: 169.0945\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 121.16376\n",
      "Epoch 461/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 121.3958 - MSE: 121.3958 - val_loss: 128.8596 - val_MSE: 128.8596\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 121.16376\n",
      "Epoch 462/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 111.5013 - MSE: 111.5013 - val_loss: 162.1352 - val_MSE: 162.1352\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 121.16376\n",
      "Epoch 463/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 142.8244 - MSE: 142.8244 - val_loss: 137.5738 - val_MSE: 137.5738\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 121.16376\n",
      "Epoch 464/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 92.5946 - MSE: 92.5946 - val_loss: 120.4428 - val_MSE: 120.4428\n",
      "\n",
      "Epoch 00464: val_loss improved from 121.16376 to 120.44279, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 465/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 159.2468 - MSE: 159.2468 - val_loss: 174.8185 - val_MSE: 174.8185\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 120.44279\n",
      "Epoch 466/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 115.6279 - MSE: 115.6279 - val_loss: 141.2438 - val_MSE: 141.2438\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 120.44279\n",
      "Epoch 467/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 95.1009 - MSE: 95.1009 - val_loss: 112.3237 - val_MSE: 112.3237\n",
      "\n",
      "Epoch 00467: val_loss improved from 120.44279 to 112.32374, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 468/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 114.8736 - MSE: 114.8736 - val_loss: 164.9747 - val_MSE: 164.9747\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 112.32374\n",
      "Epoch 469/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 136.3627 - MSE: 136.3627 - val_loss: 155.9846 - val_MSE: 155.9846\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 112.32374\n",
      "Epoch 470/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 80.4659 - MSE: 80.4659 - val_loss: 127.2777 - val_MSE: 127.2777\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 112.32374\n",
      "Epoch 471/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 8ms/step - loss: 138.1652 - MSE: 138.1652 - val_loss: 137.2661 - val_MSE: 137.2661\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 112.32374\n",
      "Epoch 472/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 137.9791 - MSE: 137.9791 - val_loss: 162.3009 - val_MSE: 162.3009\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 112.32374\n",
      "Epoch 473/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 165.1283 - MSE: 165.1283 - val_loss: 169.9800 - val_MSE: 169.9800\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 112.32374\n",
      "Epoch 474/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 133.7392 - MSE: 133.7392 - val_loss: 153.2080 - val_MSE: 153.2080\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 112.32374\n",
      "Epoch 475/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 71.9066 - MSE: 71.9066 - val_loss: 163.1608 - val_MSE: 163.1608\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 112.32374\n",
      "Epoch 476/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 124.8377 - MSE: 124.8377 - val_loss: 138.3757 - val_MSE: 138.3757\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 112.32374\n",
      "Epoch 477/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 115.3314 - MSE: 115.3314 - val_loss: 112.0543 - val_MSE: 112.0543\n",
      "\n",
      "Epoch 00477: val_loss improved from 112.32374 to 112.05428, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 478/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 100.2109 - MSE: 100.2109 - val_loss: 178.3527 - val_MSE: 178.3527\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 112.05428\n",
      "Epoch 479/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 146.1806 - MSE: 146.1806 - val_loss: 162.9448 - val_MSE: 162.9448\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 112.05428\n",
      "Epoch 480/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 109.4561 - MSE: 109.4561 - val_loss: 163.1938 - val_MSE: 163.1938\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 112.05428\n",
      "Epoch 481/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 156.0035 - MSE: 156.0035 - val_loss: 164.8450 - val_MSE: 164.8450\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 112.05428\n",
      "Epoch 482/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 131.4778 - MSE: 131.4778 - val_loss: 163.8208 - val_MSE: 163.8208\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 112.05428\n",
      "Epoch 483/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 171.1585 - MSE: 171.1585 - val_loss: 197.2805 - val_MSE: 197.2805\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 112.05428\n",
      "Epoch 484/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 129.4223 - MSE: 129.4223 - val_loss: 131.6429 - val_MSE: 131.6429\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 112.05428\n",
      "Epoch 485/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 131.5475 - MSE: 131.5475 - val_loss: 144.5737 - val_MSE: 144.5737\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 112.05428\n",
      "Epoch 486/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 103.3148 - MSE: 103.3148 - val_loss: 142.3834 - val_MSE: 142.3834\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 112.05428\n",
      "Epoch 487/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 129.5318 - MSE: 129.5318 - val_loss: 138.8752 - val_MSE: 138.8752\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 112.05428\n",
      "Epoch 488/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 106.5855 - MSE: 106.5855 - val_loss: 159.1797 - val_MSE: 159.1797\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 112.05428\n",
      "Epoch 489/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 86.9656 - MSE: 86.9656 - val_loss: 131.7257 - val_MSE: 131.7257\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 112.05428\n",
      "Epoch 490/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 83.6005 - MSE: 83.6005 - val_loss: 201.0063 - val_MSE: 201.0063\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 112.05428\n",
      "Epoch 491/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 83.0249 - MSE: 83.0249 - val_loss: 215.0130 - val_MSE: 215.0130\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 112.05428\n",
      "Epoch 492/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 130.6660 - MSE: 130.6660 - val_loss: 136.1506 - val_MSE: 136.1506\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 112.05428\n",
      "Epoch 493/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 87.5209 - MSE: 87.5209 - val_loss: 155.9903 - val_MSE: 155.9903\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 112.05428\n",
      "Epoch 494/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 94.0679 - MSE: 94.0679 - val_loss: 166.7302 - val_MSE: 166.7302\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 112.05428\n",
      "Epoch 495/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 118.4820 - MSE: 118.4820 - val_loss: 178.1404 - val_MSE: 178.1404\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 112.05428\n",
      "Epoch 496/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 151.7994 - MSE: 151.7994 - val_loss: 155.5028 - val_MSE: 155.5028\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 112.05428\n",
      "Epoch 497/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 103.3854 - MSE: 103.3854 - val_loss: 181.2798 - val_MSE: 181.2798\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 112.05428\n",
      "Epoch 498/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 152.0869 - MSE: 152.0869 - val_loss: 177.0427 - val_MSE: 177.0427\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 112.05428\n",
      "Epoch 499/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 86.5618 - MSE: 86.5618 - val_loss: 295.0305 - val_MSE: 295.0305\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 112.05428\n",
      "Epoch 500/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 166.1381 - MSE: 166.1381 - val_loss: 183.4932 - val_MSE: 183.4932\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 112.05428\n",
      "Epoch 501/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 108.4059 - MSE: 108.4059 - val_loss: 140.6160 - val_MSE: 140.6160\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 112.05428\n",
      "Epoch 502/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 116.3179 - MSE: 116.3179 - val_loss: 122.0685 - val_MSE: 122.0685\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 112.05428\n",
      "Epoch 503/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 104.7433 - MSE: 104.7433 - val_loss: 133.9986 - val_MSE: 133.9986\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 112.05428\n",
      "Epoch 504/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 106.1299 - MSE: 106.1299 - val_loss: 183.7830 - val_MSE: 183.7830\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 112.05428\n",
      "Epoch 505/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 120.4799 - MSE: 120.4799 - val_loss: 133.0551 - val_MSE: 133.0551\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 112.05428\n",
      "Epoch 506/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 100.1228 - MSE: 100.1228 - val_loss: 133.4708 - val_MSE: 133.4708\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 112.05428\n",
      "Epoch 507/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 98.3393 - MSE: 98.3393 - val_loss: 147.9481 - val_MSE: 147.9481\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 112.05428\n",
      "Epoch 508/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 113.9790 - MSE: 113.9790 - val_loss: 256.4060 - val_MSE: 256.4060\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 112.05428\n",
      "Epoch 509/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 262.1192 - MSE: 262.1192 - val_loss: 317.4999 - val_MSE: 317.4999\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 112.05428\n",
      "Epoch 510/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 297.6898 - MSE: 297.6898 - val_loss: 205.4543 - val_MSE: 205.4543\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 112.05428\n",
      "Epoch 511/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 152.0602 - MSE: 152.0602 - val_loss: 179.2428 - val_MSE: 179.2428\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 112.05428\n",
      "Epoch 512/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 7ms/step - loss: 147.5207 - MSE: 147.5207 - val_loss: 195.2802 - val_MSE: 195.2802\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 112.05428\n",
      "Epoch 513/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 134.5910 - MSE: 134.5910 - val_loss: 179.2139 - val_MSE: 179.2139\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 112.05428\n",
      "Epoch 514/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 104.4558 - MSE: 104.4558 - val_loss: 170.3941 - val_MSE: 170.3941\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 112.05428\n",
      "Epoch 515/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 109.4502 - MSE: 109.4502 - val_loss: 275.8244 - val_MSE: 275.8244\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 112.05428\n",
      "Epoch 516/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 247.5867 - MSE: 247.5867 - val_loss: 216.8529 - val_MSE: 216.8529\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 112.05428\n",
      "Epoch 517/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 185.6904 - MSE: 185.6904 - val_loss: 156.2981 - val_MSE: 156.2981\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 112.05428\n",
      "Epoch 518/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 137.4977 - MSE: 137.4977 - val_loss: 140.7306 - val_MSE: 140.7306\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 112.05428\n",
      "Epoch 519/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 193.2149 - MSE: 193.2149 - val_loss: 163.4174 - val_MSE: 163.4174\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 112.05428\n",
      "Epoch 520/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 112.6367 - MSE: 112.6367 - val_loss: 194.9153 - val_MSE: 194.9153\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 112.05428\n",
      "Epoch 521/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 225.7784 - MSE: 225.7784 - val_loss: 156.3043 - val_MSE: 156.3043\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 112.05428\n",
      "Epoch 522/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 108.7025 - MSE: 108.7025 - val_loss: 183.3709 - val_MSE: 183.3709\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 112.05428\n",
      "Epoch 523/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 145.2496 - MSE: 145.2496 - val_loss: 153.6541 - val_MSE: 153.6541\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 112.05428\n",
      "Epoch 524/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 175.5005 - MSE: 175.5005 - val_loss: 295.0551 - val_MSE: 295.0551\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 112.05428\n",
      "Epoch 525/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 202.8006 - MSE: 202.8006 - val_loss: 183.7222 - val_MSE: 183.7222\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 112.05428\n",
      "Epoch 526/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 103.4059 - MSE: 103.4059 - val_loss: 123.6694 - val_MSE: 123.6694\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 112.05428\n",
      "Epoch 527/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 89.3850 - MSE: 89.3850 - val_loss: 148.1137 - val_MSE: 148.1137\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 112.05428\n",
      "Epoch 528/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 115.6433 - MSE: 115.6433 - val_loss: 174.2529 - val_MSE: 174.2529\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 112.05428\n",
      "Epoch 529/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 120.1483 - MSE: 120.1483 - val_loss: 172.5593 - val_MSE: 172.5593\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 112.05428\n",
      "Epoch 530/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 100.1918 - MSE: 100.1918 - val_loss: 187.5212 - val_MSE: 187.5212\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 112.05428\n",
      "Epoch 531/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 114.7573 - MSE: 114.7573 - val_loss: 170.5575 - val_MSE: 170.5575\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 112.05428\n",
      "Epoch 532/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 122.5349 - MSE: 122.5349 - val_loss: 160.1107 - val_MSE: 160.1107\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 112.05428\n",
      "Epoch 533/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 157.8152 - MSE: 157.8152 - val_loss: 149.8137 - val_MSE: 149.8137\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 112.05428\n",
      "Epoch 534/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 158.1171 - MSE: 158.1171 - val_loss: 145.6942 - val_MSE: 145.6942\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 112.05428\n",
      "Epoch 535/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 74.6121 - MSE: 74.6121 - val_loss: 101.6962 - val_MSE: 101.6962\n",
      "\n",
      "Epoch 00535: val_loss improved from 112.05428 to 101.69615, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 536/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 145.3087 - MSE: 145.3087 - val_loss: 144.3449 - val_MSE: 144.3449\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 101.69615\n",
      "Epoch 537/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 115.4945 - MSE: 115.4945 - val_loss: 146.3210 - val_MSE: 146.3210\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 101.69615\n",
      "Epoch 538/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 105.9013 - MSE: 105.9013 - val_loss: 155.0167 - val_MSE: 155.0167\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 101.69615\n",
      "Epoch 539/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 122.8418 - MSE: 122.8418 - val_loss: 119.5759 - val_MSE: 119.5759\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 101.69615\n",
      "Epoch 540/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 136.2538 - MSE: 136.2538 - val_loss: 158.0855 - val_MSE: 158.0855\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 101.69615\n",
      "Epoch 541/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 112.3525 - MSE: 112.3525 - val_loss: 118.9539 - val_MSE: 118.9539\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 101.69615\n",
      "Epoch 542/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 90.7544 - MSE: 90.7544 - val_loss: 119.5884 - val_MSE: 119.5884\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 101.69615\n",
      "Epoch 543/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 80.2431 - MSE: 80.2431 - val_loss: 114.1176 - val_MSE: 114.1176\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 101.69615\n",
      "Epoch 544/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 70.9831 - MSE: 70.9831 - val_loss: 206.2537 - val_MSE: 206.2537\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 101.69615\n",
      "Epoch 545/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 95.9486 - MSE: 95.9486 - val_loss: 134.5824 - val_MSE: 134.5824\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 101.69615\n",
      "Epoch 546/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 97.3330 - MSE: 97.3330 - val_loss: 123.0972 - val_MSE: 123.0972\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 101.69615\n",
      "Epoch 547/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 82.7991 - MSE: 82.7991 - val_loss: 151.8060 - val_MSE: 151.8060\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 101.69615\n",
      "Epoch 548/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 98.0728 - MSE: 98.0728 - val_loss: 111.6964 - val_MSE: 111.6964\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 101.69615\n",
      "Epoch 549/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 128.4510 - MSE: 128.4510 - val_loss: 174.9250 - val_MSE: 174.9250\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 101.69615\n",
      "Epoch 550/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 145.4295 - MSE: 145.4295 - val_loss: 133.1559 - val_MSE: 133.1559\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 101.69615\n",
      "Epoch 551/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 104.3941 - MSE: 104.3941 - val_loss: 158.6293 - val_MSE: 158.6293\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 101.69615\n",
      "Epoch 552/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 97.4721 - MSE: 97.4721 - val_loss: 142.1145 - val_MSE: 142.1145\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 101.69615\n",
      "Epoch 553/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 8ms/step - loss: 79.4413 - MSE: 79.4413 - val_loss: 138.7247 - val_MSE: 138.7247\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 101.69615\n",
      "Epoch 554/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 109.7088 - MSE: 109.7088 - val_loss: 124.3061 - val_MSE: 124.3061\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 101.69615\n",
      "Epoch 555/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 110.7055 - MSE: 110.7055 - val_loss: 150.8133 - val_MSE: 150.8133\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 101.69615\n",
      "Epoch 556/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 111.0482 - MSE: 111.0482 - val_loss: 124.2143 - val_MSE: 124.2143\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 101.69615\n",
      "Epoch 557/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 65.9809 - MSE: 65.9809 - val_loss: 144.3306 - val_MSE: 144.3306\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 101.69615\n",
      "Epoch 558/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 110.0805 - MSE: 110.0805 - val_loss: 144.0210 - val_MSE: 144.0210\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 101.69615\n",
      "Epoch 559/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 122.6471 - MSE: 122.6471 - val_loss: 179.0416 - val_MSE: 179.0416\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 101.69615\n",
      "Epoch 560/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 96.3681 - MSE: 96.3681 - val_loss: 122.7583 - val_MSE: 122.7583\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 101.69615\n",
      "Epoch 561/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 119.1080 - MSE: 119.1080 - val_loss: 91.6179 - val_MSE: 91.6179\n",
      "\n",
      "Epoch 00561: val_loss improved from 101.69615 to 91.61790, saving model to E:\\Study\\Ph.D\\Publication\\EDL\\ML modelling related files3D32_2d64_relu_ALL.h5\n",
      "Epoch 562/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 110.9438 - MSE: 110.9438 - val_loss: 112.8958 - val_MSE: 112.8958\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 91.61790\n",
      "Epoch 563/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 92.0760 - MSE: 92.0760 - val_loss: 137.0248 - val_MSE: 137.0248\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 91.61790\n",
      "Epoch 564/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 62.7708 - MSE: 62.7708 - val_loss: 111.8413 - val_MSE: 111.8413\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 91.61790\n",
      "Epoch 565/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 198.8892 - MSE: 198.8892 - val_loss: 222.9124 - val_MSE: 222.9124\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 91.61790\n",
      "Epoch 566/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 208.9982 - MSE: 208.9982 - val_loss: 200.1293 - val_MSE: 200.1293\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 91.61790\n",
      "Epoch 567/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 128.5457 - MSE: 128.5457 - val_loss: 146.0168 - val_MSE: 146.0168\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 91.61790\n",
      "Epoch 568/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 115.7916 - MSE: 115.7916 - val_loss: 141.4889 - val_MSE: 141.4889\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 91.61790\n",
      "Epoch 569/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 161.8974 - MSE: 161.8974 - val_loss: 123.8032 - val_MSE: 123.8032\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 91.61790\n",
      "Epoch 570/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 83.9343 - MSE: 83.9343 - val_loss: 149.6130 - val_MSE: 149.6130\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 91.61790\n",
      "Epoch 571/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 107.7739 - MSE: 107.7739 - val_loss: 170.5543 - val_MSE: 170.5543\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 91.61790\n",
      "Epoch 572/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 84.7050 - MSE: 84.7050 - val_loss: 145.5087 - val_MSE: 145.5087\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 91.61790\n",
      "Epoch 573/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 236.7495 - MSE: 236.7495 - val_loss: 169.1775 - val_MSE: 169.1775\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 91.61790\n",
      "Epoch 574/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 175.0816 - MSE: 175.0816 - val_loss: 184.4092 - val_MSE: 184.4092\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 91.61790\n",
      "Epoch 575/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 173.2659 - MSE: 173.2659 - val_loss: 181.3784 - val_MSE: 181.3784\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 91.61790\n",
      "Epoch 576/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 204.4336 - MSE: 204.4336 - val_loss: 190.7167 - val_MSE: 190.7167\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 91.61790\n",
      "Epoch 577/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 129.8110 - MSE: 129.8110 - val_loss: 153.7403 - val_MSE: 153.7403\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 91.61790\n",
      "Epoch 578/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 102.0374 - MSE: 102.0374 - val_loss: 164.1825 - val_MSE: 164.1825\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 91.61790\n",
      "Epoch 579/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 115.7175 - MSE: 115.7175 - val_loss: 170.2627 - val_MSE: 170.2627\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 91.61790\n",
      "Epoch 580/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 105.8923 - MSE: 105.8923 - val_loss: 147.9985 - val_MSE: 147.9985\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 91.61790\n",
      "Epoch 581/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 130.2563 - MSE: 130.2563 - val_loss: 153.2238 - val_MSE: 153.2238\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 91.61790\n",
      "Epoch 582/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 148.1452 - MSE: 148.1452 - val_loss: 176.7401 - val_MSE: 176.7401\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 91.61790\n",
      "Epoch 583/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 192.8965 - MSE: 192.8965 - val_loss: 146.3594 - val_MSE: 146.3594\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 91.61790\n",
      "Epoch 584/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 137.2073 - MSE: 137.2073 - val_loss: 153.9005 - val_MSE: 153.9005\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 91.61790\n",
      "Epoch 585/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 114.3085 - MSE: 114.3085 - val_loss: 156.0946 - val_MSE: 156.0946\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 91.61790\n",
      "Epoch 586/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 92.0505 - MSE: 92.0505 - val_loss: 129.8515 - val_MSE: 129.8515\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 91.61790\n",
      "Epoch 587/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 124.7494 - MSE: 124.7494 - val_loss: 171.4647 - val_MSE: 171.4647\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 91.61790\n",
      "Epoch 588/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 80.4645 - MSE: 80.4645 - val_loss: 176.7673 - val_MSE: 176.7673\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 91.61790\n",
      "Epoch 589/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 122.1923 - MSE: 122.1923 - val_loss: 145.1553 - val_MSE: 145.1553\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 91.61790\n",
      "Epoch 590/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 121.0830 - MSE: 121.0830 - val_loss: 160.1319 - val_MSE: 160.1319\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 91.61790\n",
      "Epoch 591/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 176.7311 - MSE: 176.7311 - val_loss: 175.7274 - val_MSE: 175.7274\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 91.61790\n",
      "Epoch 592/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 128.3815 - MSE: 128.3815 - val_loss: 140.3793 - val_MSE: 140.3793\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 91.61790\n",
      "Epoch 593/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 111.8080 - MSE: 111.8080 - val_loss: 145.4227 - val_MSE: 145.4227\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 91.61790\n",
      "Epoch 594/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 8ms/step - loss: 94.6276 - MSE: 94.6276 - val_loss: 167.1690 - val_MSE: 167.1690\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 91.61790\n",
      "Epoch 595/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 101.5462 - MSE: 101.5462 - val_loss: 145.4956 - val_MSE: 145.4956\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 91.61790\n",
      "Epoch 596/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 80.8174 - MSE: 80.8174 - val_loss: 153.9274 - val_MSE: 153.9274\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 91.61790\n",
      "Epoch 597/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 109.6224 - MSE: 109.6224 - val_loss: 163.5374 - val_MSE: 163.5374\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 91.61790\n",
      "Epoch 598/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 98.9934 - MSE: 98.9934 - val_loss: 143.2254 - val_MSE: 143.2254\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 91.61790\n",
      "Epoch 599/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 136.3781 - MSE: 136.3781 - val_loss: 198.1003 - val_MSE: 198.1003\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 91.61790\n",
      "Epoch 600/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 156.3188 - MSE: 156.3188 - val_loss: 192.4181 - val_MSE: 192.4181\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 91.61790\n",
      "Epoch 601/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117.8018 - MSE: 117.8018 - val_loss: 188.8848 - val_MSE: 188.8848\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 91.61790\n",
      "Epoch 602/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 135.6146 - MSE: 135.6146 - val_loss: 152.7368 - val_MSE: 152.7368\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 91.61790\n",
      "Epoch 603/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 135.6255 - MSE: 135.6255 - val_loss: 169.4639 - val_MSE: 169.4639\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 91.61790\n",
      "Epoch 604/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 92.9402 - MSE: 92.9402 - val_loss: 151.2741 - val_MSE: 151.2741\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 91.61790\n",
      "Epoch 605/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 114.2466 - MSE: 114.2466 - val_loss: 162.7503 - val_MSE: 162.7503\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 91.61790\n",
      "Epoch 606/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 133.3032 - MSE: 133.3032 - val_loss: 161.5182 - val_MSE: 161.5182\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 91.61790\n",
      "Epoch 607/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 133.1845 - MSE: 133.1845 - val_loss: 156.4502 - val_MSE: 156.4502\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 91.61790\n",
      "Epoch 608/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 119.0165 - MSE: 119.0165 - val_loss: 155.6340 - val_MSE: 155.6340\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 91.61790\n",
      "Epoch 609/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 85.2165 - MSE: 85.2165 - val_loss: 146.3275 - val_MSE: 146.3275\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 91.61790\n",
      "Epoch 610/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 97.9931 - MSE: 97.9931 - val_loss: 157.7451 - val_MSE: 157.7451\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 91.61790\n",
      "Epoch 611/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 119.3456 - MSE: 119.3456 - val_loss: 154.0799 - val_MSE: 154.0799\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 91.61790\n",
      "Epoch 612/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 133.9539 - MSE: 133.9539 - val_loss: 152.8510 - val_MSE: 152.8510\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 91.61790\n",
      "Epoch 613/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 124.4102 - MSE: 124.4102 - val_loss: 126.4545 - val_MSE: 126.4545\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 91.61790\n",
      "Epoch 614/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 87.6574 - MSE: 87.6574 - val_loss: 205.8110 - val_MSE: 205.8110\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 91.61790\n",
      "Epoch 615/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 139.3490 - MSE: 139.3490 - val_loss: 156.9259 - val_MSE: 156.9259\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 91.61790\n",
      "Epoch 616/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 120.8321 - MSE: 120.8321 - val_loss: 172.1902 - val_MSE: 172.1902\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 91.61790\n",
      "Epoch 617/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 133.9870 - MSE: 133.9870 - val_loss: 136.4445 - val_MSE: 136.4445\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 91.61790\n",
      "Epoch 618/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 102.0521 - MSE: 102.0521 - val_loss: 258.4687 - val_MSE: 258.4687\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 91.61790\n",
      "Epoch 619/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 81.7125 - MSE: 81.7125 - val_loss: 137.2636 - val_MSE: 137.2636\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 91.61790\n",
      "Epoch 620/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 112.3245 - MSE: 112.3245 - val_loss: 168.8110 - val_MSE: 168.8110\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 91.61790\n",
      "Epoch 621/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 111.8344 - MSE: 111.8344 - val_loss: 165.9018 - val_MSE: 165.9018\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 91.61790\n",
      "Epoch 622/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 118.6971 - MSE: 118.6971 - val_loss: 154.5943 - val_MSE: 154.5943\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 91.61790\n",
      "Epoch 623/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 93.6976 - MSE: 93.6976 - val_loss: 176.1879 - val_MSE: 176.1879\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 91.61790\n",
      "Epoch 624/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 70.2300 - MSE: 70.2300 - val_loss: 141.6659 - val_MSE: 141.6659\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 91.61790\n",
      "Epoch 625/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 136.8305 - MSE: 136.8305 - val_loss: 137.3739 - val_MSE: 137.3739\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 91.61790\n",
      "Epoch 626/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 110.4535 - MSE: 110.4535 - val_loss: 117.7944 - val_MSE: 117.7944\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 91.61790\n",
      "Epoch 627/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117.3128 - MSE: 117.3128 - val_loss: 122.0634 - val_MSE: 122.0634\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 91.61790\n",
      "Epoch 628/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 48.5469 - MSE: 48.5469 - val_loss: 248.0660 - val_MSE: 248.0660\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 91.61790\n",
      "Epoch 629/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 183.5750 - MSE: 183.5750 - val_loss: 145.2726 - val_MSE: 145.2726\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 91.61790\n",
      "Epoch 630/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 126.9436 - MSE: 126.9436 - val_loss: 167.3587 - val_MSE: 167.3587\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 91.61790\n",
      "Epoch 631/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 169.0207 - MSE: 169.0207 - val_loss: 244.0994 - val_MSE: 244.0994\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 91.61790\n",
      "Epoch 632/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 104.2843 - MSE: 104.2843 - val_loss: 155.9650 - val_MSE: 155.9650\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 91.61790\n",
      "Epoch 633/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117.0094 - MSE: 117.0094 - val_loss: 127.4625 - val_MSE: 127.4625\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 91.61790\n",
      "Epoch 634/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 100.4815 - MSE: 100.4815 - val_loss: 158.2815 - val_MSE: 158.2815\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 91.61790\n",
      "Epoch 635/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 57.8677 - MSE: 57.8677 - val_loss: 212.6934 - val_MSE: 212.6934\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 91.61790\n",
      "Epoch 636/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 8ms/step - loss: 94.0869 - MSE: 94.0869 - val_loss: 106.1966 - val_MSE: 106.1966\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 91.61790\n",
      "Epoch 637/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 92.9993 - MSE: 92.9993 - val_loss: 130.9310 - val_MSE: 130.9310\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 91.61790\n",
      "Epoch 638/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 107.7412 - MSE: 107.7412 - val_loss: 177.6373 - val_MSE: 177.6373\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 91.61790\n",
      "Epoch 639/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 137.9093 - MSE: 137.9093 - val_loss: 119.7856 - val_MSE: 119.7856\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 91.61790\n",
      "Epoch 640/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 132.0342 - MSE: 132.0342 - val_loss: 144.1562 - val_MSE: 144.1562\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 91.61790\n",
      "Epoch 641/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 113.5753 - MSE: 113.5753 - val_loss: 152.9543 - val_MSE: 152.9543\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 91.61790\n",
      "Epoch 642/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 86.1865 - MSE: 86.1865 - val_loss: 122.3324 - val_MSE: 122.3324\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 91.61790\n",
      "Epoch 643/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 96.9582 - MSE: 96.9582 - val_loss: 164.0217 - val_MSE: 164.0217\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 91.61790\n",
      "Epoch 644/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 74.4249 - MSE: 74.4249 - val_loss: 151.4889 - val_MSE: 151.4889\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 91.61790\n",
      "Epoch 645/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 141.4175 - MSE: 141.4175 - val_loss: 221.5612 - val_MSE: 221.5612\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 91.61790\n",
      "Epoch 646/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 115.8548 - MSE: 115.8548 - val_loss: 137.0566 - val_MSE: 137.0566\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 91.61790\n",
      "Epoch 647/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 87.8386 - MSE: 87.8386 - val_loss: 113.2218 - val_MSE: 113.2218\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 91.61790\n",
      "Epoch 648/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 63.6355 - MSE: 63.6355 - val_loss: 205.2559 - val_MSE: 205.2559\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 91.61790\n",
      "Epoch 649/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 164.3256 - MSE: 164.3256 - val_loss: 140.7485 - val_MSE: 140.7485\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 91.61790\n",
      "Epoch 650/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 75.8444 - MSE: 75.8444 - val_loss: 110.7863 - val_MSE: 110.7863\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 91.61790\n",
      "Epoch 651/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 115.7890 - MSE: 115.7890 - val_loss: 157.5528 - val_MSE: 157.5528\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 91.61790\n",
      "Epoch 652/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 84.1200 - MSE: 84.1200 - val_loss: 135.4983 - val_MSE: 135.4983\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 91.61790\n",
      "Epoch 653/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 98.6858 - MSE: 98.6858 - val_loss: 107.6006 - val_MSE: 107.6006\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 91.61790\n",
      "Epoch 654/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 82.7514 - MSE: 82.7514 - val_loss: 106.5917 - val_MSE: 106.5917\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 91.61790\n",
      "Epoch 655/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 96.9986 - MSE: 96.9986 - val_loss: 137.3643 - val_MSE: 137.3643\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 91.61790\n",
      "Epoch 656/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 75.9357 - MSE: 75.9357 - val_loss: 152.2615 - val_MSE: 152.2615\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 91.61790\n",
      "Epoch 657/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 111.5381 - MSE: 111.5381 - val_loss: 111.9537 - val_MSE: 111.9537\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 91.61790\n",
      "Epoch 658/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 92.7400 - MSE: 92.7400 - val_loss: 136.3451 - val_MSE: 136.3451\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 91.61790\n",
      "Epoch 659/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 83.1260 - MSE: 83.1260 - val_loss: 142.9872 - val_MSE: 142.9872\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 91.61790\n",
      "Epoch 660/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 91.4545 - MSE: 91.4545 - val_loss: 112.6360 - val_MSE: 112.6360\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 91.61790\n",
      "Epoch 661/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 80.3489 - MSE: 80.3489 - val_loss: 154.0820 - val_MSE: 154.0820\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 91.61790\n",
      "Epoch 662/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 174.8742 - MSE: 174.8742 - val_loss: 190.6751 - val_MSE: 190.6751\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 91.61790\n",
      "Epoch 663/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 141.7089 - MSE: 141.7089 - val_loss: 182.2738 - val_MSE: 182.2738\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 91.61790\n",
      "Epoch 664/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 122.5834 - MSE: 122.5834 - val_loss: 178.1165 - val_MSE: 178.1165\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 91.61790\n",
      "Epoch 665/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 92.4365 - MSE: 92.4365 - val_loss: 152.8324 - val_MSE: 152.8324\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 91.61790\n",
      "Epoch 666/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 59.5348 - MSE: 59.5348 - val_loss: 258.3349 - val_MSE: 258.3349\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 91.61790\n",
      "Epoch 667/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 212.7565 - MSE: 212.7565 - val_loss: 175.1079 - val_MSE: 175.1079\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 91.61790\n",
      "Epoch 668/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 132.4936 - MSE: 132.4936 - val_loss: 174.0925 - val_MSE: 174.0925\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 91.61790\n",
      "Epoch 669/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 124.4013 - MSE: 124.4013 - val_loss: 127.8156 - val_MSE: 127.8156\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 91.61790\n",
      "Epoch 670/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 54.2542 - MSE: 54.2542 - val_loss: 133.8062 - val_MSE: 133.8062\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 91.61790\n",
      "Epoch 671/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117.8801 - MSE: 117.8801 - val_loss: 162.2484 - val_MSE: 162.2484\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 91.61790\n",
      "Epoch 672/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 156.7544 - MSE: 156.7544 - val_loss: 134.4414 - val_MSE: 134.4414\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 91.61790\n",
      "Epoch 673/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 102.4803 - MSE: 102.4803 - val_loss: 175.1269 - val_MSE: 175.1269\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 91.61790\n",
      "Epoch 674/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 86.3676 - MSE: 86.3676 - val_loss: 146.3864 - val_MSE: 146.3864\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 91.61790\n",
      "Epoch 675/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 74.8039 - MSE: 74.8039 - val_loss: 186.1504 - val_MSE: 186.1504\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 91.61790\n",
      "Epoch 676/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 95.8846 - MSE: 95.8846 - val_loss: 222.4523 - val_MSE: 222.4523\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 91.61790\n",
      "Epoch 677/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 169.1161 - MSE: 169.1161 - val_loss: 169.6307 - val_MSE: 169.6307\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 91.61790\n",
      "Epoch 678/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 8ms/step - loss: 113.0685 - MSE: 113.0685 - val_loss: 125.3150 - val_MSE: 125.3150\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 91.61790\n",
      "Epoch 679/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 49.4758 - MSE: 49.4758 - val_loss: 125.0898 - val_MSE: 125.0898\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 91.61790\n",
      "Epoch 680/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 70.5760 - MSE: 70.5760 - val_loss: 114.3706 - val_MSE: 114.3706\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 91.61790\n",
      "Epoch 681/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 89.2677 - MSE: 89.2677 - val_loss: 178.1401 - val_MSE: 178.1401\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 91.61790\n",
      "Epoch 682/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 91.6430 - MSE: 91.6430 - val_loss: 206.8882 - val_MSE: 206.8882\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 91.61790\n",
      "Epoch 683/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 85.9519 - MSE: 85.9519 - val_loss: 203.5734 - val_MSE: 203.5734\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 91.61790\n",
      "Epoch 684/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 165.6433 - MSE: 165.6433 - val_loss: 157.0037 - val_MSE: 157.0037\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 91.61790\n",
      "Epoch 685/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 106.3081 - MSE: 106.3081 - val_loss: 153.4788 - val_MSE: 153.4788\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 91.61790\n",
      "Epoch 686/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 105.6628 - MSE: 105.6628 - val_loss: 162.8139 - val_MSE: 162.8139\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 91.61790\n",
      "Epoch 687/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 89.3051 - MSE: 89.3051 - val_loss: 153.7386 - val_MSE: 153.7386\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 91.61790\n",
      "Epoch 688/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 88.5921 - MSE: 88.5921 - val_loss: 138.1628 - val_MSE: 138.1628\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 91.61790\n",
      "Epoch 689/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 127.4289 - MSE: 127.4289 - val_loss: 164.6454 - val_MSE: 164.6454\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 91.61790\n",
      "Epoch 690/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 79.9893 - MSE: 79.9893 - val_loss: 145.9546 - val_MSE: 145.9546\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 91.61790\n",
      "Epoch 691/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 60.3099 - MSE: 60.3099 - val_loss: 156.2299 - val_MSE: 156.2299\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 91.61790\n",
      "Epoch 692/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 122.1127 - MSE: 122.1127 - val_loss: 155.2789 - val_MSE: 155.2789\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 91.61790\n",
      "Epoch 693/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 66.2844 - MSE: 66.2844 - val_loss: 144.0194 - val_MSE: 144.0194\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 91.61790\n",
      "Epoch 694/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 88.6037 - MSE: 88.6037 - val_loss: 156.5630 - val_MSE: 156.5630\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 91.61790\n",
      "Epoch 695/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 145.7410 - MSE: 145.7410 - val_loss: 162.4776 - val_MSE: 162.4776\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 91.61790\n",
      "Epoch 696/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 188.4170 - MSE: 188.4170 - val_loss: 159.5998 - val_MSE: 159.5998\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 91.61790\n",
      "Epoch 697/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 133.7583 - MSE: 133.7583 - val_loss: 286.3386 - val_MSE: 286.3386\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 91.61790\n",
      "Epoch 698/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 234.0005 - MSE: 234.0005 - val_loss: 151.4049 - val_MSE: 151.4049\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 91.61790\n",
      "Epoch 699/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 111.8832 - MSE: 111.8832 - val_loss: 161.6788 - val_MSE: 161.6788\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 91.61790\n",
      "Epoch 700/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 102.1335 - MSE: 102.1335 - val_loss: 170.2761 - val_MSE: 170.2761\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 91.61790\n",
      "Epoch 701/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 102.8796 - MSE: 102.8796 - val_loss: 138.5003 - val_MSE: 138.5003\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 91.61790\n",
      "Epoch 702/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 128.2414 - MSE: 128.2414 - val_loss: 160.2650 - val_MSE: 160.2650\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 91.61790\n",
      "Epoch 703/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 84.6516 - MSE: 84.6516 - val_loss: 164.4634 - val_MSE: 164.4634\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 91.61790\n",
      "Epoch 704/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 134.6007 - MSE: 134.6007 - val_loss: 148.8424 - val_MSE: 148.8424\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 91.61790\n",
      "Epoch 705/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 161.4481 - MSE: 161.4481 - val_loss: 156.5180 - val_MSE: 156.5180\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 91.61790\n",
      "Epoch 706/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 147.9798 - MSE: 147.9798 - val_loss: 153.9110 - val_MSE: 153.9110\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 91.61790\n",
      "Epoch 707/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 128.5574 - MSE: 128.5574 - val_loss: 163.0098 - val_MSE: 163.0098\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 91.61790\n",
      "Epoch 708/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 149.6442 - MSE: 149.6442 - val_loss: 379.2792 - val_MSE: 379.2792\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 91.61790\n",
      "Epoch 709/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 256.7413 - MSE: 256.7413 - val_loss: 177.2582 - val_MSE: 177.2582\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 91.61790\n",
      "Epoch 710/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 210.5253 - MSE: 210.5253 - val_loss: 182.2694 - val_MSE: 182.2694\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 91.61790\n",
      "Epoch 711/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 126.0549 - MSE: 126.0549 - val_loss: 167.3731 - val_MSE: 167.3731\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 91.61790\n",
      "Epoch 712/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 86.6911 - MSE: 86.6911 - val_loss: 153.8306 - val_MSE: 153.8306\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 91.61790\n",
      "Epoch 713/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 55.4343 - MSE: 55.4343 - val_loss: 163.4765 - val_MSE: 163.4765\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 91.61790\n",
      "Epoch 714/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 122.4449 - MSE: 122.4449 - val_loss: 170.1687 - val_MSE: 170.1687\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 91.61790\n",
      "Epoch 715/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 106.0080 - MSE: 106.0080 - val_loss: 138.2227 - val_MSE: 138.2227\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 91.61790\n",
      "Epoch 716/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 123.6918 - MSE: 123.6918 - val_loss: 161.5293 - val_MSE: 161.5293\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 91.61790\n",
      "Epoch 717/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 71.7977 - MSE: 71.7977 - val_loss: 140.8153 - val_MSE: 140.8153\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 91.61790\n",
      "Epoch 718/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 123.0136 - MSE: 123.0136 - val_loss: 151.0278 - val_MSE: 151.0278\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 91.61790\n",
      "Epoch 719/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 121.8138 - MSE: 121.8138 - val_loss: 146.9133 - val_MSE: 146.9133\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 91.61790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 720/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 108.2478 - MSE: 108.2478 - val_loss: 168.9190 - val_MSE: 168.9190\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 91.61790\n",
      "Epoch 721/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 76.2777 - MSE: 76.2777 - val_loss: 160.7515 - val_MSE: 160.7515\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 91.61790\n",
      "Epoch 722/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 88.7981 - MSE: 88.7981 - val_loss: 146.2091 - val_MSE: 146.2091\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 91.61790\n",
      "Epoch 723/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 134.8174 - MSE: 134.8174 - val_loss: 154.4633 - val_MSE: 154.4633\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 91.61790\n",
      "Epoch 724/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 80.8997 - MSE: 80.8997 - val_loss: 161.5347 - val_MSE: 161.5347\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 91.61790\n",
      "Epoch 725/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 154.3457 - MSE: 154.3457 - val_loss: 174.2286 - val_MSE: 174.2286\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 91.61790\n",
      "Epoch 726/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 205.7498 - MSE: 205.7498 - val_loss: 316.1488 - val_MSE: 316.1488\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 91.61790\n",
      "Epoch 727/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 144.1073 - MSE: 144.1073 - val_loss: 185.9231 - val_MSE: 185.9231\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 91.61790\n",
      "Epoch 728/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 118.7000 - MSE: 118.7000 - val_loss: 168.4056 - val_MSE: 168.4056\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 91.61790\n",
      "Epoch 729/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 107.1408 - MSE: 107.1408 - val_loss: 154.6043 - val_MSE: 154.6043\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 91.61790\n",
      "Epoch 730/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 103.9613 - MSE: 103.9613 - val_loss: 148.1643 - val_MSE: 148.1643\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 91.61790\n",
      "Epoch 731/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 55.0296 - MSE: 55.0296 - val_loss: 155.0551 - val_MSE: 155.0551\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 91.61790\n",
      "Epoch 732/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 89.2912 - MSE: 89.2912 - val_loss: 157.7349 - val_MSE: 157.7349\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 91.61790\n",
      "Epoch 733/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 92.5410 - MSE: 92.5410 - val_loss: 161.0376 - val_MSE: 161.0376\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 91.61790\n",
      "Epoch 734/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 79.1655 - MSE: 79.1655 - val_loss: 145.3997 - val_MSE: 145.3997\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 91.61790\n",
      "Epoch 735/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 106.6722 - MSE: 106.6722 - val_loss: 126.9060 - val_MSE: 126.9060\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 91.61790\n",
      "Epoch 736/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 123.7521 - MSE: 123.7521 - val_loss: 136.2742 - val_MSE: 136.2742\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 91.61790\n",
      "Epoch 737/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 202.3894 - MSE: 202.3894 - val_loss: 213.4272 - val_MSE: 213.4272\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 91.61790\n",
      "Epoch 738/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 156.3293 - MSE: 156.3293 - val_loss: 128.4695 - val_MSE: 128.4695\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 91.61790\n",
      "Epoch 739/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 92.0494 - MSE: 92.0494 - val_loss: 169.9472 - val_MSE: 169.9472\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 91.61790\n",
      "Epoch 740/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 131.3221 - MSE: 131.3221 - val_loss: 142.8266 - val_MSE: 142.8266\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 91.61790\n",
      "Epoch 741/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 85.6178 - MSE: 85.6178 - val_loss: 150.6134 - val_MSE: 150.6134\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 91.61790\n",
      "Epoch 742/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 128.4774 - MSE: 128.4774 - val_loss: 163.7027 - val_MSE: 163.7027\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 91.61790\n",
      "Epoch 743/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 59.4161 - MSE: 59.4161 - val_loss: 149.3814 - val_MSE: 149.3814\n",
      "\n",
      "Epoch 00743: val_loss did not improve from 91.61790\n",
      "Epoch 744/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 83.1269 - MSE: 83.1269 - val_loss: 152.8991 - val_MSE: 152.8991\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 91.61790\n",
      "Epoch 745/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 89.2411 - MSE: 89.2411 - val_loss: 168.1217 - val_MSE: 168.1217\n",
      "\n",
      "Epoch 00745: val_loss did not improve from 91.61790\n",
      "Epoch 746/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 109.1297 - MSE: 109.1297 - val_loss: 147.2419 - val_MSE: 147.2419\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 91.61790\n",
      "Epoch 747/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 96.5672 - MSE: 96.5672 - val_loss: 137.5309 - val_MSE: 137.5309\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 91.61790\n",
      "Epoch 748/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 104.6787 - MSE: 104.6787 - val_loss: 192.4353 - val_MSE: 192.4353\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 91.61790\n",
      "Epoch 749/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 126.3872 - MSE: 126.3872 - val_loss: 149.5310 - val_MSE: 149.5310\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 91.61790\n",
      "Epoch 750/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 90.3449 - MSE: 90.3449 - val_loss: 163.8740 - val_MSE: 163.8740\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 91.61790\n",
      "Epoch 751/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 109.3808 - MSE: 109.3808 - val_loss: 165.0309 - val_MSE: 165.0309\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 91.61790\n",
      "Epoch 752/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 104.7697 - MSE: 104.7697 - val_loss: 163.3049 - val_MSE: 163.3049\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 91.61790\n",
      "Epoch 753/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 116.7371 - MSE: 116.7371 - val_loss: 153.2660 - val_MSE: 153.2660\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 91.61790\n",
      "Epoch 754/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 86.3629 - MSE: 86.3629 - val_loss: 146.8687 - val_MSE: 146.8687\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 91.61790\n",
      "Epoch 755/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 114.6856 - MSE: 114.6856 - val_loss: 206.6402 - val_MSE: 206.6402\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 91.61790\n",
      "Epoch 756/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 173.8612 - MSE: 173.8612 - val_loss: 188.2617 - val_MSE: 188.2617\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 91.61790\n",
      "Epoch 757/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 84.6510 - MSE: 84.6510 - val_loss: 168.3009 - val_MSE: 168.3009\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 91.61790\n",
      "Epoch 758/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 93.5336 - MSE: 93.5336 - val_loss: 148.5655 - val_MSE: 148.5655\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 91.61790\n",
      "Epoch 759/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 96.5638 - MSE: 96.5638 - val_loss: 150.9590 - val_MSE: 150.9590\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 91.61790\n",
      "Epoch 760/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 85.3429 - MSE: 85.3429 - val_loss: 141.1910 - val_MSE: 141.1910\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 91.61790\n",
      "Epoch 761/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 116.5594 - MSE: 116.5594 - val_loss: 152.7000 - val_MSE: 152.7000\n",
      "\n",
      "Epoch 00761: val_loss did not improve from 91.61790\n",
      "Epoch 762/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 9ms/step - loss: 87.3386 - MSE: 87.3386 - val_loss: 141.4436 - val_MSE: 141.4436\n",
      "\n",
      "Epoch 00762: val_loss did not improve from 91.61790\n",
      "Epoch 763/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 175.6122 - MSE: 175.6122 - val_loss: 174.1343 - val_MSE: 174.1343\n",
      "\n",
      "Epoch 00763: val_loss did not improve from 91.61790\n",
      "Epoch 764/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 144.6972 - MSE: 144.6972 - val_loss: 154.7485 - val_MSE: 154.7485\n",
      "\n",
      "Epoch 00764: val_loss did not improve from 91.61790\n",
      "Epoch 765/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 103.2382 - MSE: 103.2382 - val_loss: 160.0278 - val_MSE: 160.0278\n",
      "\n",
      "Epoch 00765: val_loss did not improve from 91.61790\n",
      "Epoch 766/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 75.3235 - MSE: 75.3235 - val_loss: 201.7082 - val_MSE: 201.7082\n",
      "\n",
      "Epoch 00766: val_loss did not improve from 91.61790\n",
      "Epoch 767/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 128.8615 - MSE: 128.8615 - val_loss: 198.2897 - val_MSE: 198.2897\n",
      "\n",
      "Epoch 00767: val_loss did not improve from 91.61790\n",
      "Epoch 768/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 163.8886 - MSE: 163.8886 - val_loss: 137.8672 - val_MSE: 137.8672\n",
      "\n",
      "Epoch 00768: val_loss did not improve from 91.61790\n",
      "Epoch 769/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 53.2464 - MSE: 53.2464 - val_loss: 199.3173 - val_MSE: 199.3173\n",
      "\n",
      "Epoch 00769: val_loss did not improve from 91.61790\n",
      "Epoch 770/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 238.7206 - MSE: 238.7206 - val_loss: 187.2759 - val_MSE: 187.2759\n",
      "\n",
      "Epoch 00770: val_loss did not improve from 91.61790\n",
      "Epoch 771/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 176.6382 - MSE: 176.6382 - val_loss: 187.1878 - val_MSE: 187.1878\n",
      "\n",
      "Epoch 00771: val_loss did not improve from 91.61790\n",
      "Epoch 772/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 192.4899 - MSE: 192.4899 - val_loss: 176.4774 - val_MSE: 176.4774\n",
      "\n",
      "Epoch 00772: val_loss did not improve from 91.61790\n",
      "Epoch 773/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 189.8161 - MSE: 189.8161 - val_loss: 252.3350 - val_MSE: 252.3350\n",
      "\n",
      "Epoch 00773: val_loss did not improve from 91.61790\n",
      "Epoch 774/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 107.3630 - MSE: 107.3630 - val_loss: 146.5845 - val_MSE: 146.5845\n",
      "\n",
      "Epoch 00774: val_loss did not improve from 91.61790\n",
      "Epoch 775/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 63.3096 - MSE: 63.3096 - val_loss: 152.6741 - val_MSE: 152.6741\n",
      "\n",
      "Epoch 00775: val_loss did not improve from 91.61790\n",
      "Epoch 776/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 93.3820 - MSE: 93.3820 - val_loss: 146.6833 - val_MSE: 146.6833\n",
      "\n",
      "Epoch 00776: val_loss did not improve from 91.61790\n",
      "Epoch 777/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 79.0250 - MSE: 79.0250 - val_loss: 148.3239 - val_MSE: 148.3239\n",
      "\n",
      "Epoch 00777: val_loss did not improve from 91.61790\n",
      "Epoch 778/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 74.7974 - MSE: 74.7974 - val_loss: 159.3536 - val_MSE: 159.3536\n",
      "\n",
      "Epoch 00778: val_loss did not improve from 91.61790\n",
      "Epoch 779/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 83.6302 - MSE: 83.6302 - val_loss: 163.9533 - val_MSE: 163.9533\n",
      "\n",
      "Epoch 00779: val_loss did not improve from 91.61790\n",
      "Epoch 780/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 123.4440 - MSE: 123.4440 - val_loss: 188.6826 - val_MSE: 188.6826\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 91.61790\n",
      "Epoch 781/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 68.9205 - MSE: 68.9205 - val_loss: 152.9793 - val_MSE: 152.9793\n",
      "\n",
      "Epoch 00781: val_loss did not improve from 91.61790\n",
      "Epoch 782/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 89.4306 - MSE: 89.4306 - val_loss: 215.7765 - val_MSE: 215.7765\n",
      "\n",
      "Epoch 00782: val_loss did not improve from 91.61790\n",
      "Epoch 783/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 135.3973 - MSE: 135.3973 - val_loss: 177.2443 - val_MSE: 177.2443\n",
      "\n",
      "Epoch 00783: val_loss did not improve from 91.61790\n",
      "Epoch 784/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 86.1764 - MSE: 86.1764 - val_loss: 156.8440 - val_MSE: 156.8440\n",
      "\n",
      "Epoch 00784: val_loss did not improve from 91.61790\n",
      "Epoch 785/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 113.5382 - MSE: 113.5382 - val_loss: 171.2899 - val_MSE: 171.2899\n",
      "\n",
      "Epoch 00785: val_loss did not improve from 91.61790\n",
      "Epoch 786/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 108.7078 - MSE: 108.7078 - val_loss: 196.6946 - val_MSE: 196.6946\n",
      "\n",
      "Epoch 00786: val_loss did not improve from 91.61790\n",
      "Epoch 787/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 173.3896 - MSE: 173.3896 - val_loss: 152.9285 - val_MSE: 152.9285\n",
      "\n",
      "Epoch 00787: val_loss did not improve from 91.61790\n",
      "Epoch 788/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 109.0925 - MSE: 109.0925 - val_loss: 137.2845 - val_MSE: 137.2845\n",
      "\n",
      "Epoch 00788: val_loss did not improve from 91.61790\n",
      "Epoch 789/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 96.4922 - MSE: 96.4922 - val_loss: 146.1542 - val_MSE: 146.1542\n",
      "\n",
      "Epoch 00789: val_loss did not improve from 91.61790\n",
      "Epoch 790/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 102.7610 - MSE: 102.7610 - val_loss: 123.6386 - val_MSE: 123.6386\n",
      "\n",
      "Epoch 00790: val_loss did not improve from 91.61790\n",
      "Epoch 791/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 85.0189 - MSE: 85.0189 - val_loss: 182.8108 - val_MSE: 182.8108\n",
      "\n",
      "Epoch 00791: val_loss did not improve from 91.61790\n",
      "Epoch 792/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 130.1581 - MSE: 130.1581 - val_loss: 144.5720 - val_MSE: 144.5720\n",
      "\n",
      "Epoch 00792: val_loss did not improve from 91.61790\n",
      "Epoch 793/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 119.9965 - MSE: 119.9965 - val_loss: 182.9696 - val_MSE: 182.9696\n",
      "\n",
      "Epoch 00793: val_loss did not improve from 91.61790\n",
      "Epoch 794/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 102.0726 - MSE: 102.0726 - val_loss: 168.9565 - val_MSE: 168.9565\n",
      "\n",
      "Epoch 00794: val_loss did not improve from 91.61790\n",
      "Epoch 795/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 88.6563 - MSE: 88.6563 - val_loss: 161.3160 - val_MSE: 161.3160\n",
      "\n",
      "Epoch 00795: val_loss did not improve from 91.61790\n",
      "Epoch 796/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 116.2744 - MSE: 116.2744 - val_loss: 158.1025 - val_MSE: 158.1025\n",
      "\n",
      "Epoch 00796: val_loss did not improve from 91.61790\n",
      "Epoch 797/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 81.9173 - MSE: 81.9173 - val_loss: 158.0948 - val_MSE: 158.0948\n",
      "\n",
      "Epoch 00797: val_loss did not improve from 91.61790\n",
      "Epoch 798/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 126.6763 - MSE: 126.6763 - val_loss: 150.4004 - val_MSE: 150.4004\n",
      "\n",
      "Epoch 00798: val_loss did not improve from 91.61790\n",
      "Epoch 799/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 123.2771 - MSE: 123.2771 - val_loss: 195.0614 - val_MSE: 195.0614\n",
      "\n",
      "Epoch 00799: val_loss did not improve from 91.61790\n",
      "Epoch 800/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 97.9394 - MSE: 97.9394 - val_loss: 179.4829 - val_MSE: 179.4829\n",
      "\n",
      "Epoch 00800: val_loss did not improve from 91.61790\n",
      "Epoch 801/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 86.7532 - MSE: 86.7532 - val_loss: 167.4746 - val_MSE: 167.4746\n",
      "\n",
      "Epoch 00801: val_loss did not improve from 91.61790\n",
      "Epoch 802/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 70.3149 - MSE: 70.3149 - val_loss: 143.0577 - val_MSE: 143.0577\n",
      "\n",
      "Epoch 00802: val_loss did not improve from 91.61790\n",
      "Epoch 803/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 111.6988 - MSE: 111.6988 - val_loss: 251.6985 - val_MSE: 251.6985\n",
      "\n",
      "Epoch 00803: val_loss did not improve from 91.61790\n",
      "Epoch 804/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 8ms/step - loss: 219.1015 - MSE: 219.1015 - val_loss: 170.2530 - val_MSE: 170.2530\n",
      "\n",
      "Epoch 00804: val_loss did not improve from 91.61790\n",
      "Epoch 805/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 211.3537 - MSE: 211.3537 - val_loss: 182.9952 - val_MSE: 182.9952\n",
      "\n",
      "Epoch 00805: val_loss did not improve from 91.61790\n",
      "Epoch 806/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 129.1606 - MSE: 129.1606 - val_loss: 162.5404 - val_MSE: 162.5404\n",
      "\n",
      "Epoch 00806: val_loss did not improve from 91.61790\n",
      "Epoch 807/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 103.4268 - MSE: 103.4268 - val_loss: 199.6300 - val_MSE: 199.6300\n",
      "\n",
      "Epoch 00807: val_loss did not improve from 91.61790\n",
      "Epoch 808/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 222.4656 - MSE: 222.4656 - val_loss: 177.9071 - val_MSE: 177.9071\n",
      "\n",
      "Epoch 00808: val_loss did not improve from 91.61790\n",
      "Epoch 809/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 144.5474 - MSE: 144.5474 - val_loss: 140.9580 - val_MSE: 140.9580\n",
      "\n",
      "Epoch 00809: val_loss did not improve from 91.61790\n",
      "Epoch 810/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 157.1744 - MSE: 157.1744 - val_loss: 187.6909 - val_MSE: 187.6909\n",
      "\n",
      "Epoch 00810: val_loss did not improve from 91.61790\n",
      "Epoch 811/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 172.7599 - MSE: 172.7599 - val_loss: 195.9591 - val_MSE: 195.9591\n",
      "\n",
      "Epoch 00811: val_loss did not improve from 91.61790\n",
      "Epoch 812/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 188.8993 - MSE: 188.8993 - val_loss: 187.2051 - val_MSE: 187.2051\n",
      "\n",
      "Epoch 00812: val_loss did not improve from 91.61790\n",
      "Epoch 813/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 178.1403 - MSE: 178.1403 - val_loss: 223.2594 - val_MSE: 223.2594\n",
      "\n",
      "Epoch 00813: val_loss did not improve from 91.61790\n",
      "Epoch 814/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 146.8983 - MSE: 146.8983 - val_loss: 217.7934 - val_MSE: 217.7934\n",
      "\n",
      "Epoch 00814: val_loss did not improve from 91.61790\n",
      "Epoch 815/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 177.4382 - MSE: 177.4382 - val_loss: 190.8160 - val_MSE: 190.8160\n",
      "\n",
      "Epoch 00815: val_loss did not improve from 91.61790\n",
      "Epoch 816/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 140.8876 - MSE: 140.8876 - val_loss: 201.7263 - val_MSE: 201.7263\n",
      "\n",
      "Epoch 00816: val_loss did not improve from 91.61790\n",
      "Epoch 817/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 190.0926 - MSE: 190.0926 - val_loss: 187.8451 - val_MSE: 187.8451\n",
      "\n",
      "Epoch 00817: val_loss did not improve from 91.61790\n",
      "Epoch 818/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 151.4007 - MSE: 151.4007 - val_loss: 209.3995 - val_MSE: 209.3995\n",
      "\n",
      "Epoch 00818: val_loss did not improve from 91.61790\n",
      "Epoch 819/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 118.0238 - MSE: 118.0238 - val_loss: 209.1401 - val_MSE: 209.1401\n",
      "\n",
      "Epoch 00819: val_loss did not improve from 91.61790\n",
      "Epoch 820/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 103.4726 - MSE: 103.4726 - val_loss: 176.5151 - val_MSE: 176.5151\n",
      "\n",
      "Epoch 00820: val_loss did not improve from 91.61790\n",
      "Epoch 821/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 121.9734 - MSE: 121.9734 - val_loss: 194.5490 - val_MSE: 194.5490\n",
      "\n",
      "Epoch 00821: val_loss did not improve from 91.61790\n",
      "Epoch 822/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 94.9179 - MSE: 94.9179 - val_loss: 170.8838 - val_MSE: 170.8838\n",
      "\n",
      "Epoch 00822: val_loss did not improve from 91.61790\n",
      "Epoch 823/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 126.3359 - MSE: 126.3359 - val_loss: 159.5044 - val_MSE: 159.5044\n",
      "\n",
      "Epoch 00823: val_loss did not improve from 91.61790\n",
      "Epoch 824/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 99.7225 - MSE: 99.7225 - val_loss: 138.3590 - val_MSE: 138.3590\n",
      "\n",
      "Epoch 00824: val_loss did not improve from 91.61790\n",
      "Epoch 825/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 115.3864 - MSE: 115.3864 - val_loss: 182.5008 - val_MSE: 182.5008\n",
      "\n",
      "Epoch 00825: val_loss did not improve from 91.61790\n",
      "Epoch 826/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 157.8082 - MSE: 157.8082 - val_loss: 166.0566 - val_MSE: 166.0566\n",
      "\n",
      "Epoch 00826: val_loss did not improve from 91.61790\n",
      "Epoch 827/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 89.6541 - MSE: 89.6541 - val_loss: 167.6393 - val_MSE: 167.6393\n",
      "\n",
      "Epoch 00827: val_loss did not improve from 91.61790\n",
      "Epoch 828/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 114.6947 - MSE: 114.6947 - val_loss: 174.0234 - val_MSE: 174.0234\n",
      "\n",
      "Epoch 00828: val_loss did not improve from 91.61790\n",
      "Epoch 829/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 61.1432 - MSE: 61.1432 - val_loss: 185.2074 - val_MSE: 185.2074\n",
      "\n",
      "Epoch 00829: val_loss did not improve from 91.61790\n",
      "Epoch 830/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 177.2368 - MSE: 177.2368 - val_loss: 198.8130 - val_MSE: 198.8130\n",
      "\n",
      "Epoch 00830: val_loss did not improve from 91.61790\n",
      "Epoch 831/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 175.0825 - MSE: 175.0825 - val_loss: 187.4796 - val_MSE: 187.4796\n",
      "\n",
      "Epoch 00831: val_loss did not improve from 91.61790\n",
      "Epoch 832/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117.5967 - MSE: 117.5967 - val_loss: 166.4555 - val_MSE: 166.4555\n",
      "\n",
      "Epoch 00832: val_loss did not improve from 91.61790\n",
      "Epoch 833/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 92.3574 - MSE: 92.3574 - val_loss: 151.9348 - val_MSE: 151.9348\n",
      "\n",
      "Epoch 00833: val_loss did not improve from 91.61790\n",
      "Epoch 834/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 105.7060 - MSE: 105.7060 - val_loss: 164.1546 - val_MSE: 164.1546\n",
      "\n",
      "Epoch 00834: val_loss did not improve from 91.61790\n",
      "Epoch 835/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 107.5820 - MSE: 107.5820 - val_loss: 177.0466 - val_MSE: 177.0466\n",
      "\n",
      "Epoch 00835: val_loss did not improve from 91.61790\n",
      "Epoch 836/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 78.4818 - MSE: 78.4818 - val_loss: 172.2988 - val_MSE: 172.2988\n",
      "\n",
      "Epoch 00836: val_loss did not improve from 91.61790\n",
      "Epoch 837/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 88.4256 - MSE: 88.4256 - val_loss: 200.7016 - val_MSE: 200.7016\n",
      "\n",
      "Epoch 00837: val_loss did not improve from 91.61790\n",
      "Epoch 838/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 141.6128 - MSE: 141.6128 - val_loss: 198.6968 - val_MSE: 198.6968\n",
      "\n",
      "Epoch 00838: val_loss did not improve from 91.61790\n",
      "Epoch 839/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 98.7534 - MSE: 98.7534 - val_loss: 142.9320 - val_MSE: 142.9320\n",
      "\n",
      "Epoch 00839: val_loss did not improve from 91.61790\n",
      "Epoch 840/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 67.9050 - MSE: 67.9050 - val_loss: 173.2260 - val_MSE: 173.2260\n",
      "\n",
      "Epoch 00840: val_loss did not improve from 91.61790\n",
      "Epoch 841/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 72.7020 - MSE: 72.7020 - val_loss: 164.5374 - val_MSE: 164.5374\n",
      "\n",
      "Epoch 00841: val_loss did not improve from 91.61790\n",
      "Epoch 842/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 87.2730 - MSE: 87.2730 - val_loss: 156.3028 - val_MSE: 156.3028\n",
      "\n",
      "Epoch 00842: val_loss did not improve from 91.61790\n",
      "Epoch 843/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 88.7732 - MSE: 88.7732 - val_loss: 146.7989 - val_MSE: 146.7989\n",
      "\n",
      "Epoch 00843: val_loss did not improve from 91.61790\n",
      "Epoch 844/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 136.2682 - MSE: 136.2682 - val_loss: 171.2655 - val_MSE: 171.2655\n",
      "\n",
      "Epoch 00844: val_loss did not improve from 91.61790\n",
      "Epoch 845/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 134.6479 - MSE: 134.6479 - val_loss: 157.1979 - val_MSE: 157.1979\n",
      "\n",
      "Epoch 00845: val_loss did not improve from 91.61790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 846/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 77.2251 - MSE: 77.2251 - val_loss: 208.0761 - val_MSE: 208.0761\n",
      "\n",
      "Epoch 00846: val_loss did not improve from 91.61790\n",
      "Epoch 847/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 195.2160 - MSE: 195.2160 - val_loss: 157.3511 - val_MSE: 157.3511\n",
      "\n",
      "Epoch 00847: val_loss did not improve from 91.61790\n",
      "Epoch 848/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 75.0027 - MSE: 75.0027 - val_loss: 167.9584 - val_MSE: 167.9584\n",
      "\n",
      "Epoch 00848: val_loss did not improve from 91.61790\n",
      "Epoch 849/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 107.0737 - MSE: 107.0737 - val_loss: 158.7106 - val_MSE: 158.7106\n",
      "\n",
      "Epoch 00849: val_loss did not improve from 91.61790\n",
      "Epoch 850/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 61.4611 - MSE: 61.4611 - val_loss: 167.2463 - val_MSE: 167.2463\n",
      "\n",
      "Epoch 00850: val_loss did not improve from 91.61790\n",
      "Epoch 851/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 92.7762 - MSE: 92.7762 - val_loss: 172.5479 - val_MSE: 172.5479\n",
      "\n",
      "Epoch 00851: val_loss did not improve from 91.61790\n",
      "Epoch 852/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 84.3566 - MSE: 84.3566 - val_loss: 133.9733 - val_MSE: 133.9733\n",
      "\n",
      "Epoch 00852: val_loss did not improve from 91.61790\n",
      "Epoch 853/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 107.6643 - MSE: 107.6643 - val_loss: 167.3660 - val_MSE: 167.3660\n",
      "\n",
      "Epoch 00853: val_loss did not improve from 91.61790\n",
      "Epoch 854/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 85.1328 - MSE: 85.1328 - val_loss: 148.3612 - val_MSE: 148.3612\n",
      "\n",
      "Epoch 00854: val_loss did not improve from 91.61790\n",
      "Epoch 855/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 61.4247 - MSE: 61.4247 - val_loss: 155.1701 - val_MSE: 155.1701\n",
      "\n",
      "Epoch 00855: val_loss did not improve from 91.61790\n",
      "Epoch 856/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 95.9807 - MSE: 95.9807 - val_loss: 137.1203 - val_MSE: 137.1203\n",
      "\n",
      "Epoch 00856: val_loss did not improve from 91.61790\n",
      "Epoch 857/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 177.8699 - MSE: 177.8699 - val_loss: 218.0525 - val_MSE: 218.0525\n",
      "\n",
      "Epoch 00857: val_loss did not improve from 91.61790\n",
      "Epoch 858/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 119.7982 - MSE: 119.7982 - val_loss: 163.9053 - val_MSE: 163.9053\n",
      "\n",
      "Epoch 00858: val_loss did not improve from 91.61790\n",
      "Epoch 859/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 130.2736 - MSE: 130.2736 - val_loss: 182.0347 - val_MSE: 182.0347\n",
      "\n",
      "Epoch 00859: val_loss did not improve from 91.61790\n",
      "Epoch 860/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 119.2254 - MSE: 119.2254 - val_loss: 151.3760 - val_MSE: 151.3760\n",
      "\n",
      "Epoch 00860: val_loss did not improve from 91.61790\n",
      "Epoch 861/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 107.3904 - MSE: 107.3904 - val_loss: 143.3866 - val_MSE: 143.3866\n",
      "\n",
      "Epoch 00861: val_loss did not improve from 91.61790\n",
      "Epoch 862/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 90.8010 - MSE: 90.8010 - val_loss: 131.6195 - val_MSE: 131.6195\n",
      "\n",
      "Epoch 00862: val_loss did not improve from 91.61790\n",
      "Epoch 863/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 85.5238 - MSE: 85.5238 - val_loss: 151.2278 - val_MSE: 151.2278\n",
      "\n",
      "Epoch 00863: val_loss did not improve from 91.61790\n",
      "Epoch 864/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 84.7225 - MSE: 84.7225 - val_loss: 143.8022 - val_MSE: 143.8022\n",
      "\n",
      "Epoch 00864: val_loss did not improve from 91.61790\n",
      "Epoch 865/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 57.7282 - MSE: 57.7282 - val_loss: 205.0940 - val_MSE: 205.0940\n",
      "\n",
      "Epoch 00865: val_loss did not improve from 91.61790\n",
      "Epoch 866/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 93.8318 - MSE: 93.8318 - val_loss: 244.5631 - val_MSE: 244.5631\n",
      "\n",
      "Epoch 00866: val_loss did not improve from 91.61790\n",
      "Epoch 867/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 67.0900 - MSE: 67.0900 - val_loss: 155.3639 - val_MSE: 155.3639\n",
      "\n",
      "Epoch 00867: val_loss did not improve from 91.61790\n",
      "Epoch 868/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 59.4353 - MSE: 59.4353 - val_loss: 133.7631 - val_MSE: 133.7631\n",
      "\n",
      "Epoch 00868: val_loss did not improve from 91.61790\n",
      "Epoch 869/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 100.6808 - MSE: 100.6808 - val_loss: 146.9801 - val_MSE: 146.9801\n",
      "\n",
      "Epoch 00869: val_loss did not improve from 91.61790\n",
      "Epoch 870/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 102.3666 - MSE: 102.3666 - val_loss: 138.7793 - val_MSE: 138.7793\n",
      "\n",
      "Epoch 00870: val_loss did not improve from 91.61790\n",
      "Epoch 871/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 64.8557 - MSE: 64.8557 - val_loss: 127.7718 - val_MSE: 127.7718\n",
      "\n",
      "Epoch 00871: val_loss did not improve from 91.61790\n",
      "Epoch 872/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 74.2217 - MSE: 74.2217 - val_loss: 127.2887 - val_MSE: 127.2887\n",
      "\n",
      "Epoch 00872: val_loss did not improve from 91.61790\n",
      "Epoch 873/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 104.1776 - MSE: 104.1776 - val_loss: 203.5203 - val_MSE: 203.5203\n",
      "\n",
      "Epoch 00873: val_loss did not improve from 91.61790\n",
      "Epoch 874/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 176.6955 - MSE: 176.6955 - val_loss: 202.7567 - val_MSE: 202.7567\n",
      "\n",
      "Epoch 00874: val_loss did not improve from 91.61790\n",
      "Epoch 875/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 181.4586 - MSE: 181.4586 - val_loss: 178.1616 - val_MSE: 178.1616\n",
      "\n",
      "Epoch 00875: val_loss did not improve from 91.61790\n",
      "Epoch 876/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 100.0494 - MSE: 100.0494 - val_loss: 133.0506 - val_MSE: 133.0506\n",
      "\n",
      "Epoch 00876: val_loss did not improve from 91.61790\n",
      "Epoch 877/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 90.0591 - MSE: 90.0591 - val_loss: 140.0893 - val_MSE: 140.0893\n",
      "\n",
      "Epoch 00877: val_loss did not improve from 91.61790\n",
      "Epoch 878/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 88.6712 - MSE: 88.6712 - val_loss: 156.7085 - val_MSE: 156.7085\n",
      "\n",
      "Epoch 00878: val_loss did not improve from 91.61790\n",
      "Epoch 879/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 45.9264 - MSE: 45.9264 - val_loss: 139.8456 - val_MSE: 139.8456\n",
      "\n",
      "Epoch 00879: val_loss did not improve from 91.61790\n",
      "Epoch 880/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 64.8436 - MSE: 64.8436 - val_loss: 181.3782 - val_MSE: 181.3782\n",
      "\n",
      "Epoch 00880: val_loss did not improve from 91.61790\n",
      "Epoch 881/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 65.6059 - MSE: 65.6059 - val_loss: 128.0735 - val_MSE: 128.0735\n",
      "\n",
      "Epoch 00881: val_loss did not improve from 91.61790\n",
      "Epoch 882/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 115.2015 - MSE: 115.2015 - val_loss: 165.5932 - val_MSE: 165.5932\n",
      "\n",
      "Epoch 00882: val_loss did not improve from 91.61790\n",
      "Epoch 883/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 84.3092 - MSE: 84.3092 - val_loss: 203.0547 - val_MSE: 203.0547\n",
      "\n",
      "Epoch 00883: val_loss did not improve from 91.61790\n",
      "Epoch 884/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 106.9701 - MSE: 106.9701 - val_loss: 142.8630 - val_MSE: 142.8630\n",
      "\n",
      "Epoch 00884: val_loss did not improve from 91.61790\n",
      "Epoch 885/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 81.7965 - MSE: 81.7965 - val_loss: 191.3778 - val_MSE: 191.3778\n",
      "\n",
      "Epoch 00885: val_loss did not improve from 91.61790\n",
      "Epoch 886/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 107.4403 - MSE: 107.4403 - val_loss: 269.9557 - val_MSE: 269.9557\n",
      "\n",
      "Epoch 00886: val_loss did not improve from 91.61790\n",
      "Epoch 887/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 120.9119 - MSE: 120.9119 - val_loss: 297.4200 - val_MSE: 297.4200\n",
      "\n",
      "Epoch 00887: val_loss did not improve from 91.61790\n",
      "Epoch 888/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 7ms/step - loss: 162.3109 - MSE: 162.3109 - val_loss: 146.5730 - val_MSE: 146.5730\n",
      "\n",
      "Epoch 00888: val_loss did not improve from 91.61790\n",
      "Epoch 889/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 66.5951 - MSE: 66.5951 - val_loss: 146.1049 - val_MSE: 146.1049\n",
      "\n",
      "Epoch 00889: val_loss did not improve from 91.61790\n",
      "Epoch 890/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 73.6302 - MSE: 73.6302 - val_loss: 156.1616 - val_MSE: 156.1616\n",
      "\n",
      "Epoch 00890: val_loss did not improve from 91.61790\n",
      "Epoch 891/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 118.9352 - MSE: 118.9352 - val_loss: 117.1306 - val_MSE: 117.1306\n",
      "\n",
      "Epoch 00891: val_loss did not improve from 91.61790\n",
      "Epoch 892/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 82.0205 - MSE: 82.0205 - val_loss: 124.8805 - val_MSE: 124.8805\n",
      "\n",
      "Epoch 00892: val_loss did not improve from 91.61790\n",
      "Epoch 893/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 77.9837 - MSE: 77.9837 - val_loss: 130.4707 - val_MSE: 130.4707\n",
      "\n",
      "Epoch 00893: val_loss did not improve from 91.61790\n",
      "Epoch 894/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 44.8512 - MSE: 44.8512 - val_loss: 134.7445 - val_MSE: 134.7445\n",
      "\n",
      "Epoch 00894: val_loss did not improve from 91.61790\n",
      "Epoch 895/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 142.3590 - MSE: 142.3590 - val_loss: 134.2140 - val_MSE: 134.2140\n",
      "\n",
      "Epoch 00895: val_loss did not improve from 91.61790\n",
      "Epoch 896/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 74.1620 - MSE: 74.1620 - val_loss: 147.5878 - val_MSE: 147.5878\n",
      "\n",
      "Epoch 00896: val_loss did not improve from 91.61790\n",
      "Epoch 897/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 80.6324 - MSE: 80.6324 - val_loss: 193.1539 - val_MSE: 193.1539\n",
      "\n",
      "Epoch 00897: val_loss did not improve from 91.61790\n",
      "Epoch 898/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 83.0044 - MSE: 83.0044 - val_loss: 167.4918 - val_MSE: 167.4918\n",
      "\n",
      "Epoch 00898: val_loss did not improve from 91.61790\n",
      "Epoch 899/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 70.1804 - MSE: 70.1804 - val_loss: 116.3847 - val_MSE: 116.3847\n",
      "\n",
      "Epoch 00899: val_loss did not improve from 91.61790\n",
      "Epoch 900/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 108.4256 - MSE: 108.4256 - val_loss: 159.7960 - val_MSE: 159.7960\n",
      "\n",
      "Epoch 00900: val_loss did not improve from 91.61790\n",
      "Epoch 901/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 104.0001 - MSE: 104.0001 - val_loss: 158.0879 - val_MSE: 158.0879\n",
      "\n",
      "Epoch 00901: val_loss did not improve from 91.61790\n",
      "Epoch 902/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 81.5101 - MSE: 81.5101 - val_loss: 180.1305 - val_MSE: 180.1305\n",
      "\n",
      "Epoch 00902: val_loss did not improve from 91.61790\n",
      "Epoch 903/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 100.0150 - MSE: 100.0150 - val_loss: 159.6311 - val_MSE: 159.6311\n",
      "\n",
      "Epoch 00903: val_loss did not improve from 91.61790\n",
      "Epoch 904/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 106.8289 - MSE: 106.8289 - val_loss: 154.8233 - val_MSE: 154.8233\n",
      "\n",
      "Epoch 00904: val_loss did not improve from 91.61790\n",
      "Epoch 905/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 120.6743 - MSE: 120.6743 - val_loss: 160.1426 - val_MSE: 160.1426\n",
      "\n",
      "Epoch 00905: val_loss did not improve from 91.61790\n",
      "Epoch 906/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 102.3440 - MSE: 102.3440 - val_loss: 145.0967 - val_MSE: 145.0967\n",
      "\n",
      "Epoch 00906: val_loss did not improve from 91.61790\n",
      "Epoch 907/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 100.9794 - MSE: 100.9794 - val_loss: 167.3602 - val_MSE: 167.3602\n",
      "\n",
      "Epoch 00907: val_loss did not improve from 91.61790\n",
      "Epoch 908/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 118.8275 - MSE: 118.8275 - val_loss: 155.5586 - val_MSE: 155.5586\n",
      "\n",
      "Epoch 00908: val_loss did not improve from 91.61790\n",
      "Epoch 909/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 104.8569 - MSE: 104.8569 - val_loss: 181.4602 - val_MSE: 181.4602\n",
      "\n",
      "Epoch 00909: val_loss did not improve from 91.61790\n",
      "Epoch 910/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 95.7451 - MSE: 95.7451 - val_loss: 175.3825 - val_MSE: 175.3825\n",
      "\n",
      "Epoch 00910: val_loss did not improve from 91.61790\n",
      "Epoch 911/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 168.3371 - MSE: 168.3371 - val_loss: 160.8250 - val_MSE: 160.8250\n",
      "\n",
      "Epoch 00911: val_loss did not improve from 91.61790\n",
      "Epoch 912/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 106.6056 - MSE: 106.6056 - val_loss: 165.4319 - val_MSE: 165.4319\n",
      "\n",
      "Epoch 00912: val_loss did not improve from 91.61790\n",
      "Epoch 913/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 72.2182 - MSE: 72.2182 - val_loss: 163.2514 - val_MSE: 163.2514\n",
      "\n",
      "Epoch 00913: val_loss did not improve from 91.61790\n",
      "Epoch 914/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 82.2283 - MSE: 82.2283 - val_loss: 174.7094 - val_MSE: 174.7094\n",
      "\n",
      "Epoch 00914: val_loss did not improve from 91.61790\n",
      "Epoch 915/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 72.7835 - MSE: 72.7835 - val_loss: 152.5796 - val_MSE: 152.5796\n",
      "\n",
      "Epoch 00915: val_loss did not improve from 91.61790\n",
      "Epoch 916/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 85.5309 - MSE: 85.5309 - val_loss: 198.1402 - val_MSE: 198.1402\n",
      "\n",
      "Epoch 00916: val_loss did not improve from 91.61790\n",
      "Epoch 917/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 89.1843 - MSE: 89.1843 - val_loss: 167.4811 - val_MSE: 167.4811\n",
      "\n",
      "Epoch 00917: val_loss did not improve from 91.61790\n",
      "Epoch 918/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 89.8294 - MSE: 89.8294 - val_loss: 152.0658 - val_MSE: 152.0658\n",
      "\n",
      "Epoch 00918: val_loss did not improve from 91.61790\n",
      "Epoch 919/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 126.7797 - MSE: 126.7797 - val_loss: 185.8202 - val_MSE: 185.8202\n",
      "\n",
      "Epoch 00919: val_loss did not improve from 91.61790\n",
      "Epoch 920/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 97.4094 - MSE: 97.4094 - val_loss: 211.3033 - val_MSE: 211.3033\n",
      "\n",
      "Epoch 00920: val_loss did not improve from 91.61790\n",
      "Epoch 921/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 153.6597 - MSE: 153.6597 - val_loss: 180.8702 - val_MSE: 180.8702\n",
      "\n",
      "Epoch 00921: val_loss did not improve from 91.61790\n",
      "Epoch 922/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 95.5259 - MSE: 95.5259 - val_loss: 166.9170 - val_MSE: 166.9170\n",
      "\n",
      "Epoch 00922: val_loss did not improve from 91.61790\n",
      "Epoch 923/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 114.5134 - MSE: 114.5134 - val_loss: 141.1749 - val_MSE: 141.1749\n",
      "\n",
      "Epoch 00923: val_loss did not improve from 91.61790\n",
      "Epoch 924/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 68.0617 - MSE: 68.0617 - val_loss: 152.6360 - val_MSE: 152.6360\n",
      "\n",
      "Epoch 00924: val_loss did not improve from 91.61790\n",
      "Epoch 925/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 82.5712 - MSE: 82.5712 - val_loss: 163.4919 - val_MSE: 163.4919\n",
      "\n",
      "Epoch 00925: val_loss did not improve from 91.61790\n",
      "Epoch 926/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 95.1114 - MSE: 95.1114 - val_loss: 175.6780 - val_MSE: 175.6780\n",
      "\n",
      "Epoch 00926: val_loss did not improve from 91.61790\n",
      "Epoch 927/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 66.2629 - MSE: 66.2629 - val_loss: 141.2183 - val_MSE: 141.2183\n",
      "\n",
      "Epoch 00927: val_loss did not improve from 91.61790\n",
      "Epoch 928/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 83.5318 - MSE: 83.5318 - val_loss: 138.5886 - val_MSE: 138.5886\n",
      "\n",
      "Epoch 00928: val_loss did not improve from 91.61790\n",
      "Epoch 929/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 69.1927 - MSE: 69.1927 - val_loss: 142.7999 - val_MSE: 142.7999\n",
      "\n",
      "Epoch 00929: val_loss did not improve from 91.61790\n",
      "Epoch 930/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 8ms/step - loss: 103.2224 - MSE: 103.2224 - val_loss: 129.0570 - val_MSE: 129.0570\n",
      "\n",
      "Epoch 00930: val_loss did not improve from 91.61790\n",
      "Epoch 931/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 110.0477 - MSE: 110.0477 - val_loss: 157.3208 - val_MSE: 157.3208\n",
      "\n",
      "Epoch 00931: val_loss did not improve from 91.61790\n",
      "Epoch 932/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 95.2638 - MSE: 95.2638 - val_loss: 134.8289 - val_MSE: 134.8289\n",
      "\n",
      "Epoch 00932: val_loss did not improve from 91.61790\n",
      "Epoch 933/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 64.3138 - MSE: 64.3138 - val_loss: 165.5652 - val_MSE: 165.5652\n",
      "\n",
      "Epoch 00933: val_loss did not improve from 91.61790\n",
      "Epoch 934/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 85.8392 - MSE: 85.8392 - val_loss: 172.7684 - val_MSE: 172.7684\n",
      "\n",
      "Epoch 00934: val_loss did not improve from 91.61790\n",
      "Epoch 935/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 97.7620 - MSE: 97.7620 - val_loss: 155.3374 - val_MSE: 155.3374\n",
      "\n",
      "Epoch 00935: val_loss did not improve from 91.61790\n",
      "Epoch 936/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 72.3557 - MSE: 72.3557 - val_loss: 156.0641 - val_MSE: 156.0641\n",
      "\n",
      "Epoch 00936: val_loss did not improve from 91.61790\n",
      "Epoch 937/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 78.5523 - MSE: 78.5523 - val_loss: 180.9866 - val_MSE: 180.9866\n",
      "\n",
      "Epoch 00937: val_loss did not improve from 91.61790\n",
      "Epoch 938/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 66.0332 - MSE: 66.0332 - val_loss: 161.5581 - val_MSE: 161.5581\n",
      "\n",
      "Epoch 00938: val_loss did not improve from 91.61790\n",
      "Epoch 939/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 100.2707 - MSE: 100.2707 - val_loss: 188.7695 - val_MSE: 188.7695\n",
      "\n",
      "Epoch 00939: val_loss did not improve from 91.61790\n",
      "Epoch 940/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 94.2967 - MSE: 94.2967 - val_loss: 155.0220 - val_MSE: 155.0220\n",
      "\n",
      "Epoch 00940: val_loss did not improve from 91.61790\n",
      "Epoch 941/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 107.3863 - MSE: 107.3863 - val_loss: 151.8261 - val_MSE: 151.8261\n",
      "\n",
      "Epoch 00941: val_loss did not improve from 91.61790\n",
      "Epoch 942/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 82.6705 - MSE: 82.6705 - val_loss: 150.2222 - val_MSE: 150.2222\n",
      "\n",
      "Epoch 00942: val_loss did not improve from 91.61790\n",
      "Epoch 943/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 77.8673 - MSE: 77.8673 - val_loss: 158.0894 - val_MSE: 158.0894\n",
      "\n",
      "Epoch 00943: val_loss did not improve from 91.61790\n",
      "Epoch 944/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 85.1593 - MSE: 85.1593 - val_loss: 147.7128 - val_MSE: 147.7128\n",
      "\n",
      "Epoch 00944: val_loss did not improve from 91.61790\n",
      "Epoch 945/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 92.5748 - MSE: 92.5748 - val_loss: 169.4359 - val_MSE: 169.4359\n",
      "\n",
      "Epoch 00945: val_loss did not improve from 91.61790\n",
      "Epoch 946/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 89.3695 - MSE: 89.3695 - val_loss: 164.8316 - val_MSE: 164.8316\n",
      "\n",
      "Epoch 00946: val_loss did not improve from 91.61790\n",
      "Epoch 947/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 151.5672 - MSE: 151.5672 - val_loss: 192.2106 - val_MSE: 192.2106\n",
      "\n",
      "Epoch 00947: val_loss did not improve from 91.61790\n",
      "Epoch 948/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 176.6400 - MSE: 176.6400 - val_loss: 310.3543 - val_MSE: 310.3543\n",
      "\n",
      "Epoch 00948: val_loss did not improve from 91.61790\n",
      "Epoch 949/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 132.4893 - MSE: 132.4893 - val_loss: 152.9747 - val_MSE: 152.9747\n",
      "\n",
      "Epoch 00949: val_loss did not improve from 91.61790\n",
      "Epoch 950/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 134.8444 - MSE: 134.8444 - val_loss: 150.6010 - val_MSE: 150.6010\n",
      "\n",
      "Epoch 00950: val_loss did not improve from 91.61790\n",
      "Epoch 951/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 120.1965 - MSE: 120.1965 - val_loss: 168.0444 - val_MSE: 168.0444\n",
      "\n",
      "Epoch 00951: val_loss did not improve from 91.61790\n",
      "Epoch 952/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 97.3379 - MSE: 97.3379 - val_loss: 203.5792 - val_MSE: 203.5792\n",
      "\n",
      "Epoch 00952: val_loss did not improve from 91.61790\n",
      "Epoch 953/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 65.6256 - MSE: 65.6256 - val_loss: 166.1639 - val_MSE: 166.1639\n",
      "\n",
      "Epoch 00953: val_loss did not improve from 91.61790\n",
      "Epoch 954/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 111.3809 - MSE: 111.3809 - val_loss: 155.4252 - val_MSE: 155.4252\n",
      "\n",
      "Epoch 00954: val_loss did not improve from 91.61790\n",
      "Epoch 955/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 62.2750 - MSE: 62.2750 - val_loss: 158.7023 - val_MSE: 158.7023\n",
      "\n",
      "Epoch 00955: val_loss did not improve from 91.61790\n",
      "Epoch 956/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 88.2476 - MSE: 88.2476 - val_loss: 276.8956 - val_MSE: 276.8956\n",
      "\n",
      "Epoch 00956: val_loss did not improve from 91.61790\n",
      "Epoch 957/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 121.7693 - MSE: 121.7693 - val_loss: 154.0810 - val_MSE: 154.0810\n",
      "\n",
      "Epoch 00957: val_loss did not improve from 91.61790\n",
      "Epoch 958/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 101.3987 - MSE: 101.3987 - val_loss: 166.2665 - val_MSE: 166.2665\n",
      "\n",
      "Epoch 00958: val_loss did not improve from 91.61790\n",
      "Epoch 959/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 89.9094 - MSE: 89.9094 - val_loss: 147.5694 - val_MSE: 147.5694\n",
      "\n",
      "Epoch 00959: val_loss did not improve from 91.61790\n",
      "Epoch 960/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 87.9928 - MSE: 87.9928 - val_loss: 160.4049 - val_MSE: 160.4049\n",
      "\n",
      "Epoch 00960: val_loss did not improve from 91.61790\n",
      "Epoch 961/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 83.6410 - MSE: 83.6410 - val_loss: 201.3331 - val_MSE: 201.3331\n",
      "\n",
      "Epoch 00961: val_loss did not improve from 91.61790\n",
      "Epoch 962/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 362.4052 - MSE: 362.4052 - val_loss: 214.2952 - val_MSE: 214.2952\n",
      "\n",
      "Epoch 00962: val_loss did not improve from 91.61790\n",
      "Epoch 963/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 162.5285 - MSE: 162.5285 - val_loss: 196.0849 - val_MSE: 196.0849\n",
      "\n",
      "Epoch 00963: val_loss did not improve from 91.61790\n",
      "Epoch 964/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 93.7981 - MSE: 93.7981 - val_loss: 159.7963 - val_MSE: 159.7963\n",
      "\n",
      "Epoch 00964: val_loss did not improve from 91.61790\n",
      "Epoch 965/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 116.6652 - MSE: 116.6652 - val_loss: 159.1437 - val_MSE: 159.1437\n",
      "\n",
      "Epoch 00965: val_loss did not improve from 91.61790\n",
      "Epoch 966/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 82.3565 - MSE: 82.3565 - val_loss: 163.0434 - val_MSE: 163.0434\n",
      "\n",
      "Epoch 00966: val_loss did not improve from 91.61790\n",
      "Epoch 967/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 74.4506 - MSE: 74.4506 - val_loss: 139.3811 - val_MSE: 139.3811\n",
      "\n",
      "Epoch 00967: val_loss did not improve from 91.61790\n",
      "Epoch 968/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 66.5822 - MSE: 66.5822 - val_loss: 213.7964 - val_MSE: 213.7964\n",
      "\n",
      "Epoch 00968: val_loss did not improve from 91.61790\n",
      "Epoch 969/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 85.7169 - MSE: 85.7169 - val_loss: 167.4205 - val_MSE: 167.4205\n",
      "\n",
      "Epoch 00969: val_loss did not improve from 91.61790\n",
      "Epoch 970/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 96.6149 - MSE: 96.6149 - val_loss: 172.9341 - val_MSE: 172.9341\n",
      "\n",
      "Epoch 00970: val_loss did not improve from 91.61790\n",
      "Epoch 971/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 83.4594 - MSE: 83.4594 - val_loss: 166.3995 - val_MSE: 166.3995\n",
      "\n",
      "Epoch 00971: val_loss did not improve from 91.61790\n",
      "Epoch 972/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 7ms/step - loss: 90.0756 - MSE: 90.0756 - val_loss: 178.9990 - val_MSE: 178.9990\n",
      "\n",
      "Epoch 00972: val_loss did not improve from 91.61790\n",
      "Epoch 973/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 123.6025 - MSE: 123.6025 - val_loss: 141.1337 - val_MSE: 141.1337\n",
      "\n",
      "Epoch 00973: val_loss did not improve from 91.61790\n",
      "Epoch 974/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 126.8888 - MSE: 126.8888 - val_loss: 229.8984 - val_MSE: 229.8984\n",
      "\n",
      "Epoch 00974: val_loss did not improve from 91.61790\n",
      "Epoch 975/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 99.0750 - MSE: 99.0750 - val_loss: 158.3025 - val_MSE: 158.3025\n",
      "\n",
      "Epoch 00975: val_loss did not improve from 91.61790\n",
      "Epoch 976/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 78.8618 - MSE: 78.8618 - val_loss: 153.9589 - val_MSE: 153.9589\n",
      "\n",
      "Epoch 00976: val_loss did not improve from 91.61790\n",
      "Epoch 977/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 68.1277 - MSE: 68.1277 - val_loss: 167.6917 - val_MSE: 167.6917\n",
      "\n",
      "Epoch 00977: val_loss did not improve from 91.61790\n",
      "Epoch 978/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 121.6682 - MSE: 121.6682 - val_loss: 167.6911 - val_MSE: 167.6911\n",
      "\n",
      "Epoch 00978: val_loss did not improve from 91.61790\n",
      "Epoch 979/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 70.5027 - MSE: 70.5027 - val_loss: 151.6836 - val_MSE: 151.6836\n",
      "\n",
      "Epoch 00979: val_loss did not improve from 91.61790\n",
      "Epoch 980/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 82.0098 - MSE: 82.0098 - val_loss: 221.5305 - val_MSE: 221.5305\n",
      "\n",
      "Epoch 00980: val_loss did not improve from 91.61790\n",
      "Epoch 981/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 92.8342 - MSE: 92.8342 - val_loss: 151.0725 - val_MSE: 151.0725\n",
      "\n",
      "Epoch 00981: val_loss did not improve from 91.61790\n",
      "Epoch 982/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 77.4782 - MSE: 77.4782 - val_loss: 169.5433 - val_MSE: 169.5433\n",
      "\n",
      "Epoch 00982: val_loss did not improve from 91.61790\n",
      "Epoch 983/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 91.4700 - MSE: 91.4700 - val_loss: 163.2931 - val_MSE: 163.2931\n",
      "\n",
      "Epoch 00983: val_loss did not improve from 91.61790\n",
      "Epoch 984/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 113.8072 - MSE: 113.8072 - val_loss: 155.2955 - val_MSE: 155.2955\n",
      "\n",
      "Epoch 00984: val_loss did not improve from 91.61790\n",
      "Epoch 985/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 96.5701 - MSE: 96.5701 - val_loss: 150.0308 - val_MSE: 150.0308\n",
      "\n",
      "Epoch 00985: val_loss did not improve from 91.61790\n",
      "Epoch 986/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117.6140 - MSE: 117.6140 - val_loss: 189.1148 - val_MSE: 189.1148\n",
      "\n",
      "Epoch 00986: val_loss did not improve from 91.61790\n",
      "Epoch 987/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 99.3963 - MSE: 99.3963 - val_loss: 149.4628 - val_MSE: 149.4628\n",
      "\n",
      "Epoch 00987: val_loss did not improve from 91.61790\n",
      "Epoch 988/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 80.5374 - MSE: 80.5374 - val_loss: 170.4925 - val_MSE: 170.4925\n",
      "\n",
      "Epoch 00988: val_loss did not improve from 91.61790\n",
      "Epoch 989/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 83.9815 - MSE: 83.9815 - val_loss: 166.7075 - val_MSE: 166.7075\n",
      "\n",
      "Epoch 00989: val_loss did not improve from 91.61790\n",
      "Epoch 990/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 101.5749 - MSE: 101.5749 - val_loss: 175.9861 - val_MSE: 175.9861\n",
      "\n",
      "Epoch 00990: val_loss did not improve from 91.61790\n",
      "Epoch 991/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 72.9908 - MSE: 72.9908 - val_loss: 167.8428 - val_MSE: 167.8428\n",
      "\n",
      "Epoch 00991: val_loss did not improve from 91.61790\n",
      "Epoch 992/1500\n",
      "141/141 [==============================] - ETA: 0s - loss: 119.1434 - MSE: 119.143 - 1s 7ms/step - loss: 118.2842 - MSE: 118.2842 - val_loss: 168.3261 - val_MSE: 168.3261\n",
      "\n",
      "Epoch 00992: val_loss did not improve from 91.61790\n",
      "Epoch 993/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 63.7825 - MSE: 63.7825 - val_loss: 218.0953 - val_MSE: 218.0953\n",
      "\n",
      "Epoch 00993: val_loss did not improve from 91.61790\n",
      "Epoch 994/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 134.5955 - MSE: 134.5955 - val_loss: 161.0926 - val_MSE: 161.0926\n",
      "\n",
      "Epoch 00994: val_loss did not improve from 91.61790\n",
      "Epoch 995/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 82.9400 - MSE: 82.9400 - val_loss: 187.9704 - val_MSE: 187.9704\n",
      "\n",
      "Epoch 00995: val_loss did not improve from 91.61790\n",
      "Epoch 996/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 91.5947 - MSE: 91.5947 - val_loss: 175.1262 - val_MSE: 175.1262\n",
      "\n",
      "Epoch 00996: val_loss did not improve from 91.61790\n",
      "Epoch 997/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 133.8780 - MSE: 133.8780 - val_loss: 137.6857 - val_MSE: 137.6857\n",
      "\n",
      "Epoch 00997: val_loss did not improve from 91.61790\n",
      "Epoch 998/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 100.6658 - MSE: 100.6658 - val_loss: 181.1566 - val_MSE: 181.1566\n",
      "\n",
      "Epoch 00998: val_loss did not improve from 91.61790\n",
      "Epoch 999/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 179.5489 - MSE: 179.5489 - val_loss: 158.7236 - val_MSE: 158.7236\n",
      "\n",
      "Epoch 00999: val_loss did not improve from 91.61790\n",
      "Epoch 1000/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 137.2012 - MSE: 137.2012 - val_loss: 141.9176 - val_MSE: 141.9176\n",
      "\n",
      "Epoch 01000: val_loss did not improve from 91.61790\n",
      "Epoch 1001/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 89.0035 - MSE: 89.0035 - val_loss: 161.2944 - val_MSE: 161.2944\n",
      "\n",
      "Epoch 01001: val_loss did not improve from 91.61790\n",
      "Epoch 1002/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 98.7320 - MSE: 98.7320 - val_loss: 178.2376 - val_MSE: 178.2376\n",
      "\n",
      "Epoch 01002: val_loss did not improve from 91.61790\n",
      "Epoch 1003/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 86.0114 - MSE: 86.0114 - val_loss: 168.3978 - val_MSE: 168.3978\n",
      "\n",
      "Epoch 01003: val_loss did not improve from 91.61790\n",
      "Epoch 1004/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 89.4087 - MSE: 89.4087 - val_loss: 142.3547 - val_MSE: 142.3547\n",
      "\n",
      "Epoch 01004: val_loss did not improve from 91.61790\n",
      "Epoch 1005/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 82.6363 - MSE: 82.6363 - val_loss: 136.8356 - val_MSE: 136.8356\n",
      "\n",
      "Epoch 01005: val_loss did not improve from 91.61790\n",
      "Epoch 1006/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 88.9769 - MSE: 88.9769 - val_loss: 141.5514 - val_MSE: 141.5514\n",
      "\n",
      "Epoch 01006: val_loss did not improve from 91.61790\n",
      "Epoch 1007/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 110.8053 - MSE: 110.8053 - val_loss: 128.3888 - val_MSE: 128.3888\n",
      "\n",
      "Epoch 01007: val_loss did not improve from 91.61790\n",
      "Epoch 1008/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 94.6910 - MSE: 94.6910 - val_loss: 129.0238 - val_MSE: 129.0238\n",
      "\n",
      "Epoch 01008: val_loss did not improve from 91.61790\n",
      "Epoch 1009/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 80.5621 - MSE: 80.5621 - val_loss: 149.9353 - val_MSE: 149.9353\n",
      "\n",
      "Epoch 01009: val_loss did not improve from 91.61790\n",
      "Epoch 1010/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 119.1515 - MSE: 119.1515 - val_loss: 209.7668 - val_MSE: 209.7668\n",
      "\n",
      "Epoch 01010: val_loss did not improve from 91.61790\n",
      "Epoch 1011/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 191.5018 - MSE: 191.5018 - val_loss: 243.9488 - val_MSE: 243.9488\n",
      "\n",
      "Epoch 01011: val_loss did not improve from 91.61790\n",
      "Epoch 1012/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 194.2361 - MSE: 194.2361 - val_loss: 188.5460 - val_MSE: 188.5460\n",
      "\n",
      "Epoch 01012: val_loss did not improve from 91.61790\n",
      "Epoch 1013/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 182.6287 - MSE: 182.6287 - val_loss: 156.9381 - val_MSE: 156.9381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01013: val_loss did not improve from 91.61790\n",
      "Epoch 1014/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 205.2142 - MSE: 205.2142 - val_loss: 142.1424 - val_MSE: 142.1424\n",
      "\n",
      "Epoch 01014: val_loss did not improve from 91.61790\n",
      "Epoch 1015/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 82.8461 - MSE: 82.8461 - val_loss: 128.2032 - val_MSE: 128.2032\n",
      "\n",
      "Epoch 01015: val_loss did not improve from 91.61790\n",
      "Epoch 1016/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 92.0580 - MSE: 92.0580 - val_loss: 121.9491 - val_MSE: 121.9491\n",
      "\n",
      "Epoch 01016: val_loss did not improve from 91.61790\n",
      "Epoch 1017/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 87.7688 - MSE: 87.7688 - val_loss: 149.9198 - val_MSE: 149.9198\n",
      "\n",
      "Epoch 01017: val_loss did not improve from 91.61790\n",
      "Epoch 1018/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 55.9551 - MSE: 55.9551 - val_loss: 117.9232 - val_MSE: 117.9232\n",
      "\n",
      "Epoch 01018: val_loss did not improve from 91.61790\n",
      "Epoch 1019/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 81.1476 - MSE: 81.1476 - val_loss: 121.2942 - val_MSE: 121.2942\n",
      "\n",
      "Epoch 01019: val_loss did not improve from 91.61790\n",
      "Epoch 1020/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 70.2928 - MSE: 70.2928 - val_loss: 202.6212 - val_MSE: 202.6212\n",
      "\n",
      "Epoch 01020: val_loss did not improve from 91.61790\n",
      "Epoch 1021/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 128.2923 - MSE: 128.2923 - val_loss: 143.4063 - val_MSE: 143.4063\n",
      "\n",
      "Epoch 01021: val_loss did not improve from 91.61790\n",
      "Epoch 1022/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 49.8916 - MSE: 49.8916 - val_loss: 176.2518 - val_MSE: 176.2518\n",
      "\n",
      "Epoch 01022: val_loss did not improve from 91.61790\n",
      "Epoch 1023/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 90.7279 - MSE: 90.7279 - val_loss: 122.6145 - val_MSE: 122.6145\n",
      "\n",
      "Epoch 01023: val_loss did not improve from 91.61790\n",
      "Epoch 1024/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 74.0649 - MSE: 74.0649 - val_loss: 137.6102 - val_MSE: 137.6102\n",
      "\n",
      "Epoch 01024: val_loss did not improve from 91.61790\n",
      "Epoch 1025/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 48.5837 - MSE: 48.5837 - val_loss: 163.7348 - val_MSE: 163.7348\n",
      "\n",
      "Epoch 01025: val_loss did not improve from 91.61790\n",
      "Epoch 1026/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 87.0341 - MSE: 87.0341 - val_loss: 180.0792 - val_MSE: 180.0792\n",
      "\n",
      "Epoch 01026: val_loss did not improve from 91.61790\n",
      "Epoch 1027/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 121.7137 - MSE: 121.7137 - val_loss: 168.4287 - val_MSE: 168.4287\n",
      "\n",
      "Epoch 01027: val_loss did not improve from 91.61790\n",
      "Epoch 1028/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 80.7316 - MSE: 80.7316 - val_loss: 162.1380 - val_MSE: 162.1380\n",
      "\n",
      "Epoch 01028: val_loss did not improve from 91.61790\n",
      "Epoch 1029/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 80.3727 - MSE: 80.3727 - val_loss: 156.7889 - val_MSE: 156.7889\n",
      "\n",
      "Epoch 01029: val_loss did not improve from 91.61790\n",
      "Epoch 1030/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 90.9773 - MSE: 90.9773 - val_loss: 156.8842 - val_MSE: 156.8842\n",
      "\n",
      "Epoch 01030: val_loss did not improve from 91.61790\n",
      "Epoch 1031/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 80.1054 - MSE: 80.1054 - val_loss: 189.4321 - val_MSE: 189.4321\n",
      "\n",
      "Epoch 01031: val_loss did not improve from 91.61790\n",
      "Epoch 1032/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 68.9507 - MSE: 68.9507 - val_loss: 167.9283 - val_MSE: 167.9283\n",
      "\n",
      "Epoch 01032: val_loss did not improve from 91.61790\n",
      "Epoch 1033/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 57.9537 - MSE: 57.9537 - val_loss: 154.1855 - val_MSE: 154.1855\n",
      "\n",
      "Epoch 01033: val_loss did not improve from 91.61790\n",
      "Epoch 1034/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 75.5239 - MSE: 75.5239 - val_loss: 189.4569 - val_MSE: 189.4569\n",
      "\n",
      "Epoch 01034: val_loss did not improve from 91.61790\n",
      "Epoch 1035/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 52.0866 - MSE: 52.0866 - val_loss: 241.9547 - val_MSE: 241.9547\n",
      "\n",
      "Epoch 01035: val_loss did not improve from 91.61790\n",
      "Epoch 1036/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 104.1547 - MSE: 104.1547 - val_loss: 155.3967 - val_MSE: 155.3967\n",
      "\n",
      "Epoch 01036: val_loss did not improve from 91.61790\n",
      "Epoch 1037/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 90.7612 - MSE: 90.7612 - val_loss: 154.0959 - val_MSE: 154.0959\n",
      "\n",
      "Epoch 01037: val_loss did not improve from 91.61790\n",
      "Epoch 1038/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 54.5307 - MSE: 54.5307 - val_loss: 147.2464 - val_MSE: 147.2464\n",
      "\n",
      "Epoch 01038: val_loss did not improve from 91.61790\n",
      "Epoch 1039/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 134.8822 - MSE: 134.8822 - val_loss: 227.6971 - val_MSE: 227.6971\n",
      "\n",
      "Epoch 01039: val_loss did not improve from 91.61790\n",
      "Epoch 1040/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 188.8658 - MSE: 188.8658 - val_loss: 183.2722 - val_MSE: 183.2722\n",
      "\n",
      "Epoch 01040: val_loss did not improve from 91.61790\n",
      "Epoch 1041/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 230.7336 - MSE: 230.7336 - val_loss: 220.9782 - val_MSE: 220.9782\n",
      "\n",
      "Epoch 01041: val_loss did not improve from 91.61790\n",
      "Epoch 1042/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 125.1277 - MSE: 125.1277 - val_loss: 162.9409 - val_MSE: 162.9409\n",
      "\n",
      "Epoch 01042: val_loss did not improve from 91.61790\n",
      "Epoch 1043/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 89.7187 - MSE: 89.7187 - val_loss: 167.5958 - val_MSE: 167.5958\n",
      "\n",
      "Epoch 01043: val_loss did not improve from 91.61790\n",
      "Epoch 1044/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 76.6161 - MSE: 76.6161 - val_loss: 145.5669 - val_MSE: 145.5669\n",
      "\n",
      "Epoch 01044: val_loss did not improve from 91.61790\n",
      "Epoch 1045/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 86.9867 - MSE: 86.9867 - val_loss: 193.8980 - val_MSE: 193.8980\n",
      "\n",
      "Epoch 01045: val_loss did not improve from 91.61790\n",
      "Epoch 1046/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 77.9085 - MSE: 77.9085 - val_loss: 124.6293 - val_MSE: 124.6293\n",
      "\n",
      "Epoch 01046: val_loss did not improve from 91.61790\n",
      "Epoch 1047/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 78.0525 - MSE: 78.0525 - val_loss: 182.3700 - val_MSE: 182.3700\n",
      "\n",
      "Epoch 01047: val_loss did not improve from 91.61790\n",
      "Epoch 1048/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 62.8309 - MSE: 62.8309 - val_loss: 132.3051 - val_MSE: 132.3051\n",
      "\n",
      "Epoch 01048: val_loss did not improve from 91.61790\n",
      "Epoch 1049/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 101.0588 - MSE: 101.0588 - val_loss: 121.7712 - val_MSE: 121.7712\n",
      "\n",
      "Epoch 01049: val_loss did not improve from 91.61790\n",
      "Epoch 1050/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 58.6708 - MSE: 58.6708 - val_loss: 141.3814 - val_MSE: 141.3814\n",
      "\n",
      "Epoch 01050: val_loss did not improve from 91.61790\n",
      "Epoch 1051/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 65.0215 - MSE: 65.0215 - val_loss: 125.1736 - val_MSE: 125.1736\n",
      "\n",
      "Epoch 01051: val_loss did not improve from 91.61790\n",
      "Epoch 1052/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 93.0210 - MSE: 93.0210 - val_loss: 141.1256 - val_MSE: 141.1256\n",
      "\n",
      "Epoch 01052: val_loss did not improve from 91.61790\n",
      "Epoch 1053/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 81.5486 - MSE: 81.5486 - val_loss: 138.4438 - val_MSE: 138.4438\n",
      "\n",
      "Epoch 01053: val_loss did not improve from 91.61790\n",
      "Epoch 1054/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 70.7023 - MSE: 70.7023 - val_loss: 161.1474 - val_MSE: 161.1474\n",
      "\n",
      "Epoch 01054: val_loss did not improve from 91.61790\n",
      "Epoch 1055/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 8ms/step - loss: 78.6228 - MSE: 78.6228 - val_loss: 256.9557 - val_MSE: 256.9557\n",
      "\n",
      "Epoch 01055: val_loss did not improve from 91.61790\n",
      "Epoch 1056/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 241.2364 - MSE: 241.2364 - val_loss: 250.7727 - val_MSE: 250.7727\n",
      "\n",
      "Epoch 01056: val_loss did not improve from 91.61790\n",
      "Epoch 1057/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 92.8616 - MSE: 92.8616 - val_loss: 111.9532 - val_MSE: 111.9532\n",
      "\n",
      "Epoch 01057: val_loss did not improve from 91.61790\n",
      "Epoch 1058/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 111.8055 - MSE: 111.8055 - val_loss: 178.2219 - val_MSE: 178.2219\n",
      "\n",
      "Epoch 01058: val_loss did not improve from 91.61790\n",
      "Epoch 1059/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 56.2107 - MSE: 56.2107 - val_loss: 149.8283 - val_MSE: 149.8283\n",
      "\n",
      "Epoch 01059: val_loss did not improve from 91.61790\n",
      "Epoch 1060/1500\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 67.8545 - MSE: 67.8545 - val_loss: 148.8065 - val_MSE: 148.8065\n",
      "\n",
      "Epoch 01060: val_loss did not improve from 91.61790\n",
      "Epoch 1061/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 65.8468 - MSE: 65.8468 - val_loss: 127.7531 - val_MSE: 127.7531\n",
      "\n",
      "Epoch 01061: val_loss did not improve from 91.61790\n",
      "Epoch 1062/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 53.3387 - MSE: 53.3387 - val_loss: 154.9214 - val_MSE: 154.9214\n",
      "\n",
      "Epoch 01062: val_loss did not improve from 91.61790\n",
      "Epoch 1063/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 44.8743 - MSE: 44.8743 - val_loss: 156.4419 - val_MSE: 156.4419\n",
      "\n",
      "Epoch 01063: val_loss did not improve from 91.61790\n",
      "Epoch 1064/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 65.3308 - MSE: 65.3308 - val_loss: 124.2290 - val_MSE: 124.2290\n",
      "\n",
      "Epoch 01064: val_loss did not improve from 91.61790\n",
      "Epoch 1065/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 73.1617 - MSE: 73.1617 - val_loss: 126.4901 - val_MSE: 126.4901\n",
      "\n",
      "Epoch 01065: val_loss did not improve from 91.61790\n",
      "Epoch 1066/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 94.6319 - MSE: 94.6319 - val_loss: 115.3476 - val_MSE: 115.3476\n",
      "\n",
      "Epoch 01066: val_loss did not improve from 91.61790\n",
      "Epoch 1067/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 48.0628 - MSE: 48.0628 - val_loss: 139.1387 - val_MSE: 139.1387\n",
      "\n",
      "Epoch 01067: val_loss did not improve from 91.61790\n",
      "Epoch 1068/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 86.3479 - MSE: 86.3479 - val_loss: 207.9158 - val_MSE: 207.9158\n",
      "\n",
      "Epoch 01068: val_loss did not improve from 91.61790\n",
      "Epoch 1069/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 186.7085 - MSE: 186.7085 - val_loss: 171.5530 - val_MSE: 171.5530\n",
      "\n",
      "Epoch 01069: val_loss did not improve from 91.61790\n",
      "Epoch 1070/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 112.3283 - MSE: 112.3283 - val_loss: 152.1829 - val_MSE: 152.1829\n",
      "\n",
      "Epoch 01070: val_loss did not improve from 91.61790\n",
      "Epoch 1071/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 83.9825 - MSE: 83.9825 - val_loss: 155.3721 - val_MSE: 155.3721\n",
      "\n",
      "Epoch 01071: val_loss did not improve from 91.61790\n",
      "Epoch 1072/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 83.7012 - MSE: 83.7012 - val_loss: 128.3215 - val_MSE: 128.3215\n",
      "\n",
      "Epoch 01072: val_loss did not improve from 91.61790\n",
      "Epoch 1073/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 65.6869 - MSE: 65.6869 - val_loss: 120.7719 - val_MSE: 120.7719\n",
      "\n",
      "Epoch 01073: val_loss did not improve from 91.61790\n",
      "Epoch 1074/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 62.6627 - MSE: 62.6627 - val_loss: 142.9678 - val_MSE: 142.9678\n",
      "\n",
      "Epoch 01074: val_loss did not improve from 91.61790\n",
      "Epoch 1075/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 92.2050 - MSE: 92.2050 - val_loss: 164.9462 - val_MSE: 164.9462\n",
      "\n",
      "Epoch 01075: val_loss did not improve from 91.61790\n",
      "Epoch 1076/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 69.5144 - MSE: 69.5144 - val_loss: 116.3164 - val_MSE: 116.3164\n",
      "\n",
      "Epoch 01076: val_loss did not improve from 91.61790\n",
      "Epoch 1077/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 99.0277 - MSE: 99.0277 - val_loss: 147.5909 - val_MSE: 147.5909\n",
      "\n",
      "Epoch 01077: val_loss did not improve from 91.61790\n",
      "Epoch 1078/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 88.2240 - MSE: 88.2240 - val_loss: 131.7104 - val_MSE: 131.7104\n",
      "\n",
      "Epoch 01078: val_loss did not improve from 91.61790\n",
      "Epoch 1079/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 61.8674 - MSE: 61.8674 - val_loss: 144.6425 - val_MSE: 144.6425\n",
      "\n",
      "Epoch 01079: val_loss did not improve from 91.61790\n",
      "Epoch 1080/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 66.0038 - MSE: 66.0038 - val_loss: 151.3689 - val_MSE: 151.3689\n",
      "\n",
      "Epoch 01080: val_loss did not improve from 91.61790\n",
      "Epoch 1081/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 66.0383 - MSE: 66.0383 - val_loss: 191.1736 - val_MSE: 191.1736\n",
      "\n",
      "Epoch 01081: val_loss did not improve from 91.61790\n",
      "Epoch 1082/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 71.9451 - MSE: 71.9451 - val_loss: 132.0347 - val_MSE: 132.0347\n",
      "\n",
      "Epoch 01082: val_loss did not improve from 91.61790\n",
      "Epoch 1083/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 57.2025 - MSE: 57.2025 - val_loss: 149.2843 - val_MSE: 149.2843\n",
      "\n",
      "Epoch 01083: val_loss did not improve from 91.61790\n",
      "Epoch 1084/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 65.7665 - MSE: 65.7665 - val_loss: 138.0710 - val_MSE: 138.0710\n",
      "\n",
      "Epoch 01084: val_loss did not improve from 91.61790\n",
      "Epoch 1085/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 68.2731 - MSE: 68.2731 - val_loss: 129.7071 - val_MSE: 129.7071\n",
      "\n",
      "Epoch 01085: val_loss did not improve from 91.61790\n",
      "Epoch 1086/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 62.3762 - MSE: 62.3762 - val_loss: 131.5396 - val_MSE: 131.5396\n",
      "\n",
      "Epoch 01086: val_loss did not improve from 91.61790\n",
      "Epoch 1087/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 78.8114 - MSE: 78.8114 - val_loss: 128.3156 - val_MSE: 128.3156\n",
      "\n",
      "Epoch 01087: val_loss did not improve from 91.61790\n",
      "Epoch 1088/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 55.8145 - MSE: 55.8145 - val_loss: 103.3478 - val_MSE: 103.3478\n",
      "\n",
      "Epoch 01088: val_loss did not improve from 91.61790\n",
      "Epoch 1089/1500\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 67.6236 - MSE: 67.6236 - val_loss: 147.9321 - val_MSE: 147.9321\n",
      "\n",
      "Epoch 01089: val_loss did not improve from 91.61790\n",
      "Epoch 1090/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 45.4334 - MSE: 45.4334 - val_loss: 236.0815 - val_MSE: 236.0815\n",
      "\n",
      "Epoch 01090: val_loss did not improve from 91.61790\n",
      "Epoch 1091/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 170.3954 - MSE: 170.3954 - val_loss: 126.9223 - val_MSE: 126.9223\n",
      "\n",
      "Epoch 01091: val_loss did not improve from 91.61790\n",
      "Epoch 1092/1500\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 80.0519 - MSE: 80.0519 - val_loss: 127.2918 - val_MSE: 127.2918\n",
      "\n",
      "Epoch 01092: val_loss did not improve from 91.61790\n",
      "Epoch 1093/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 50.4279 - MSE: 50.4279 - val_loss: 133.3493 - val_MSE: 133.3493\n",
      "\n",
      "Epoch 01093: val_loss did not improve from 91.61790\n",
      "Epoch 1094/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 63.2860 - MSE: 63.2860 - val_loss: 176.6775 - val_MSE: 176.6775\n",
      "\n",
      "Epoch 01094: val_loss did not improve from 91.61790\n",
      "Epoch 1095/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 48.5594 - MSE: 48.5594 - val_loss: 151.6985 - val_MSE: 151.6985\n",
      "\n",
      "Epoch 01095: val_loss did not improve from 91.61790\n",
      "Epoch 1096/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 41.9810 - MSE: 41.9810 - val_loss: 152.5170 - val_MSE: 152.5170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01096: val_loss did not improve from 91.61790\n",
      "Epoch 1097/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 34.4911 - MSE: 34.4911 - val_loss: 204.2171 - val_MSE: 204.2171\n",
      "\n",
      "Epoch 01097: val_loss did not improve from 91.61790\n",
      "Epoch 1098/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 78.9844 - MSE: 78.9844 - val_loss: 136.3588 - val_MSE: 136.3588\n",
      "\n",
      "Epoch 01098: val_loss did not improve from 91.61790\n",
      "Epoch 1099/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 93.9169 - MSE: 93.9169 - val_loss: 135.9404 - val_MSE: 135.9404\n",
      "\n",
      "Epoch 01099: val_loss did not improve from 91.61790\n",
      "Epoch 1100/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 69.4257 - MSE: 69.4257 - val_loss: 135.5109 - val_MSE: 135.5109\n",
      "\n",
      "Epoch 01100: val_loss did not improve from 91.61790\n",
      "Epoch 1101/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 36.5728 - MSE: 36.5728 - val_loss: 127.5153 - val_MSE: 127.5153\n",
      "\n",
      "Epoch 01101: val_loss did not improve from 91.61790\n",
      "Epoch 1102/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 91.7724 - MSE: 91.7724 - val_loss: 128.3271 - val_MSE: 128.3271\n",
      "\n",
      "Epoch 01102: val_loss did not improve from 91.61790\n",
      "Epoch 1103/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 114.4243 - MSE: 114.4243 - val_loss: 127.9388 - val_MSE: 127.9388\n",
      "\n",
      "Epoch 01103: val_loss did not improve from 91.61790\n",
      "Epoch 1104/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 67.8801 - MSE: 67.8801 - val_loss: 141.8909 - val_MSE: 141.8909\n",
      "\n",
      "Epoch 01104: val_loss did not improve from 91.61790\n",
      "Epoch 1105/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 87.3360 - MSE: 87.3360 - val_loss: 134.2905 - val_MSE: 134.2905\n",
      "\n",
      "Epoch 01105: val_loss did not improve from 91.61790\n",
      "Epoch 1106/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 73.4016 - MSE: 73.4016 - val_loss: 140.5715 - val_MSE: 140.5715\n",
      "\n",
      "Epoch 01106: val_loss did not improve from 91.61790\n",
      "Epoch 1107/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 84.5697 - MSE: 84.5697 - val_loss: 152.1571 - val_MSE: 152.1571\n",
      "\n",
      "Epoch 01107: val_loss did not improve from 91.61790\n",
      "Epoch 1108/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 115.3912 - MSE: 115.3912 - val_loss: 140.8580 - val_MSE: 140.8580\n",
      "\n",
      "Epoch 01108: val_loss did not improve from 91.61790\n",
      "Epoch 1109/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 103.4652 - MSE: 103.4652 - val_loss: 160.3993 - val_MSE: 160.3993\n",
      "\n",
      "Epoch 01109: val_loss did not improve from 91.61790\n",
      "Epoch 1110/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 78.8546 - MSE: 78.8546 - val_loss: 157.6491 - val_MSE: 157.6491\n",
      "\n",
      "Epoch 01110: val_loss did not improve from 91.61790\n",
      "Epoch 1111/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 137.3649 - MSE: 137.3649 - val_loss: 184.0226 - val_MSE: 184.0226\n",
      "\n",
      "Epoch 01111: val_loss did not improve from 91.61790\n",
      "Epoch 1112/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 94.3478 - MSE: 94.3478 - val_loss: 160.9097 - val_MSE: 160.9097\n",
      "\n",
      "Epoch 01112: val_loss did not improve from 91.61790\n",
      "Epoch 1113/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 78.0935 - MSE: 78.0935 - val_loss: 157.0966 - val_MSE: 157.0966\n",
      "\n",
      "Epoch 01113: val_loss did not improve from 91.61790\n",
      "Epoch 1114/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 106.2089 - MSE: 106.2089 - val_loss: 137.8218 - val_MSE: 137.8218\n",
      "\n",
      "Epoch 01114: val_loss did not improve from 91.61790\n",
      "Epoch 1115/1500\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 95.6924 - MSE: 95.6924 - val_loss: 146.5356 - val_MSE: 146.5356\n",
      "\n",
      "Epoch 01115: val_loss did not improve from 91.61790\n",
      "Epoch 1116/1500\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 78.0784 - MSE: 78.0784 - val_loss: 147.9325 - val_MSE: 147.9325\n",
      "\n",
      "Epoch 01116: val_loss did not improve from 91.61790\n",
      "Epoch 1117/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 87.0206 - MSE: 87.0206 - val_loss: 151.6206 - val_MSE: 151.6206\n",
      "\n",
      "Epoch 01117: val_loss did not improve from 91.61790\n",
      "Epoch 1118/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 48.0340 - MSE: 48.0340 - val_loss: 140.4798 - val_MSE: 140.4798\n",
      "\n",
      "Epoch 01118: val_loss did not improve from 91.61790\n",
      "Epoch 1119/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 93.1394 - MSE: 93.1394 - val_loss: 146.9266 - val_MSE: 146.9266\n",
      "\n",
      "Epoch 01119: val_loss did not improve from 91.61790\n",
      "Epoch 1120/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 74.6581 - MSE: 74.6581 - val_loss: 193.0957 - val_MSE: 193.0957\n",
      "\n",
      "Epoch 01120: val_loss did not improve from 91.61790\n",
      "Epoch 1121/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 89.8498 - MSE: 89.8498 - val_loss: 150.9278 - val_MSE: 150.9278\n",
      "\n",
      "Epoch 01121: val_loss did not improve from 91.61790\n",
      "Epoch 1122/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 63.1993 - MSE: 63.1993 - val_loss: 154.7932 - val_MSE: 154.7932\n",
      "\n",
      "Epoch 01122: val_loss did not improve from 91.61790\n",
      "Epoch 1123/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 76.4745 - MSE: 76.4745 - val_loss: 183.6838 - val_MSE: 183.6838\n",
      "\n",
      "Epoch 01123: val_loss did not improve from 91.61790\n",
      "Epoch 1124/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 118.0760 - MSE: 118.0760 - val_loss: 224.5878 - val_MSE: 224.5878\n",
      "\n",
      "Epoch 01124: val_loss did not improve from 91.61790\n",
      "Epoch 1125/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 91.5074 - MSE: 91.5074 - val_loss: 194.6338 - val_MSE: 194.6338\n",
      "\n",
      "Epoch 01125: val_loss did not improve from 91.61790\n",
      "Epoch 1126/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 57.2581 - MSE: 57.2581 - val_loss: 161.5521 - val_MSE: 161.5521\n",
      "\n",
      "Epoch 01126: val_loss did not improve from 91.61790\n",
      "Epoch 1127/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 79.2533 - MSE: 79.2533 - val_loss: 160.6169 - val_MSE: 160.6169\n",
      "\n",
      "Epoch 01127: val_loss did not improve from 91.61790\n",
      "Epoch 1128/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 75.3512 - MSE: 75.3512 - val_loss: 147.8404 - val_MSE: 147.8404\n",
      "\n",
      "Epoch 01128: val_loss did not improve from 91.61790\n",
      "Epoch 1129/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 79.4438 - MSE: 79.4438 - val_loss: 154.6051 - val_MSE: 154.6051\n",
      "\n",
      "Epoch 01129: val_loss did not improve from 91.61790\n",
      "Epoch 1130/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 64.9619 - MSE: 64.9619 - val_loss: 145.8369 - val_MSE: 145.8369\n",
      "\n",
      "Epoch 01130: val_loss did not improve from 91.61790\n",
      "Epoch 1131/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 82.3092 - MSE: 82.3092 - val_loss: 241.4734 - val_MSE: 241.4734\n",
      "\n",
      "Epoch 01131: val_loss did not improve from 91.61790\n",
      "Epoch 1132/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 218.2760 - MSE: 218.2760 - val_loss: 226.8340 - val_MSE: 226.8340\n",
      "\n",
      "Epoch 01132: val_loss did not improve from 91.61790\n",
      "Epoch 1133/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 245.8309 - MSE: 245.8309 - val_loss: 213.8787 - val_MSE: 213.8787\n",
      "\n",
      "Epoch 01133: val_loss did not improve from 91.61790\n",
      "Epoch 1134/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 189.4263 - MSE: 189.4263 - val_loss: 175.7322 - val_MSE: 175.7322\n",
      "\n",
      "Epoch 01134: val_loss did not improve from 91.61790\n",
      "Epoch 1135/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 148.4205 - MSE: 148.4205 - val_loss: 172.6618 - val_MSE: 172.6618\n",
      "\n",
      "Epoch 01135: val_loss did not improve from 91.61790\n",
      "Epoch 1136/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 77.8501 - MSE: 77.8501 - val_loss: 180.8588 - val_MSE: 180.8588\n",
      "\n",
      "Epoch 01136: val_loss did not improve from 91.61790\n",
      "Epoch 1137/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 69.9385 - MSE: 69.9385 - val_loss: 166.0497 - val_MSE: 166.0497\n",
      "\n",
      "Epoch 01137: val_loss did not improve from 91.61790\n",
      "Epoch 1138/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 8ms/step - loss: 61.4128 - MSE: 61.4128 - val_loss: 177.8002 - val_MSE: 177.8002\n",
      "\n",
      "Epoch 01138: val_loss did not improve from 91.61790\n",
      "Epoch 1139/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 77.4460 - MSE: 77.4460 - val_loss: 171.3206 - val_MSE: 171.3206\n",
      "\n",
      "Epoch 01139: val_loss did not improve from 91.61790\n",
      "Epoch 1140/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 71.8329 - MSE: 71.8329 - val_loss: 157.5550 - val_MSE: 157.5550\n",
      "\n",
      "Epoch 01140: val_loss did not improve from 91.61790\n",
      "Epoch 1141/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 75.8886 - MSE: 75.8886 - val_loss: 182.8299 - val_MSE: 182.8299\n",
      "\n",
      "Epoch 01141: val_loss did not improve from 91.61790\n",
      "Epoch 1142/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 78.2405 - MSE: 78.2405 - val_loss: 171.3515 - val_MSE: 171.3515\n",
      "\n",
      "Epoch 01142: val_loss did not improve from 91.61790\n",
      "Epoch 1143/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 71.5725 - MSE: 71.5725 - val_loss: 157.9965 - val_MSE: 157.9965\n",
      "\n",
      "Epoch 01143: val_loss did not improve from 91.61790\n",
      "Epoch 1144/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 59.5629 - MSE: 59.5629 - val_loss: 158.0290 - val_MSE: 158.0290\n",
      "\n",
      "Epoch 01144: val_loss did not improve from 91.61790\n",
      "Epoch 1145/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 73.2269 - MSE: 73.2269 - val_loss: 153.6195 - val_MSE: 153.6195\n",
      "\n",
      "Epoch 01145: val_loss did not improve from 91.61790\n",
      "Epoch 1146/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 98.1917 - MSE: 98.1917 - val_loss: 169.9426 - val_MSE: 169.9426\n",
      "\n",
      "Epoch 01146: val_loss did not improve from 91.61790\n",
      "Epoch 1147/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 87.6145 - MSE: 87.6145 - val_loss: 157.9234 - val_MSE: 157.9234\n",
      "\n",
      "Epoch 01147: val_loss did not improve from 91.61790\n",
      "Epoch 1148/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 75.9933 - MSE: 75.9933 - val_loss: 171.6135 - val_MSE: 171.6135\n",
      "\n",
      "Epoch 01148: val_loss did not improve from 91.61790\n",
      "Epoch 1149/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 89.4074 - MSE: 89.4074 - val_loss: 161.2309 - val_MSE: 161.2309\n",
      "\n",
      "Epoch 01149: val_loss did not improve from 91.61790\n",
      "Epoch 1150/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 73.3411 - MSE: 73.3411 - val_loss: 160.7535 - val_MSE: 160.7535\n",
      "\n",
      "Epoch 01150: val_loss did not improve from 91.61790\n",
      "Epoch 1151/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 79.1882 - MSE: 79.1882 - val_loss: 191.4999 - val_MSE: 191.4999\n",
      "\n",
      "Epoch 01151: val_loss did not improve from 91.61790\n",
      "Epoch 1152/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 108.1005 - MSE: 108.1005 - val_loss: 157.6128 - val_MSE: 157.6128\n",
      "\n",
      "Epoch 01152: val_loss did not improve from 91.61790\n",
      "Epoch 1153/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 76.8728 - MSE: 76.8728 - val_loss: 159.7761 - val_MSE: 159.7761\n",
      "\n",
      "Epoch 01153: val_loss did not improve from 91.61790\n",
      "Epoch 1154/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 84.6789 - MSE: 84.6789 - val_loss: 155.6616 - val_MSE: 155.6616\n",
      "\n",
      "Epoch 01154: val_loss did not improve from 91.61790\n",
      "Epoch 1155/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 91.4624 - MSE: 91.4624 - val_loss: 122.4771 - val_MSE: 122.4771\n",
      "\n",
      "Epoch 01155: val_loss did not improve from 91.61790\n",
      "Epoch 1156/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 95.0698 - MSE: 95.0698 - val_loss: 144.3824 - val_MSE: 144.3824\n",
      "\n",
      "Epoch 01156: val_loss did not improve from 91.61790\n",
      "Epoch 1157/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 62.3955 - MSE: 62.3955 - val_loss: 175.6725 - val_MSE: 175.6725\n",
      "\n",
      "Epoch 01157: val_loss did not improve from 91.61790\n",
      "Epoch 1158/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 104.9814 - MSE: 104.9814 - val_loss: 149.0461 - val_MSE: 149.0461\n",
      "\n",
      "Epoch 01158: val_loss did not improve from 91.61790\n",
      "Epoch 1159/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 87.5435 - MSE: 87.5435 - val_loss: 149.4124 - val_MSE: 149.4124\n",
      "\n",
      "Epoch 01159: val_loss did not improve from 91.61790\n",
      "Epoch 1160/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 74.1100 - MSE: 74.1100 - val_loss: 155.8578 - val_MSE: 155.8578\n",
      "\n",
      "Epoch 01160: val_loss did not improve from 91.61790\n",
      "Epoch 1161/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 84.1305 - MSE: 84.1305 - val_loss: 159.8192 - val_MSE: 159.8192\n",
      "\n",
      "Epoch 01161: val_loss did not improve from 91.61790\n",
      "Epoch 1162/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 103.8257 - MSE: 103.8257 - val_loss: 155.0237 - val_MSE: 155.0237\n",
      "\n",
      "Epoch 01162: val_loss did not improve from 91.61790\n",
      "Epoch 1163/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 88.1857 - MSE: 88.1857 - val_loss: 158.8923 - val_MSE: 158.8923\n",
      "\n",
      "Epoch 01163: val_loss did not improve from 91.61790\n",
      "Epoch 1164/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 78.9462 - MSE: 78.9462 - val_loss: 147.9640 - val_MSE: 147.9640\n",
      "\n",
      "Epoch 01164: val_loss did not improve from 91.61790\n",
      "Epoch 1165/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 66.4458 - MSE: 66.4458 - val_loss: 187.6604 - val_MSE: 187.6604\n",
      "\n",
      "Epoch 01165: val_loss did not improve from 91.61790\n",
      "Epoch 1166/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 105.7485 - MSE: 105.7485 - val_loss: 170.3208 - val_MSE: 170.3208\n",
      "\n",
      "Epoch 01166: val_loss did not improve from 91.61790\n",
      "Epoch 1167/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 51.1436 - MSE: 51.1436 - val_loss: 167.3411 - val_MSE: 167.3411\n",
      "\n",
      "Epoch 01167: val_loss did not improve from 91.61790\n",
      "Epoch 1168/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 59.1429 - MSE: 59.1429 - val_loss: 180.2984 - val_MSE: 180.2984\n",
      "\n",
      "Epoch 01168: val_loss did not improve from 91.61790\n",
      "Epoch 1169/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 64.0622 - MSE: 64.0622 - val_loss: 192.9478 - val_MSE: 192.9478\n",
      "\n",
      "Epoch 01169: val_loss did not improve from 91.61790\n",
      "Epoch 1170/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 71.4952 - MSE: 71.4952 - val_loss: 165.1136 - val_MSE: 165.1136\n",
      "\n",
      "Epoch 01170: val_loss did not improve from 91.61790\n",
      "Epoch 1171/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 115.8836 - MSE: 115.8836 - val_loss: 150.4450 - val_MSE: 150.4450\n",
      "\n",
      "Epoch 01171: val_loss did not improve from 91.61790\n",
      "Epoch 1172/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 62.8852 - MSE: 62.8852 - val_loss: 154.8420 - val_MSE: 154.8420\n",
      "\n",
      "Epoch 01172: val_loss did not improve from 91.61790\n",
      "Epoch 1173/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 70.6177 - MSE: 70.6177 - val_loss: 168.6238 - val_MSE: 168.6238\n",
      "\n",
      "Epoch 01173: val_loss did not improve from 91.61790\n",
      "Epoch 1174/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 69.2805 - MSE: 69.2805 - val_loss: 160.0881 - val_MSE: 160.0881\n",
      "\n",
      "Epoch 01174: val_loss did not improve from 91.61790\n",
      "Epoch 1175/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 93.3115 - MSE: 93.3115 - val_loss: 161.1800 - val_MSE: 161.1800\n",
      "\n",
      "Epoch 01175: val_loss did not improve from 91.61790\n",
      "Epoch 1176/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 72.9220 - MSE: 72.9220 - val_loss: 157.8434 - val_MSE: 157.8434\n",
      "\n",
      "Epoch 01176: val_loss did not improve from 91.61790\n",
      "Epoch 1177/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 85.7915 - MSE: 85.7915 - val_loss: 156.0678 - val_MSE: 156.0678\n",
      "\n",
      "Epoch 01177: val_loss did not improve from 91.61790\n",
      "Epoch 1178/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 79.3411 - MSE: 79.3411 - val_loss: 184.0444 - val_MSE: 184.0444\n",
      "\n",
      "Epoch 01178: val_loss did not improve from 91.61790\n",
      "Epoch 1179/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 60.9806 - MSE: 60.9806 - val_loss: 173.7190 - val_MSE: 173.7190\n",
      "\n",
      "Epoch 01179: val_loss did not improve from 91.61790\n",
      "Epoch 1180/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 8ms/step - loss: 89.9403 - MSE: 89.9403 - val_loss: 151.6960 - val_MSE: 151.6960\n",
      "\n",
      "Epoch 01180: val_loss did not improve from 91.61790\n",
      "Epoch 1181/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 95.9968 - MSE: 95.9968 - val_loss: 153.0949 - val_MSE: 153.0949\n",
      "\n",
      "Epoch 01181: val_loss did not improve from 91.61790\n",
      "Epoch 1182/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 82.7993 - MSE: 82.7993 - val_loss: 165.3088 - val_MSE: 165.3088\n",
      "\n",
      "Epoch 01182: val_loss did not improve from 91.61790\n",
      "Epoch 1183/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 63.8268 - MSE: 63.8268 - val_loss: 205.6727 - val_MSE: 205.6727\n",
      "\n",
      "Epoch 01183: val_loss did not improve from 91.61790\n",
      "Epoch 1184/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 114.8597 - MSE: 114.8597 - val_loss: 149.2861 - val_MSE: 149.2861\n",
      "\n",
      "Epoch 01184: val_loss did not improve from 91.61790\n",
      "Epoch 1185/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 74.9409 - MSE: 74.9409 - val_loss: 143.5835 - val_MSE: 143.5835\n",
      "\n",
      "Epoch 01185: val_loss did not improve from 91.61790\n",
      "Epoch 1186/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 66.2925 - MSE: 66.2925 - val_loss: 152.2266 - val_MSE: 152.2266\n",
      "\n",
      "Epoch 01186: val_loss did not improve from 91.61790\n",
      "Epoch 1187/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 87.2660 - MSE: 87.2660 - val_loss: 146.3049 - val_MSE: 146.3049\n",
      "\n",
      "Epoch 01187: val_loss did not improve from 91.61790\n",
      "Epoch 1188/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 81.1042 - MSE: 81.1042 - val_loss: 169.1222 - val_MSE: 169.1222\n",
      "\n",
      "Epoch 01188: val_loss did not improve from 91.61790\n",
      "Epoch 1189/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 83.1896 - MSE: 83.1896 - val_loss: 181.2442 - val_MSE: 181.2442\n",
      "\n",
      "Epoch 01189: val_loss did not improve from 91.61790\n",
      "Epoch 1190/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 101.6560 - MSE: 101.6560 - val_loss: 163.4913 - val_MSE: 163.4913\n",
      "\n",
      "Epoch 01190: val_loss did not improve from 91.61790\n",
      "Epoch 1191/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 65.4326 - MSE: 65.4326 - val_loss: 155.9374 - val_MSE: 155.9374\n",
      "\n",
      "Epoch 01191: val_loss did not improve from 91.61790\n",
      "Epoch 1192/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 72.9253 - MSE: 72.9253 - val_loss: 159.7573 - val_MSE: 159.7573\n",
      "\n",
      "Epoch 01192: val_loss did not improve from 91.61790\n",
      "Epoch 1193/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 121.1027 - MSE: 121.1027 - val_loss: 144.9118 - val_MSE: 144.9118\n",
      "\n",
      "Epoch 01193: val_loss did not improve from 91.61790\n",
      "Epoch 1194/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 85.8095 - MSE: 85.8095 - val_loss: 147.2153 - val_MSE: 147.2153\n",
      "\n",
      "Epoch 01194: val_loss did not improve from 91.61790\n",
      "Epoch 1195/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 104.6446 - MSE: 104.6446 - val_loss: 161.2010 - val_MSE: 161.2010\n",
      "\n",
      "Epoch 01195: val_loss did not improve from 91.61790\n",
      "Epoch 1196/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 105.5801 - MSE: 105.5801 - val_loss: 190.7726 - val_MSE: 190.7726\n",
      "\n",
      "Epoch 01196: val_loss did not improve from 91.61790\n",
      "Epoch 1197/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 97.4324 - MSE: 97.4324 - val_loss: 181.8898 - val_MSE: 181.8898\n",
      "\n",
      "Epoch 01197: val_loss did not improve from 91.61790\n",
      "Epoch 1198/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 61.6422 - MSE: 61.6422 - val_loss: 205.0164 - val_MSE: 205.0164\n",
      "\n",
      "Epoch 01198: val_loss did not improve from 91.61790\n",
      "Epoch 1199/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 83.9599 - MSE: 83.9599 - val_loss: 167.5859 - val_MSE: 167.5859\n",
      "\n",
      "Epoch 01199: val_loss did not improve from 91.61790\n",
      "Epoch 1200/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 68.3167 - MSE: 68.3167 - val_loss: 153.6361 - val_MSE: 153.6361\n",
      "\n",
      "Epoch 01200: val_loss did not improve from 91.61790\n",
      "Epoch 1201/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 73.3347 - MSE: 73.3347 - val_loss: 163.3982 - val_MSE: 163.3982\n",
      "\n",
      "Epoch 01201: val_loss did not improve from 91.61790\n",
      "Epoch 1202/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 87.3641 - MSE: 87.3641 - val_loss: 182.5396 - val_MSE: 182.5396\n",
      "\n",
      "Epoch 01202: val_loss did not improve from 91.61790\n",
      "Epoch 1203/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 43.7081 - MSE: 43.7081 - val_loss: 212.6370 - val_MSE: 212.6370\n",
      "\n",
      "Epoch 01203: val_loss did not improve from 91.61790\n",
      "Epoch 1204/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 72.2910 - MSE: 72.2910 - val_loss: 158.4748 - val_MSE: 158.4748\n",
      "\n",
      "Epoch 01204: val_loss did not improve from 91.61790\n",
      "Epoch 1205/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 76.6365 - MSE: 76.6365 - val_loss: 145.0371 - val_MSE: 145.0371\n",
      "\n",
      "Epoch 01205: val_loss did not improve from 91.61790\n",
      "Epoch 1206/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 109.4619 - MSE: 109.4619 - val_loss: 222.4339 - val_MSE: 222.4339\n",
      "\n",
      "Epoch 01206: val_loss did not improve from 91.61790\n",
      "Epoch 1207/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 128.4886 - MSE: 128.4886 - val_loss: 145.3410 - val_MSE: 145.3410\n",
      "\n",
      "Epoch 01207: val_loss did not improve from 91.61790\n",
      "Epoch 1208/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 90.7995 - MSE: 90.7995 - val_loss: 182.5853 - val_MSE: 182.5853\n",
      "\n",
      "Epoch 01208: val_loss did not improve from 91.61790\n",
      "Epoch 1209/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 87.8962 - MSE: 87.8962 - val_loss: 166.8055 - val_MSE: 166.8055\n",
      "\n",
      "Epoch 01209: val_loss did not improve from 91.61790\n",
      "Epoch 1210/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 53.1757 - MSE: 53.1757 - val_loss: 135.6963 - val_MSE: 135.6963\n",
      "\n",
      "Epoch 01210: val_loss did not improve from 91.61790\n",
      "Epoch 1211/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 41.4090 - MSE: 41.4090 - val_loss: 178.6069 - val_MSE: 178.6069\n",
      "\n",
      "Epoch 01211: val_loss did not improve from 91.61790\n",
      "Epoch 1212/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 49.0413 - MSE: 49.0413 - val_loss: 142.0049 - val_MSE: 142.0049\n",
      "\n",
      "Epoch 01212: val_loss did not improve from 91.61790\n",
      "Epoch 1213/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 70.2758 - MSE: 70.2758 - val_loss: 152.4471 - val_MSE: 152.4471\n",
      "\n",
      "Epoch 01213: val_loss did not improve from 91.61790\n",
      "Epoch 1214/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 51.2320 - MSE: 51.2320 - val_loss: 158.6134 - val_MSE: 158.6134\n",
      "\n",
      "Epoch 01214: val_loss did not improve from 91.61790\n",
      "Epoch 1215/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 74.1799 - MSE: 74.1799 - val_loss: 135.5015 - val_MSE: 135.5015\n",
      "\n",
      "Epoch 01215: val_loss did not improve from 91.61790\n",
      "Epoch 1216/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 57.7458 - MSE: 57.7458 - val_loss: 171.6059 - val_MSE: 171.6059\n",
      "\n",
      "Epoch 01216: val_loss did not improve from 91.61790\n",
      "Epoch 1217/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 73.6566 - MSE: 73.6566 - val_loss: 186.1738 - val_MSE: 186.1738\n",
      "\n",
      "Epoch 01217: val_loss did not improve from 91.61790\n",
      "Epoch 1218/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 83.6125 - MSE: 83.6125 - val_loss: 157.1268 - val_MSE: 157.1268\n",
      "\n",
      "Epoch 01218: val_loss did not improve from 91.61790\n",
      "Epoch 1219/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 113.8387 - MSE: 113.8387 - val_loss: 200.7483 - val_MSE: 200.7483\n",
      "\n",
      "Epoch 01219: val_loss did not improve from 91.61790\n",
      "Epoch 1220/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 86.6488 - MSE: 86.6488 - val_loss: 173.4478 - val_MSE: 173.4478\n",
      "\n",
      "Epoch 01220: val_loss did not improve from 91.61790\n",
      "Epoch 1221/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 89.6215 - MSE: 89.6215 - val_loss: 187.9042 - val_MSE: 187.9042\n",
      "\n",
      "Epoch 01221: val_loss did not improve from 91.61790\n",
      "Epoch 1222/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 8ms/step - loss: 82.2384 - MSE: 82.2384 - val_loss: 244.2658 - val_MSE: 244.2658\n",
      "\n",
      "Epoch 01222: val_loss did not improve from 91.61790\n",
      "Epoch 1223/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 98.8664 - MSE: 98.8664 - val_loss: 163.8094 - val_MSE: 163.8094\n",
      "\n",
      "Epoch 01223: val_loss did not improve from 91.61790\n",
      "Epoch 1224/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 77.2384 - MSE: 77.2384 - val_loss: 175.6581 - val_MSE: 175.6581\n",
      "\n",
      "Epoch 01224: val_loss did not improve from 91.61790\n",
      "Epoch 1225/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 82.9961 - MSE: 82.9961 - val_loss: 170.4103 - val_MSE: 170.4103\n",
      "\n",
      "Epoch 01225: val_loss did not improve from 91.61790\n",
      "Epoch 1226/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 101.7296 - MSE: 101.7296 - val_loss: 162.2138 - val_MSE: 162.2138\n",
      "\n",
      "Epoch 01226: val_loss did not improve from 91.61790\n",
      "Epoch 1227/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 77.0181 - MSE: 77.0181 - val_loss: 276.2186 - val_MSE: 276.2186\n",
      "\n",
      "Epoch 01227: val_loss did not improve from 91.61790\n",
      "Epoch 1228/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 110.8683 - MSE: 110.8683 - val_loss: 179.6351 - val_MSE: 179.6351\n",
      "\n",
      "Epoch 01228: val_loss did not improve from 91.61790\n",
      "Epoch 1229/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 70.0434 - MSE: 70.0434 - val_loss: 158.7818 - val_MSE: 158.7818\n",
      "\n",
      "Epoch 01229: val_loss did not improve from 91.61790\n",
      "Epoch 1230/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 60.2111 - MSE: 60.2111 - val_loss: 156.0554 - val_MSE: 156.0554\n",
      "\n",
      "Epoch 01230: val_loss did not improve from 91.61790\n",
      "Epoch 1231/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 86.5177 - MSE: 86.5177 - val_loss: 182.9115 - val_MSE: 182.9115\n",
      "\n",
      "Epoch 01231: val_loss did not improve from 91.61790\n",
      "Epoch 1232/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 61.4438 - MSE: 61.4438 - val_loss: 219.5339 - val_MSE: 219.5339\n",
      "\n",
      "Epoch 01232: val_loss did not improve from 91.61790\n",
      "Epoch 1233/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 82.1021 - MSE: 82.1021 - val_loss: 211.4961 - val_MSE: 211.4961\n",
      "\n",
      "Epoch 01233: val_loss did not improve from 91.61790\n",
      "Epoch 1234/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 72.5928 - MSE: 72.5928 - val_loss: 161.5277 - val_MSE: 161.5277\n",
      "\n",
      "Epoch 01234: val_loss did not improve from 91.61790\n",
      "Epoch 1235/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 75.0182 - MSE: 75.0182 - val_loss: 185.9434 - val_MSE: 185.9434\n",
      "\n",
      "Epoch 01235: val_loss did not improve from 91.61790\n",
      "Epoch 1236/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 85.8780 - MSE: 85.8780 - val_loss: 160.5980 - val_MSE: 160.5980\n",
      "\n",
      "Epoch 01236: val_loss did not improve from 91.61790\n",
      "Epoch 1237/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 75.0252 - MSE: 75.0252 - val_loss: 166.6816 - val_MSE: 166.6816\n",
      "\n",
      "Epoch 01237: val_loss did not improve from 91.61790\n",
      "Epoch 1238/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 66.4474 - MSE: 66.4474 - val_loss: 151.9610 - val_MSE: 151.9610\n",
      "\n",
      "Epoch 01238: val_loss did not improve from 91.61790\n",
      "Epoch 1239/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 60.9586 - MSE: 60.9586 - val_loss: 140.9107 - val_MSE: 140.9107\n",
      "\n",
      "Epoch 01239: val_loss did not improve from 91.61790\n",
      "Epoch 1240/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 56.5261 - MSE: 56.5261 - val_loss: 135.4825 - val_MSE: 135.4825\n",
      "\n",
      "Epoch 01240: val_loss did not improve from 91.61790\n",
      "Epoch 1241/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 64.9443 - MSE: 64.9443 - val_loss: 150.3741 - val_MSE: 150.3741\n",
      "\n",
      "Epoch 01241: val_loss did not improve from 91.61790\n",
      "Epoch 1242/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 89.2466 - MSE: 89.2466 - val_loss: 156.7183 - val_MSE: 156.7183\n",
      "\n",
      "Epoch 01242: val_loss did not improve from 91.61790\n",
      "Epoch 1243/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 84.7700 - MSE: 84.7700 - val_loss: 176.0998 - val_MSE: 176.0998\n",
      "\n",
      "Epoch 01243: val_loss did not improve from 91.61790\n",
      "Epoch 1244/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 85.9435 - MSE: 85.9435 - val_loss: 148.9715 - val_MSE: 148.9715\n",
      "\n",
      "Epoch 01244: val_loss did not improve from 91.61790\n",
      "Epoch 1245/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 68.7750 - MSE: 68.7750 - val_loss: 171.7463 - val_MSE: 171.7463\n",
      "\n",
      "Epoch 01245: val_loss did not improve from 91.61790\n",
      "Epoch 1246/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 77.8303 - MSE: 77.8303 - val_loss: 143.4605 - val_MSE: 143.4605\n",
      "\n",
      "Epoch 01246: val_loss did not improve from 91.61790\n",
      "Epoch 1247/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 69.3005 - MSE: 69.3005 - val_loss: 137.1324 - val_MSE: 137.1324\n",
      "\n",
      "Epoch 01247: val_loss did not improve from 91.61790\n",
      "Epoch 1248/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 66.5937 - MSE: 66.5937 - val_loss: 152.1687 - val_MSE: 152.1687\n",
      "\n",
      "Epoch 01248: val_loss did not improve from 91.61790\n",
      "Epoch 1249/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 85.8479 - MSE: 85.8479 - val_loss: 173.6172 - val_MSE: 173.6172\n",
      "\n",
      "Epoch 01249: val_loss did not improve from 91.61790\n",
      "Epoch 1250/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 103.6689 - MSE: 103.6689 - val_loss: 136.9739 - val_MSE: 136.9739\n",
      "\n",
      "Epoch 01250: val_loss did not improve from 91.61790\n",
      "Epoch 1251/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 60.1496 - MSE: 60.1496 - val_loss: 153.5644 - val_MSE: 153.5644\n",
      "\n",
      "Epoch 01251: val_loss did not improve from 91.61790\n",
      "Epoch 1252/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 47.5886 - MSE: 47.5886 - val_loss: 182.5605 - val_MSE: 182.5605\n",
      "\n",
      "Epoch 01252: val_loss did not improve from 91.61790\n",
      "Epoch 1253/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 42.4701 - MSE: 42.4701 - val_loss: 148.1602 - val_MSE: 148.1602\n",
      "\n",
      "Epoch 01253: val_loss did not improve from 91.61790\n",
      "Epoch 1254/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 116.4641 - MSE: 116.4641 - val_loss: 143.4622 - val_MSE: 143.4622\n",
      "\n",
      "Epoch 01254: val_loss did not improve from 91.61790\n",
      "Epoch 1255/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 52.2349 - MSE: 52.2349 - val_loss: 171.2404 - val_MSE: 171.2404\n",
      "\n",
      "Epoch 01255: val_loss did not improve from 91.61790\n",
      "Epoch 1256/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 82.4872 - MSE: 82.4872 - val_loss: 148.0562 - val_MSE: 148.0562\n",
      "\n",
      "Epoch 01256: val_loss did not improve from 91.61790\n",
      "Epoch 1257/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 80.7055 - MSE: 80.7055 - val_loss: 183.0973 - val_MSE: 183.0973\n",
      "\n",
      "Epoch 01257: val_loss did not improve from 91.61790\n",
      "Epoch 1258/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 84.1642 - MSE: 84.1642 - val_loss: 171.3634 - val_MSE: 171.3634\n",
      "\n",
      "Epoch 01258: val_loss did not improve from 91.61790\n",
      "Epoch 1259/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 56.4030 - MSE: 56.4030 - val_loss: 175.2435 - val_MSE: 175.2435\n",
      "\n",
      "Epoch 01259: val_loss did not improve from 91.61790\n",
      "Epoch 1260/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 56.5743 - MSE: 56.5743 - val_loss: 190.8134 - val_MSE: 190.8134\n",
      "\n",
      "Epoch 01260: val_loss did not improve from 91.61790\n",
      "Epoch 1261/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 86.8515 - MSE: 86.8515 - val_loss: 205.8224 - val_MSE: 205.8224\n",
      "\n",
      "Epoch 01261: val_loss did not improve from 91.61790\n",
      "Epoch 1262/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 95.6137 - MSE: 95.6137 - val_loss: 156.2554 - val_MSE: 156.2554\n",
      "\n",
      "Epoch 01262: val_loss did not improve from 91.61790\n",
      "Epoch 1263/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 68.0040 - MSE: 68.0040 - val_loss: 160.5848 - val_MSE: 160.5848\n",
      "\n",
      "Epoch 01263: val_loss did not improve from 91.61790\n",
      "Epoch 1264/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 8ms/step - loss: 120.0088 - MSE: 120.0088 - val_loss: 153.6537 - val_MSE: 153.6537\n",
      "\n",
      "Epoch 01264: val_loss did not improve from 91.61790\n",
      "Epoch 1265/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 58.7262 - MSE: 58.7262 - val_loss: 187.0871 - val_MSE: 187.0871\n",
      "\n",
      "Epoch 01265: val_loss did not improve from 91.61790\n",
      "Epoch 1266/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 77.6580 - MSE: 77.6580 - val_loss: 172.1053 - val_MSE: 172.1053\n",
      "\n",
      "Epoch 01266: val_loss did not improve from 91.61790\n",
      "Epoch 1267/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 79.9807 - MSE: 79.9807 - val_loss: 183.2318 - val_MSE: 183.2318\n",
      "\n",
      "Epoch 01267: val_loss did not improve from 91.61790\n",
      "Epoch 1268/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 43.4870 - MSE: 43.4870 - val_loss: 189.0346 - val_MSE: 189.0346\n",
      "\n",
      "Epoch 01268: val_loss did not improve from 91.61790\n",
      "Epoch 1269/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 53.9978 - MSE: 53.9978 - val_loss: 154.1709 - val_MSE: 154.1709\n",
      "\n",
      "Epoch 01269: val_loss did not improve from 91.61790\n",
      "Epoch 1270/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 76.2371 - MSE: 76.2371 - val_loss: 155.2390 - val_MSE: 155.2390\n",
      "\n",
      "Epoch 01270: val_loss did not improve from 91.61790\n",
      "Epoch 1271/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 88.9560 - MSE: 88.9560 - val_loss: 193.0874 - val_MSE: 193.0874\n",
      "\n",
      "Epoch 01271: val_loss did not improve from 91.61790\n",
      "Epoch 1272/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 67.1742 - MSE: 67.1742 - val_loss: 155.7610 - val_MSE: 155.7610\n",
      "\n",
      "Epoch 01272: val_loss did not improve from 91.61790\n",
      "Epoch 1273/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 72.1913 - MSE: 72.1913 - val_loss: 165.7794 - val_MSE: 165.7794\n",
      "\n",
      "Epoch 01273: val_loss did not improve from 91.61790\n",
      "Epoch 1274/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 108.4287 - MSE: 108.4287 - val_loss: 155.0079 - val_MSE: 155.0079\n",
      "\n",
      "Epoch 01274: val_loss did not improve from 91.61790\n",
      "Epoch 1275/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 115.7150 - MSE: 115.7150 - val_loss: 157.6418 - val_MSE: 157.6418\n",
      "\n",
      "Epoch 01275: val_loss did not improve from 91.61790\n",
      "Epoch 1276/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 89.8881 - MSE: 89.8881 - val_loss: 175.3237 - val_MSE: 175.3237\n",
      "\n",
      "Epoch 01276: val_loss did not improve from 91.61790\n",
      "Epoch 1277/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 67.6360 - MSE: 67.6360 - val_loss: 154.3604 - val_MSE: 154.3604\n",
      "\n",
      "Epoch 01277: val_loss did not improve from 91.61790\n",
      "Epoch 1278/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 87.6683 - MSE: 87.6683 - val_loss: 220.4987 - val_MSE: 220.4987\n",
      "\n",
      "Epoch 01278: val_loss did not improve from 91.61790\n",
      "Epoch 1279/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 107.8007 - MSE: 107.8007 - val_loss: 174.8217 - val_MSE: 174.8217\n",
      "\n",
      "Epoch 01279: val_loss did not improve from 91.61790\n",
      "Epoch 1280/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 57.4415 - MSE: 57.4415 - val_loss: 191.8246 - val_MSE: 191.8246\n",
      "\n",
      "Epoch 01280: val_loss did not improve from 91.61790\n",
      "Epoch 1281/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 101.8725 - MSE: 101.8725 - val_loss: 161.6536 - val_MSE: 161.6536\n",
      "\n",
      "Epoch 01281: val_loss did not improve from 91.61790\n",
      "Epoch 1282/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 66.5697 - MSE: 66.5697 - val_loss: 151.0134 - val_MSE: 151.0134\n",
      "\n",
      "Epoch 01282: val_loss did not improve from 91.61790\n",
      "Epoch 1283/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 58.9332 - MSE: 58.9332 - val_loss: 164.4778 - val_MSE: 164.4778\n",
      "\n",
      "Epoch 01283: val_loss did not improve from 91.61790\n",
      "Epoch 1284/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 86.9420 - MSE: 86.9420 - val_loss: 180.8713 - val_MSE: 180.8713\n",
      "\n",
      "Epoch 01284: val_loss did not improve from 91.61790\n",
      "Epoch 1285/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 109.0373 - MSE: 109.0373 - val_loss: 186.5957 - val_MSE: 186.5957\n",
      "\n",
      "Epoch 01285: val_loss did not improve from 91.61790\n",
      "Epoch 1286/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 61.9942 - MSE: 61.9942 - val_loss: 165.5965 - val_MSE: 165.5965\n",
      "\n",
      "Epoch 01286: val_loss did not improve from 91.61790\n",
      "Epoch 1287/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 81.0814 - MSE: 81.0814 - val_loss: 171.9164 - val_MSE: 171.9164\n",
      "\n",
      "Epoch 01287: val_loss did not improve from 91.61790\n",
      "Epoch 1288/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 101.8194 - MSE: 101.8194 - val_loss: 161.5205 - val_MSE: 161.5205\n",
      "\n",
      "Epoch 01288: val_loss did not improve from 91.61790\n",
      "Epoch 1289/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 46.9858 - MSE: 46.9858 - val_loss: 145.1219 - val_MSE: 145.1219\n",
      "\n",
      "Epoch 01289: val_loss did not improve from 91.61790\n",
      "Epoch 1290/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 62.9060 - MSE: 62.9060 - val_loss: 205.7168 - val_MSE: 205.7168\n",
      "\n",
      "Epoch 01290: val_loss did not improve from 91.61790\n",
      "Epoch 1291/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 65.4886 - MSE: 65.4886 - val_loss: 150.5044 - val_MSE: 150.5044\n",
      "\n",
      "Epoch 01291: val_loss did not improve from 91.61790\n",
      "Epoch 1292/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 75.7894 - MSE: 75.7894 - val_loss: 152.0012 - val_MSE: 152.0012\n",
      "\n",
      "Epoch 01292: val_loss did not improve from 91.61790\n",
      "Epoch 1293/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 75.2275 - MSE: 75.2275 - val_loss: 151.6118 - val_MSE: 151.6118\n",
      "\n",
      "Epoch 01293: val_loss did not improve from 91.61790\n",
      "Epoch 1294/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 66.7900 - MSE: 66.7900 - val_loss: 221.8026 - val_MSE: 221.8026\n",
      "\n",
      "Epoch 01294: val_loss did not improve from 91.61790\n",
      "Epoch 1295/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 84.0741 - MSE: 84.0741 - val_loss: 262.3012 - val_MSE: 262.3012\n",
      "\n",
      "Epoch 01295: val_loss did not improve from 91.61790\n",
      "Epoch 1296/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 76.2949 - MSE: 76.2949 - val_loss: 173.6897 - val_MSE: 173.6897\n",
      "\n",
      "Epoch 01296: val_loss did not improve from 91.61790\n",
      "Epoch 1297/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 49.7967 - MSE: 49.7967 - val_loss: 212.2019 - val_MSE: 212.2019\n",
      "\n",
      "Epoch 01297: val_loss did not improve from 91.61790\n",
      "Epoch 1298/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 101.9490 - MSE: 101.9490 - val_loss: 159.3351 - val_MSE: 159.3351\n",
      "\n",
      "Epoch 01298: val_loss did not improve from 91.61790\n",
      "Epoch 1299/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 63.5154 - MSE: 63.5154 - val_loss: 186.0334 - val_MSE: 186.0334\n",
      "\n",
      "Epoch 01299: val_loss did not improve from 91.61790\n",
      "Epoch 1300/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 68.1797 - MSE: 68.1797 - val_loss: 145.3533 - val_MSE: 145.3533\n",
      "\n",
      "Epoch 01300: val_loss did not improve from 91.61790\n",
      "Epoch 1301/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 69.8451 - MSE: 69.8451 - val_loss: 149.4315 - val_MSE: 149.4315\n",
      "\n",
      "Epoch 01301: val_loss did not improve from 91.61790\n",
      "Epoch 1302/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 73.4808 - MSE: 73.4808 - val_loss: 168.9150 - val_MSE: 168.9150\n",
      "\n",
      "Epoch 01302: val_loss did not improve from 91.61790\n",
      "Epoch 1303/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 73.1413 - MSE: 73.1413 - val_loss: 168.1183 - val_MSE: 168.1183\n",
      "\n",
      "Epoch 01303: val_loss did not improve from 91.61790\n",
      "Epoch 1304/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 57.1433 - MSE: 57.1433 - val_loss: 206.4387 - val_MSE: 206.4387\n",
      "\n",
      "Epoch 01304: val_loss did not improve from 91.61790\n",
      "Epoch 1305/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 81.2785 - MSE: 81.2785 - val_loss: 188.6840 - val_MSE: 188.6840\n",
      "\n",
      "Epoch 01305: val_loss did not improve from 91.61790\n",
      "Epoch 1306/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 7ms/step - loss: 71.1741 - MSE: 71.1741 - val_loss: 153.1491 - val_MSE: 153.1491\n",
      "\n",
      "Epoch 01306: val_loss did not improve from 91.61790\n",
      "Epoch 1307/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 77.6532 - MSE: 77.6532 - val_loss: 151.1482 - val_MSE: 151.1482\n",
      "\n",
      "Epoch 01307: val_loss did not improve from 91.61790\n",
      "Epoch 1308/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 47.6519 - MSE: 47.6519 - val_loss: 156.2716 - val_MSE: 156.2716\n",
      "\n",
      "Epoch 01308: val_loss did not improve from 91.61790\n",
      "Epoch 1309/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 90.6320 - MSE: 90.6320 - val_loss: 167.9751 - val_MSE: 167.9751\n",
      "\n",
      "Epoch 01309: val_loss did not improve from 91.61790\n",
      "Epoch 1310/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 96.7568 - MSE: 96.7568 - val_loss: 163.7869 - val_MSE: 163.7869\n",
      "\n",
      "Epoch 01310: val_loss did not improve from 91.61790\n",
      "Epoch 1311/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 60.3878 - MSE: 60.3878 - val_loss: 189.8359 - val_MSE: 189.8359\n",
      "\n",
      "Epoch 01311: val_loss did not improve from 91.61790\n",
      "Epoch 1312/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 86.9814 - MSE: 86.9814 - val_loss: 196.3609 - val_MSE: 196.3609\n",
      "\n",
      "Epoch 01312: val_loss did not improve from 91.61790\n",
      "Epoch 1313/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 89.9270 - MSE: 89.9270 - val_loss: 156.4659 - val_MSE: 156.4659\n",
      "\n",
      "Epoch 01313: val_loss did not improve from 91.61790\n",
      "Epoch 1314/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 112.4013 - MSE: 112.4013 - val_loss: 188.4021 - val_MSE: 188.4021\n",
      "\n",
      "Epoch 01314: val_loss did not improve from 91.61790\n",
      "Epoch 1315/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 75.2499 - MSE: 75.2499 - val_loss: 158.3222 - val_MSE: 158.3222\n",
      "\n",
      "Epoch 01315: val_loss did not improve from 91.61790\n",
      "Epoch 1316/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 61.3108 - MSE: 61.3108 - val_loss: 223.9042 - val_MSE: 223.9042\n",
      "\n",
      "Epoch 01316: val_loss did not improve from 91.61790\n",
      "Epoch 1317/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 77.2321 - MSE: 77.2321 - val_loss: 145.3484 - val_MSE: 145.3484\n",
      "\n",
      "Epoch 01317: val_loss did not improve from 91.61790\n",
      "Epoch 1318/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 79.5231 - MSE: 79.5231 - val_loss: 167.3391 - val_MSE: 167.3391\n",
      "\n",
      "Epoch 01318: val_loss did not improve from 91.61790\n",
      "Epoch 1319/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 64.8489 - MSE: 64.8489 - val_loss: 172.5985 - val_MSE: 172.5985\n",
      "\n",
      "Epoch 01319: val_loss did not improve from 91.61790\n",
      "Epoch 1320/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 65.5027 - MSE: 65.5027 - val_loss: 131.5765 - val_MSE: 131.5765\n",
      "\n",
      "Epoch 01320: val_loss did not improve from 91.61790\n",
      "Epoch 1321/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 107.3482 - MSE: 107.3482 - val_loss: 157.5498 - val_MSE: 157.5498\n",
      "\n",
      "Epoch 01321: val_loss did not improve from 91.61790\n",
      "Epoch 1322/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 55.5620 - MSE: 55.5620 - val_loss: 134.6175 - val_MSE: 134.6175\n",
      "\n",
      "Epoch 01322: val_loss did not improve from 91.61790\n",
      "Epoch 1323/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 73.4717 - MSE: 73.4717 - val_loss: 159.7141 - val_MSE: 159.7141\n",
      "\n",
      "Epoch 01323: val_loss did not improve from 91.61790\n",
      "Epoch 1324/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 65.3059 - MSE: 65.3059 - val_loss: 174.9014 - val_MSE: 174.9014\n",
      "\n",
      "Epoch 01324: val_loss did not improve from 91.61790\n",
      "Epoch 1325/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 79.5066 - MSE: 79.5066 - val_loss: 202.8111 - val_MSE: 202.8111\n",
      "\n",
      "Epoch 01325: val_loss did not improve from 91.61790\n",
      "Epoch 1326/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 118.6797 - MSE: 118.6797 - val_loss: 151.8858 - val_MSE: 151.8858\n",
      "\n",
      "Epoch 01326: val_loss did not improve from 91.61790\n",
      "Epoch 1327/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 73.7043 - MSE: 73.7043 - val_loss: 192.3798 - val_MSE: 192.3798\n",
      "\n",
      "Epoch 01327: val_loss did not improve from 91.61790\n",
      "Epoch 1328/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 93.3569 - MSE: 93.3569 - val_loss: 151.1884 - val_MSE: 151.1884\n",
      "\n",
      "Epoch 01328: val_loss did not improve from 91.61790\n",
      "Epoch 1329/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 58.4653 - MSE: 58.4653 - val_loss: 157.7490 - val_MSE: 157.7490\n",
      "\n",
      "Epoch 01329: val_loss did not improve from 91.61790\n",
      "Epoch 1330/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 70.3491 - MSE: 70.3491 - val_loss: 216.2753 - val_MSE: 216.2753\n",
      "\n",
      "Epoch 01330: val_loss did not improve from 91.61790\n",
      "Epoch 1331/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 81.2772 - MSE: 81.2772 - val_loss: 171.9694 - val_MSE: 171.9694\n",
      "\n",
      "Epoch 01331: val_loss did not improve from 91.61790\n",
      "Epoch 1332/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 62.9173 - MSE: 62.9173 - val_loss: 161.2123 - val_MSE: 161.2123\n",
      "\n",
      "Epoch 01332: val_loss did not improve from 91.61790\n",
      "Epoch 1333/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 66.2516 - MSE: 66.2516 - val_loss: 185.6702 - val_MSE: 185.6702\n",
      "\n",
      "Epoch 01333: val_loss did not improve from 91.61790\n",
      "Epoch 1334/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 80.8549 - MSE: 80.8549 - val_loss: 134.0043 - val_MSE: 134.0043\n",
      "\n",
      "Epoch 01334: val_loss did not improve from 91.61790\n",
      "Epoch 1335/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 67.4245 - MSE: 67.4245 - val_loss: 145.0732 - val_MSE: 145.0732\n",
      "\n",
      "Epoch 01335: val_loss did not improve from 91.61790\n",
      "Epoch 1336/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 54.8178 - MSE: 54.8178 - val_loss: 165.7887 - val_MSE: 165.7887\n",
      "\n",
      "Epoch 01336: val_loss did not improve from 91.61790\n",
      "Epoch 1337/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 58.8150 - MSE: 58.8150 - val_loss: 158.9959 - val_MSE: 158.9959\n",
      "\n",
      "Epoch 01337: val_loss did not improve from 91.61790\n",
      "Epoch 1338/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 72.7610 - MSE: 72.7610 - val_loss: 186.1691 - val_MSE: 186.1691\n",
      "\n",
      "Epoch 01338: val_loss did not improve from 91.61790\n",
      "Epoch 1339/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 39.1318 - MSE: 39.1318 - val_loss: 176.4539 - val_MSE: 176.4539\n",
      "\n",
      "Epoch 01339: val_loss did not improve from 91.61790\n",
      "Epoch 1340/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 51.2211 - MSE: 51.2211 - val_loss: 180.7676 - val_MSE: 180.7676\n",
      "\n",
      "Epoch 01340: val_loss did not improve from 91.61790\n",
      "Epoch 1341/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 71.4466 - MSE: 71.4466 - val_loss: 177.8902 - val_MSE: 177.8902\n",
      "\n",
      "Epoch 01341: val_loss did not improve from 91.61790\n",
      "Epoch 1342/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 73.1522 - MSE: 73.1522 - val_loss: 185.9018 - val_MSE: 185.9018\n",
      "\n",
      "Epoch 01342: val_loss did not improve from 91.61790\n",
      "Epoch 1343/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 65.1916 - MSE: 65.1916 - val_loss: 178.0438 - val_MSE: 178.0438\n",
      "\n",
      "Epoch 01343: val_loss did not improve from 91.61790\n",
      "Epoch 1344/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 92.0450 - MSE: 92.0450 - val_loss: 145.8929 - val_MSE: 145.8929\n",
      "\n",
      "Epoch 01344: val_loss did not improve from 91.61790\n",
      "Epoch 1345/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 77.1924 - MSE: 77.1924 - val_loss: 140.2620 - val_MSE: 140.2620\n",
      "\n",
      "Epoch 01345: val_loss did not improve from 91.61790\n",
      "Epoch 1346/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 70.4726 - MSE: 70.4726 - val_loss: 171.3230 - val_MSE: 171.3230\n",
      "\n",
      "Epoch 01346: val_loss did not improve from 91.61790\n",
      "Epoch 1347/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 105.0633 - MSE: 105.0633 - val_loss: 175.5209 - val_MSE: 175.5209\n",
      "\n",
      "Epoch 01347: val_loss did not improve from 91.61790\n",
      "Epoch 1348/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 9ms/step - loss: 62.8353 - MSE: 62.8353 - val_loss: 178.7778 - val_MSE: 178.7778\n",
      "\n",
      "Epoch 01348: val_loss did not improve from 91.61790\n",
      "Epoch 1349/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 64.7544 - MSE: 64.7544 - val_loss: 181.2210 - val_MSE: 181.2210\n",
      "\n",
      "Epoch 01349: val_loss did not improve from 91.61790\n",
      "Epoch 1350/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 48.8835 - MSE: 48.8835 - val_loss: 159.1306 - val_MSE: 159.1306\n",
      "\n",
      "Epoch 01350: val_loss did not improve from 91.61790\n",
      "Epoch 1351/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 59.1912 - MSE: 59.1912 - val_loss: 166.3796 - val_MSE: 166.3796\n",
      "\n",
      "Epoch 01351: val_loss did not improve from 91.61790\n",
      "Epoch 1352/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 53.1827 - MSE: 53.1827 - val_loss: 175.6657 - val_MSE: 175.6657\n",
      "\n",
      "Epoch 01352: val_loss did not improve from 91.61790\n",
      "Epoch 1353/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 119.8844 - MSE: 119.8844 - val_loss: 135.9355 - val_MSE: 135.9355\n",
      "\n",
      "Epoch 01353: val_loss did not improve from 91.61790\n",
      "Epoch 1354/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 62.9810 - MSE: 62.9810 - val_loss: 164.9641 - val_MSE: 164.9641\n",
      "\n",
      "Epoch 01354: val_loss did not improve from 91.61790\n",
      "Epoch 1355/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 88.9679 - MSE: 88.9679 - val_loss: 155.5085 - val_MSE: 155.5085\n",
      "\n",
      "Epoch 01355: val_loss did not improve from 91.61790\n",
      "Epoch 1356/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 59.1059 - MSE: 59.1059 - val_loss: 197.5476 - val_MSE: 197.5476\n",
      "\n",
      "Epoch 01356: val_loss did not improve from 91.61790\n",
      "Epoch 1357/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 72.6507 - MSE: 72.6507 - val_loss: 144.6551 - val_MSE: 144.6551\n",
      "\n",
      "Epoch 01357: val_loss did not improve from 91.61790\n",
      "Epoch 1358/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 61.4080 - MSE: 61.4080 - val_loss: 205.4308 - val_MSE: 205.4308\n",
      "\n",
      "Epoch 01358: val_loss did not improve from 91.61790\n",
      "Epoch 1359/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 82.8501 - MSE: 82.8501 - val_loss: 191.2236 - val_MSE: 191.2236\n",
      "\n",
      "Epoch 01359: val_loss did not improve from 91.61790\n",
      "Epoch 1360/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 59.7538 - MSE: 59.7538 - val_loss: 159.2607 - val_MSE: 159.2607\n",
      "\n",
      "Epoch 01360: val_loss did not improve from 91.61790\n",
      "Epoch 1361/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 48.7682 - MSE: 48.7682 - val_loss: 166.6933 - val_MSE: 166.6933\n",
      "\n",
      "Epoch 01361: val_loss did not improve from 91.61790\n",
      "Epoch 1362/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 56.7572 - MSE: 56.7572 - val_loss: 187.1798 - val_MSE: 187.1798\n",
      "\n",
      "Epoch 01362: val_loss did not improve from 91.61790\n",
      "Epoch 1363/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 58.1145 - MSE: 58.1145 - val_loss: 227.3737 - val_MSE: 227.3737\n",
      "\n",
      "Epoch 01363: val_loss did not improve from 91.61790\n",
      "Epoch 1364/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 87.7203 - MSE: 87.7203 - val_loss: 165.2019 - val_MSE: 165.2019\n",
      "\n",
      "Epoch 01364: val_loss did not improve from 91.61790\n",
      "Epoch 1365/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 66.4407 - MSE: 66.4407 - val_loss: 176.4104 - val_MSE: 176.4104\n",
      "\n",
      "Epoch 01365: val_loss did not improve from 91.61790\n",
      "Epoch 1366/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 79.9471 - MSE: 79.9471 - val_loss: 166.0876 - val_MSE: 166.0876\n",
      "\n",
      "Epoch 01366: val_loss did not improve from 91.61790\n",
      "Epoch 1367/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 63.3500 - MSE: 63.3500 - val_loss: 173.0451 - val_MSE: 173.0451\n",
      "\n",
      "Epoch 01367: val_loss did not improve from 91.61790\n",
      "Epoch 1368/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 47.4536 - MSE: 47.4536 - val_loss: 183.8038 - val_MSE: 183.8038\n",
      "\n",
      "Epoch 01368: val_loss did not improve from 91.61790\n",
      "Epoch 1369/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 55.0738 - MSE: 55.0738 - val_loss: 147.7986 - val_MSE: 147.7986\n",
      "\n",
      "Epoch 01369: val_loss did not improve from 91.61790\n",
      "Epoch 1370/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 80.7106 - MSE: 80.7106 - val_loss: 215.6218 - val_MSE: 215.6218\n",
      "\n",
      "Epoch 01370: val_loss did not improve from 91.61790\n",
      "Epoch 1371/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 63.0586 - MSE: 63.0586 - val_loss: 178.8018 - val_MSE: 178.8018\n",
      "\n",
      "Epoch 01371: val_loss did not improve from 91.61790\n",
      "Epoch 1372/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 54.2630 - MSE: 54.2630 - val_loss: 163.8583 - val_MSE: 163.8583\n",
      "\n",
      "Epoch 01372: val_loss did not improve from 91.61790\n",
      "Epoch 1373/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 101.9137 - MSE: 101.9137 - val_loss: 152.6808 - val_MSE: 152.6808\n",
      "\n",
      "Epoch 01373: val_loss did not improve from 91.61790\n",
      "Epoch 1374/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 58.2996 - MSE: 58.2996 - val_loss: 155.2515 - val_MSE: 155.2515\n",
      "\n",
      "Epoch 01374: val_loss did not improve from 91.61790\n",
      "Epoch 1375/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 68.8210 - MSE: 68.8210 - val_loss: 167.4893 - val_MSE: 167.4893\n",
      "\n",
      "Epoch 01375: val_loss did not improve from 91.61790\n",
      "Epoch 1376/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 47.4645 - MSE: 47.4645 - val_loss: 180.7524 - val_MSE: 180.7524\n",
      "\n",
      "Epoch 01376: val_loss did not improve from 91.61790\n",
      "Epoch 1377/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 74.3393 - MSE: 74.3393 - val_loss: 148.3488 - val_MSE: 148.3488\n",
      "\n",
      "Epoch 01377: val_loss did not improve from 91.61790\n",
      "Epoch 1378/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 51.1083 - MSE: 51.1083 - val_loss: 196.0596 - val_MSE: 196.0596\n",
      "\n",
      "Epoch 01378: val_loss did not improve from 91.61790\n",
      "Epoch 1379/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 64.7565 - MSE: 64.7565 - val_loss: 155.6396 - val_MSE: 155.6396\n",
      "\n",
      "Epoch 01379: val_loss did not improve from 91.61790\n",
      "Epoch 1380/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 61.2410 - MSE: 61.2410 - val_loss: 175.8574 - val_MSE: 175.8574\n",
      "\n",
      "Epoch 01380: val_loss did not improve from 91.61790\n",
      "Epoch 1381/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 60.6901 - MSE: 60.6901 - val_loss: 137.7010 - val_MSE: 137.7010\n",
      "\n",
      "Epoch 01381: val_loss did not improve from 91.61790\n",
      "Epoch 1382/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 57.5754 - MSE: 57.5754 - val_loss: 152.7622 - val_MSE: 152.7622\n",
      "\n",
      "Epoch 01382: val_loss did not improve from 91.61790\n",
      "Epoch 1383/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 75.7457 - MSE: 75.7457 - val_loss: 208.3457 - val_MSE: 208.3457\n",
      "\n",
      "Epoch 01383: val_loss did not improve from 91.61790\n",
      "Epoch 1384/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 144.7787 - MSE: 144.7787 - val_loss: 138.9315 - val_MSE: 138.9315\n",
      "\n",
      "Epoch 01384: val_loss did not improve from 91.61790\n",
      "Epoch 1385/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 74.0886 - MSE: 74.0886 - val_loss: 165.1067 - val_MSE: 165.1067\n",
      "\n",
      "Epoch 01385: val_loss did not improve from 91.61790\n",
      "Epoch 1386/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 72.2325 - MSE: 72.2325 - val_loss: 144.7063 - val_MSE: 144.7063\n",
      "\n",
      "Epoch 01386: val_loss did not improve from 91.61790\n",
      "Epoch 1387/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 39.6718 - MSE: 39.6718 - val_loss: 242.5211 - val_MSE: 242.5211\n",
      "\n",
      "Epoch 01387: val_loss did not improve from 91.61790\n",
      "Epoch 1388/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 86.3561 - MSE: 86.3561 - val_loss: 134.6576 - val_MSE: 134.6576\n",
      "\n",
      "Epoch 01388: val_loss did not improve from 91.61790\n",
      "Epoch 1389/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 48.7476 - MSE: 48.7476 - val_loss: 146.7181 - val_MSE: 146.7181\n",
      "\n",
      "Epoch 01389: val_loss did not improve from 91.61790\n",
      "Epoch 1390/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 8ms/step - loss: 64.0422 - MSE: 64.0422 - val_loss: 160.6931 - val_MSE: 160.6931\n",
      "\n",
      "Epoch 01390: val_loss did not improve from 91.61790\n",
      "Epoch 1391/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 35.4137 - MSE: 35.4137 - val_loss: 150.7921 - val_MSE: 150.7921\n",
      "\n",
      "Epoch 01391: val_loss did not improve from 91.61790\n",
      "Epoch 1392/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 67.3190 - MSE: 67.3190 - val_loss: 163.2545 - val_MSE: 163.2545\n",
      "\n",
      "Epoch 01392: val_loss did not improve from 91.61790\n",
      "Epoch 1393/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 57.7041 - MSE: 57.7041 - val_loss: 210.5717 - val_MSE: 210.5717\n",
      "\n",
      "Epoch 01393: val_loss did not improve from 91.61790\n",
      "Epoch 1394/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 56.2893 - MSE: 56.2893 - val_loss: 190.8042 - val_MSE: 190.8042\n",
      "\n",
      "Epoch 01394: val_loss did not improve from 91.61790\n",
      "Epoch 1395/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 62.2522 - MSE: 62.2522 - val_loss: 160.5697 - val_MSE: 160.5697\n",
      "\n",
      "Epoch 01395: val_loss did not improve from 91.61790\n",
      "Epoch 1396/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 47.0309 - MSE: 47.0309 - val_loss: 164.3605 - val_MSE: 164.3605\n",
      "\n",
      "Epoch 01396: val_loss did not improve from 91.61790\n",
      "Epoch 1397/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 122.4793 - MSE: 122.4793 - val_loss: 180.5199 - val_MSE: 180.5199\n",
      "\n",
      "Epoch 01397: val_loss did not improve from 91.61790\n",
      "Epoch 1398/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 77.2915 - MSE: 77.2915 - val_loss: 174.2786 - val_MSE: 174.2786\n",
      "\n",
      "Epoch 01398: val_loss did not improve from 91.61790\n",
      "Epoch 1399/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 86.9759 - MSE: 86.9759 - val_loss: 138.7472 - val_MSE: 138.7472\n",
      "\n",
      "Epoch 01399: val_loss did not improve from 91.61790\n",
      "Epoch 1400/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 68.5085 - MSE: 68.5085 - val_loss: 165.6190 - val_MSE: 165.6190\n",
      "\n",
      "Epoch 01400: val_loss did not improve from 91.61790\n",
      "Epoch 1401/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 54.5531 - MSE: 54.5531 - val_loss: 154.4017 - val_MSE: 154.4017\n",
      "\n",
      "Epoch 01401: val_loss did not improve from 91.61790\n",
      "Epoch 1402/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 51.3742 - MSE: 51.3742 - val_loss: 168.9834 - val_MSE: 168.9834\n",
      "\n",
      "Epoch 01402: val_loss did not improve from 91.61790\n",
      "Epoch 1403/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 78.9701 - MSE: 78.9701 - val_loss: 142.6854 - val_MSE: 142.6854\n",
      "\n",
      "Epoch 01403: val_loss did not improve from 91.61790\n",
      "Epoch 1404/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 62.2270 - MSE: 62.2270 - val_loss: 156.5126 - val_MSE: 156.5126\n",
      "\n",
      "Epoch 01404: val_loss did not improve from 91.61790\n",
      "Epoch 1405/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 42.9592 - MSE: 42.9592 - val_loss: 165.9575 - val_MSE: 165.9575\n",
      "\n",
      "Epoch 01405: val_loss did not improve from 91.61790\n",
      "Epoch 1406/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 64.9965 - MSE: 64.9965 - val_loss: 179.6651 - val_MSE: 179.6651\n",
      "\n",
      "Epoch 01406: val_loss did not improve from 91.61790\n",
      "Epoch 1407/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 63.6676 - MSE: 63.6676 - val_loss: 148.5621 - val_MSE: 148.5621\n",
      "\n",
      "Epoch 01407: val_loss did not improve from 91.61790\n",
      "Epoch 1408/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 51.5065 - MSE: 51.5065 - val_loss: 189.2220 - val_MSE: 189.2220\n",
      "\n",
      "Epoch 01408: val_loss did not improve from 91.61790\n",
      "Epoch 1409/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 74.8096 - MSE: 74.8096 - val_loss: 194.6481 - val_MSE: 194.6481\n",
      "\n",
      "Epoch 01409: val_loss did not improve from 91.61790\n",
      "Epoch 1410/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 64.9041 - MSE: 64.9041 - val_loss: 218.8830 - val_MSE: 218.8830\n",
      "\n",
      "Epoch 01410: val_loss did not improve from 91.61790\n",
      "Epoch 1411/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 51.6323 - MSE: 51.6323 - val_loss: 193.0251 - val_MSE: 193.0251\n",
      "\n",
      "Epoch 01411: val_loss did not improve from 91.61790\n",
      "Epoch 1412/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 70.5004 - MSE: 70.5004 - val_loss: 130.0579 - val_MSE: 130.0579\n",
      "\n",
      "Epoch 01412: val_loss did not improve from 91.61790\n",
      "Epoch 1413/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 87.0806 - MSE: 87.0806 - val_loss: 169.4662 - val_MSE: 169.4662\n",
      "\n",
      "Epoch 01413: val_loss did not improve from 91.61790\n",
      "Epoch 1414/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 102.1925 - MSE: 102.1925 - val_loss: 172.1025 - val_MSE: 172.1025\n",
      "\n",
      "Epoch 01414: val_loss did not improve from 91.61790\n",
      "Epoch 1415/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 79.7824 - MSE: 79.7824 - val_loss: 239.8278 - val_MSE: 239.8278\n",
      "\n",
      "Epoch 01415: val_loss did not improve from 91.61790\n",
      "Epoch 1416/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 75.7824 - MSE: 75.7824 - val_loss: 213.4200 - val_MSE: 213.4200\n",
      "\n",
      "Epoch 01416: val_loss did not improve from 91.61790\n",
      "Epoch 1417/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 66.3763 - MSE: 66.3763 - val_loss: 147.6743 - val_MSE: 147.6743\n",
      "\n",
      "Epoch 01417: val_loss did not improve from 91.61790\n",
      "Epoch 1418/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 51.7590 - MSE: 51.7590 - val_loss: 168.8082 - val_MSE: 168.8082\n",
      "\n",
      "Epoch 01418: val_loss did not improve from 91.61790\n",
      "Epoch 1419/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 57.6842 - MSE: 57.6842 - val_loss: 183.2681 - val_MSE: 183.2681\n",
      "\n",
      "Epoch 01419: val_loss did not improve from 91.61790\n",
      "Epoch 1420/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 61.9715 - MSE: 61.9715 - val_loss: 138.7979 - val_MSE: 138.7979\n",
      "\n",
      "Epoch 01420: val_loss did not improve from 91.61790\n",
      "Epoch 1421/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 72.2905 - MSE: 72.2905 - val_loss: 126.2445 - val_MSE: 126.2445\n",
      "\n",
      "Epoch 01421: val_loss did not improve from 91.61790\n",
      "Epoch 1422/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 54.6229 - MSE: 54.6229 - val_loss: 132.1381 - val_MSE: 132.1381\n",
      "\n",
      "Epoch 01422: val_loss did not improve from 91.61790\n",
      "Epoch 1423/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 48.2049 - MSE: 48.2049 - val_loss: 182.5609 - val_MSE: 182.5609\n",
      "\n",
      "Epoch 01423: val_loss did not improve from 91.61790\n",
      "Epoch 1424/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 94.8285 - MSE: 94.8285 - val_loss: 190.4889 - val_MSE: 190.4889\n",
      "\n",
      "Epoch 01424: val_loss did not improve from 91.61790\n",
      "Epoch 1425/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 88.4308 - MSE: 88.4308 - val_loss: 147.8250 - val_MSE: 147.8250\n",
      "\n",
      "Epoch 01425: val_loss did not improve from 91.61790\n",
      "Epoch 1426/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 66.9315 - MSE: 66.9315 - val_loss: 191.2814 - val_MSE: 191.2814\n",
      "\n",
      "Epoch 01426: val_loss did not improve from 91.61790\n",
      "Epoch 1427/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 67.3555 - MSE: 67.3555 - val_loss: 190.2091 - val_MSE: 190.2091\n",
      "\n",
      "Epoch 01427: val_loss did not improve from 91.61790\n",
      "Epoch 1428/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 52.6910 - MSE: 52.6910 - val_loss: 125.9897 - val_MSE: 125.9897\n",
      "\n",
      "Epoch 01428: val_loss did not improve from 91.61790\n",
      "Epoch 1429/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 66.4489 - MSE: 66.4489 - val_loss: 197.5469 - val_MSE: 197.5469\n",
      "\n",
      "Epoch 01429: val_loss did not improve from 91.61790\n",
      "Epoch 1430/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 54.2227 - MSE: 54.2227 - val_loss: 211.1094 - val_MSE: 211.1094\n",
      "\n",
      "Epoch 01430: val_loss did not improve from 91.61790\n",
      "Epoch 1431/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 45.4384 - MSE: 45.4384 - val_loss: 320.9992 - val_MSE: 320.9992\n",
      "\n",
      "Epoch 01431: val_loss did not improve from 91.61790\n",
      "Epoch 1432/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 7ms/step - loss: 118.1139 - MSE: 118.1139 - val_loss: 182.0285 - val_MSE: 182.0285\n",
      "\n",
      "Epoch 01432: val_loss did not improve from 91.61790\n",
      "Epoch 1433/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 64.3311 - MSE: 64.3311 - val_loss: 167.8849 - val_MSE: 167.8849\n",
      "\n",
      "Epoch 01433: val_loss did not improve from 91.61790\n",
      "Epoch 1434/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 77.5659 - MSE: 77.5659 - val_loss: 181.3445 - val_MSE: 181.3445\n",
      "\n",
      "Epoch 01434: val_loss did not improve from 91.61790\n",
      "Epoch 1435/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 51.1660 - MSE: 51.1660 - val_loss: 206.0607 - val_MSE: 206.0607\n",
      "\n",
      "Epoch 01435: val_loss did not improve from 91.61790\n",
      "Epoch 1436/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 77.2554 - MSE: 77.2554 - val_loss: 160.4703 - val_MSE: 160.4703\n",
      "\n",
      "Epoch 01436: val_loss did not improve from 91.61790\n",
      "Epoch 1437/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 83.2713 - MSE: 83.2713 - val_loss: 195.7728 - val_MSE: 195.7728\n",
      "\n",
      "Epoch 01437: val_loss did not improve from 91.61790\n",
      "Epoch 1438/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 49.7691 - MSE: 49.7691 - val_loss: 159.0054 - val_MSE: 159.0054\n",
      "\n",
      "Epoch 01438: val_loss did not improve from 91.61790\n",
      "Epoch 1439/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 56.1846 - MSE: 56.1846 - val_loss: 145.0180 - val_MSE: 145.0180\n",
      "\n",
      "Epoch 01439: val_loss did not improve from 91.61790\n",
      "Epoch 1440/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 84.8338 - MSE: 84.8338 - val_loss: 177.0334 - val_MSE: 177.0334\n",
      "\n",
      "Epoch 01440: val_loss did not improve from 91.61790\n",
      "Epoch 1441/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 103.6510 - MSE: 103.6510 - val_loss: 202.9297 - val_MSE: 202.9297\n",
      "\n",
      "Epoch 01441: val_loss did not improve from 91.61790\n",
      "Epoch 1442/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 54.3351 - MSE: 54.3351 - val_loss: 160.0505 - val_MSE: 160.0505\n",
      "\n",
      "Epoch 01442: val_loss did not improve from 91.61790\n",
      "Epoch 1443/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 71.2447 - MSE: 71.2447 - val_loss: 167.7291 - val_MSE: 167.7291\n",
      "\n",
      "Epoch 01443: val_loss did not improve from 91.61790\n",
      "Epoch 1444/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 87.6013 - MSE: 87.6013 - val_loss: 181.1338 - val_MSE: 181.1338\n",
      "\n",
      "Epoch 01444: val_loss did not improve from 91.61790\n",
      "Epoch 1445/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 72.6825 - MSE: 72.6825 - val_loss: 170.4175 - val_MSE: 170.4175\n",
      "\n",
      "Epoch 01445: val_loss did not improve from 91.61790\n",
      "Epoch 1446/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 99.3799 - MSE: 99.3799 - val_loss: 165.8003 - val_MSE: 165.8003\n",
      "\n",
      "Epoch 01446: val_loss did not improve from 91.61790\n",
      "Epoch 1447/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 64.1591 - MSE: 64.1591 - val_loss: 162.0076 - val_MSE: 162.0076\n",
      "\n",
      "Epoch 01447: val_loss did not improve from 91.61790\n",
      "Epoch 1448/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 119.6803 - MSE: 119.6803 - val_loss: 160.0475 - val_MSE: 160.0475\n",
      "\n",
      "Epoch 01448: val_loss did not improve from 91.61790\n",
      "Epoch 1449/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 48.2359 - MSE: 48.2359 - val_loss: 205.2536 - val_MSE: 205.2536\n",
      "\n",
      "Epoch 01449: val_loss did not improve from 91.61790\n",
      "Epoch 1450/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 77.2671 - MSE: 77.2671 - val_loss: 189.5012 - val_MSE: 189.5012\n",
      "\n",
      "Epoch 01450: val_loss did not improve from 91.61790\n",
      "Epoch 1451/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 81.6056 - MSE: 81.6056 - val_loss: 182.2403 - val_MSE: 182.2403\n",
      "\n",
      "Epoch 01451: val_loss did not improve from 91.61790\n",
      "Epoch 1452/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 84.2511 - MSE: 84.2511 - val_loss: 168.8871 - val_MSE: 168.8871\n",
      "\n",
      "Epoch 01452: val_loss did not improve from 91.61790\n",
      "Epoch 1453/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 64.8722 - MSE: 64.8722 - val_loss: 183.1385 - val_MSE: 183.1385\n",
      "\n",
      "Epoch 01453: val_loss did not improve from 91.61790\n",
      "Epoch 1454/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 50.3429 - MSE: 50.3429 - val_loss: 165.4715 - val_MSE: 165.4715\n",
      "\n",
      "Epoch 01454: val_loss did not improve from 91.61790\n",
      "Epoch 1455/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 69.3680 - MSE: 69.3680 - val_loss: 166.1176 - val_MSE: 166.1176\n",
      "\n",
      "Epoch 01455: val_loss did not improve from 91.61790\n",
      "Epoch 1456/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 64.1480 - MSE: 64.1480 - val_loss: 150.6961 - val_MSE: 150.6961\n",
      "\n",
      "Epoch 01456: val_loss did not improve from 91.61790\n",
      "Epoch 1457/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 53.7625 - MSE: 53.7625 - val_loss: 196.5575 - val_MSE: 196.5575\n",
      "\n",
      "Epoch 01457: val_loss did not improve from 91.61790\n",
      "Epoch 1458/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 61.6446 - MSE: 61.6446 - val_loss: 168.7711 - val_MSE: 168.7711\n",
      "\n",
      "Epoch 01458: val_loss did not improve from 91.61790\n",
      "Epoch 1459/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 72.4919 - MSE: 72.4919 - val_loss: 176.3585 - val_MSE: 176.3585\n",
      "\n",
      "Epoch 01459: val_loss did not improve from 91.61790\n",
      "Epoch 1460/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 76.5011 - MSE: 76.5011 - val_loss: 174.9356 - val_MSE: 174.9356\n",
      "\n",
      "Epoch 01460: val_loss did not improve from 91.61790\n",
      "Epoch 1461/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 53.6666 - MSE: 53.6666 - val_loss: 234.3269 - val_MSE: 234.3269\n",
      "\n",
      "Epoch 01461: val_loss did not improve from 91.61790\n",
      "Epoch 1462/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 109.3420 - MSE: 109.3420 - val_loss: 259.2706 - val_MSE: 259.2706\n",
      "\n",
      "Epoch 01462: val_loss did not improve from 91.61790\n",
      "Epoch 1463/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 102.3406 - MSE: 102.3406 - val_loss: 159.3407 - val_MSE: 159.3407\n",
      "\n",
      "Epoch 01463: val_loss did not improve from 91.61790\n",
      "Epoch 1464/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 77.3870 - MSE: 77.3870 - val_loss: 146.9250 - val_MSE: 146.9250\n",
      "\n",
      "Epoch 01464: val_loss did not improve from 91.61790\n",
      "Epoch 1465/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 469.3032 - MSE: 469.3032 - val_loss: 195.7054 - val_MSE: 195.7054\n",
      "\n",
      "Epoch 01465: val_loss did not improve from 91.61790\n",
      "Epoch 1466/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 122.9771 - MSE: 122.9771 - val_loss: 170.0866 - val_MSE: 170.0866\n",
      "\n",
      "Epoch 01466: val_loss did not improve from 91.61790\n",
      "Epoch 1467/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 62.4406 - MSE: 62.4406 - val_loss: 185.9387 - val_MSE: 185.9387\n",
      "\n",
      "Epoch 01467: val_loss did not improve from 91.61790\n",
      "Epoch 1468/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 57.5852 - MSE: 57.5852 - val_loss: 176.7613 - val_MSE: 176.7613\n",
      "\n",
      "Epoch 01468: val_loss did not improve from 91.61790\n",
      "Epoch 1469/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 202.7107 - MSE: 202.7107 - val_loss: 146.4769 - val_MSE: 146.4769\n",
      "\n",
      "Epoch 01469: val_loss did not improve from 91.61790\n",
      "Epoch 1470/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 51.1771 - MSE: 51.1771 - val_loss: 156.4077 - val_MSE: 156.4077\n",
      "\n",
      "Epoch 01470: val_loss did not improve from 91.61790\n",
      "Epoch 1471/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 60.7748 - MSE: 60.7748 - val_loss: 167.8637 - val_MSE: 167.8637\n",
      "\n",
      "Epoch 01471: val_loss did not improve from 91.61790\n",
      "Epoch 1472/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 103.0050 - MSE: 103.0050 - val_loss: 177.1011 - val_MSE: 177.1011\n",
      "\n",
      "Epoch 01472: val_loss did not improve from 91.61790\n",
      "Epoch 1473/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 91.3074 - MSE: 91.3074 - val_loss: 161.2332 - val_MSE: 161.2332\n",
      "\n",
      "Epoch 01473: val_loss did not improve from 91.61790\n",
      "Epoch 1474/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 8ms/step - loss: 53.0119 - MSE: 53.0119 - val_loss: 158.8151 - val_MSE: 158.8151\n",
      "\n",
      "Epoch 01474: val_loss did not improve from 91.61790\n",
      "Epoch 1475/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 49.5339 - MSE: 49.5339 - val_loss: 151.4277 - val_MSE: 151.4277\n",
      "\n",
      "Epoch 01475: val_loss did not improve from 91.61790\n",
      "Epoch 1476/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 51.4687 - MSE: 51.4687 - val_loss: 167.8572 - val_MSE: 167.8572\n",
      "\n",
      "Epoch 01476: val_loss did not improve from 91.61790\n",
      "Epoch 1477/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 73.4298 - MSE: 73.4298 - val_loss: 140.2355 - val_MSE: 140.2355\n",
      "\n",
      "Epoch 01477: val_loss did not improve from 91.61790\n",
      "Epoch 1478/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 39.5808 - MSE: 39.5808 - val_loss: 142.8461 - val_MSE: 142.8461\n",
      "\n",
      "Epoch 01478: val_loss did not improve from 91.61790\n",
      "Epoch 1479/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 73.4979 - MSE: 73.4979 - val_loss: 158.1890 - val_MSE: 158.1890\n",
      "\n",
      "Epoch 01479: val_loss did not improve from 91.61790\n",
      "Epoch 1480/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 64.9994 - MSE: 64.9994 - val_loss: 180.3524 - val_MSE: 180.3524\n",
      "\n",
      "Epoch 01480: val_loss did not improve from 91.61790\n",
      "Epoch 1481/1500\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 56.6530 - MSE: 56.6530 - val_loss: 153.2311 - val_MSE: 153.2311\n",
      "\n",
      "Epoch 01481: val_loss did not improve from 91.61790\n",
      "Epoch 1482/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 59.4485 - MSE: 59.4485 - val_loss: 183.8508 - val_MSE: 183.8508\n",
      "\n",
      "Epoch 01482: val_loss did not improve from 91.61790\n",
      "Epoch 1483/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 90.1367 - MSE: 90.1367 - val_loss: 161.8423 - val_MSE: 161.8423\n",
      "\n",
      "Epoch 01483: val_loss did not improve from 91.61790\n",
      "Epoch 1484/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 54.7059 - MSE: 54.7059 - val_loss: 177.0285 - val_MSE: 177.0285\n",
      "\n",
      "Epoch 01484: val_loss did not improve from 91.61790\n",
      "Epoch 1485/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 67.3532 - MSE: 67.3532 - val_loss: 145.5327 - val_MSE: 145.5327\n",
      "\n",
      "Epoch 01485: val_loss did not improve from 91.61790\n",
      "Epoch 1486/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 78.1506 - MSE: 78.1506 - val_loss: 154.6081 - val_MSE: 154.6081\n",
      "\n",
      "Epoch 01486: val_loss did not improve from 91.61790\n",
      "Epoch 1487/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 44.7211 - MSE: 44.7211 - val_loss: 168.4255 - val_MSE: 168.4255\n",
      "\n",
      "Epoch 01487: val_loss did not improve from 91.61790\n",
      "Epoch 1488/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 125.5433 - MSE: 125.5433 - val_loss: 163.5359 - val_MSE: 163.5359\n",
      "\n",
      "Epoch 01488: val_loss did not improve from 91.61790\n",
      "Epoch 1489/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 65.2679 - MSE: 65.2679 - val_loss: 151.9283 - val_MSE: 151.9283\n",
      "\n",
      "Epoch 01489: val_loss did not improve from 91.61790\n",
      "Epoch 1490/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 88.1770 - MSE: 88.1770 - val_loss: 145.4065 - val_MSE: 145.4065\n",
      "\n",
      "Epoch 01490: val_loss did not improve from 91.61790\n",
      "Epoch 1491/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 63.3969 - MSE: 63.3969 - val_loss: 131.7278 - val_MSE: 131.7278\n",
      "\n",
      "Epoch 01491: val_loss did not improve from 91.61790\n",
      "Epoch 1492/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 27.5507 - MSE: 27.5507 - val_loss: 181.3763 - val_MSE: 181.3763\n",
      "\n",
      "Epoch 01492: val_loss did not improve from 91.61790\n",
      "Epoch 1493/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 67.2599 - MSE: 67.2599 - val_loss: 150.5232 - val_MSE: 150.5232\n",
      "\n",
      "Epoch 01493: val_loss did not improve from 91.61790\n",
      "Epoch 1494/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 38.5670 - MSE: 38.5670 - val_loss: 197.0914 - val_MSE: 197.0914\n",
      "\n",
      "Epoch 01494: val_loss did not improve from 91.61790\n",
      "Epoch 1495/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 81.1400 - MSE: 81.1400 - val_loss: 183.1357 - val_MSE: 183.1357\n",
      "\n",
      "Epoch 01495: val_loss did not improve from 91.61790\n",
      "Epoch 1496/1500\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 37.8369 - MSE: 37.8369 - val_loss: 168.4349 - val_MSE: 168.4349\n",
      "\n",
      "Epoch 01496: val_loss did not improve from 91.61790\n",
      "Epoch 1497/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 30.2738 - MSE: 30.2738 - val_loss: 161.8370 - val_MSE: 161.8370\n",
      "\n",
      "Epoch 01497: val_loss did not improve from 91.61790\n",
      "Epoch 1498/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 62.1637 - MSE: 62.1637 - val_loss: 189.1791 - val_MSE: 189.1791\n",
      "\n",
      "Epoch 01498: val_loss did not improve from 91.61790\n",
      "Epoch 1499/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 116.5622 - MSE: 116.5622 - val_loss: 156.1578 - val_MSE: 156.1578\n",
      "\n",
      "Epoch 01499: val_loss did not improve from 91.61790\n",
      "Epoch 1500/1500\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 74.3206 - MSE: 74.3206 - val_loss: 241.5997 - val_MSE: 241.5997\n",
      "\n",
      "Epoch 01500: val_loss did not improve from 91.61790\n"
     ]
    }
   ],
   "source": [
    "filepath=\"E:\\\\Study\\\\Ph.D\\\\Publication\\\\EDL\\\\ML modelling related files\"\n",
    "filename=filepath+\"3D32_2d64_relu_ALL.h5\"\n",
    "checkpointer = ModelCheckpoint( monitor='val_loss',filepath=filename, verbose=1, save_best_only=True)\n",
    "history3=model.fit(x_train,y_train, validation_data=(x_cv, y_cv), epochs=1500, batch_size=16, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "minloss=round(min(history3.history['val_loss']), 1) \n",
    "modelfilepath = filepath +  '\\\\history_loss_relu'\n",
    "df=pd.DataFrame(history3.history)\n",
    "# model.save(modelfilepath+'.h5')\n",
    "df.to_csv(modelfilepath+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer lstm_53: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-64077fbc810a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_traindim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# model.add(LSTM(64, return_sequences=True))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shivp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32mc:\\users\\shivp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shivp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shivp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m                                      str(K.ndim(x)))\n\u001b[0m\u001b[0;32m    312\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 is incompatible with layer lstm_53: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=False, input_shape=(x_traindim[1].shape)))\n",
    "# model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(3, activation='linear'))\n",
    "opt=keras.optimizers.adam(0.001)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=['MSE'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2247 samples, validate on 397 samples\n",
      "Epoch 1/10\n",
      "2247/2247 [==============================] - 22s 10ms/step - loss: 15482.2082 - mean_squared_error: 15482.2082 - val_loss: 1121.5093 - val_mean_squared_error: 1121.5093\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1121.50926, saving model to E:\\Simulations\\Silvaco\\\\2D HEMT\\EDL\\DATA for modeling\\models_history\\FOM_MSE_withGANdata_noDropoutused26july.hdf5\n",
      "Epoch 2/10\n",
      "2247/2247 [==============================] - 4s 2ms/step - loss: 1105.7519 - mean_squared_error: 1105.7519 - val_loss: 943.9846 - val_mean_squared_error: 943.9846\n",
      "\n",
      "Epoch 00002: val_loss improved from 1121.50926 to 943.98458, saving model to E:\\Simulations\\Silvaco\\\\2D HEMT\\EDL\\DATA for modeling\\models_history\\FOM_MSE_withGANdata_noDropoutused26july.hdf5\n",
      "Epoch 3/10\n",
      "2247/2247 [==============================] - 4s 2ms/step - loss: 983.5061 - mean_squared_error: 983.5061 - val_loss: 906.2233 - val_mean_squared_error: 906.2233\n",
      "\n",
      "Epoch 00003: val_loss improved from 943.98458 to 906.22333, saving model to E:\\Simulations\\Silvaco\\\\2D HEMT\\EDL\\DATA for modeling\\models_history\\FOM_MSE_withGANdata_noDropoutused26july.hdf5\n",
      "Epoch 4/10\n",
      "2247/2247 [==============================] - 4s 2ms/step - loss: 932.8457 - mean_squared_error: 932.8457 - val_loss: 851.4704 - val_mean_squared_error: 851.4704\n",
      "\n",
      "Epoch 00004: val_loss improved from 906.22333 to 851.47043, saving model to E:\\Simulations\\Silvaco\\\\2D HEMT\\EDL\\DATA for modeling\\models_history\\FOM_MSE_withGANdata_noDropoutused26july.hdf5\n",
      "Epoch 5/10\n",
      "2247/2247 [==============================] - 4s 2ms/step - loss: 896.5517 - mean_squared_error: 896.5517 - val_loss: 829.2317 - val_mean_squared_error: 829.2317\n",
      "\n",
      "Epoch 00005: val_loss improved from 851.47043 to 829.23166, saving model to E:\\Simulations\\Silvaco\\\\2D HEMT\\EDL\\DATA for modeling\\models_history\\FOM_MSE_withGANdata_noDropoutused26july.hdf5\n",
      "Epoch 6/10\n",
      "2247/2247 [==============================] - 4s 2ms/step - loss: 874.2555 - mean_squared_error: 874.2555 - val_loss: 800.2390 - val_mean_squared_error: 800.2390\n",
      "\n",
      "Epoch 00006: val_loss improved from 829.23166 to 800.23903, saving model to E:\\Simulations\\Silvaco\\\\2D HEMT\\EDL\\DATA for modeling\\models_history\\FOM_MSE_withGANdata_noDropoutused26july.hdf5\n",
      "Epoch 7/10\n",
      "2247/2247 [==============================] - 4s 2ms/step - loss: 858.4612 - mean_squared_error: 858.4612 - val_loss: 862.6957 - val_mean_squared_error: 862.6957\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 800.23903\n",
      "Epoch 8/10\n",
      "2247/2247 [==============================] - 4s 2ms/step - loss: 841.2704 - mean_squared_error: 841.2704 - val_loss: 785.6184 - val_mean_squared_error: 785.6184\n",
      "\n",
      "Epoch 00008: val_loss improved from 800.23903 to 785.61839, saving model to E:\\Simulations\\Silvaco\\\\2D HEMT\\EDL\\DATA for modeling\\models_history\\FOM_MSE_withGANdata_noDropoutused26july.hdf5\n",
      "Epoch 9/10\n",
      "2247/2247 [==============================] - 4s 2ms/step - loss: 827.9947 - mean_squared_error: 827.9947 - val_loss: 787.4700 - val_mean_squared_error: 787.4700\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 785.61839\n",
      "Epoch 10/10\n",
      "2247/2247 [==============================] - 4s 2ms/step - loss: 811.1895 - mean_squared_error: 811.1895 - val_loss: 748.4838 - val_mean_squared_error: 748.4838\n",
      "\n",
      "Epoch 00010: val_loss improved from 785.61839 to 748.48385, saving model to E:\\Simulations\\Silvaco\\\\2D HEMT\\EDL\\DATA for modeling\\models_history\\FOM_MSE_withGANdata_noDropoutused26july.hdf5\n"
     ]
    }
   ],
   "source": [
    "filepath=\"E:\\\\Simulations\\\\Silvaco\\\\\\\\2D HEMT\\\\EDL\\\\DATA for modeling\\\\models_history\\\\FOM_MSE_withGANdata_noDropoutused26july.hdf5\"\n",
    "checkpointer = ModelCheckpoint( monitor='val_loss',filepath=filepath, verbose=1, save_best_only=True)\n",
    "history3=model.fit(x_traindim,y_train, validation_data=(x_cvdim, y_cv), epochs=10, batch_size=16, callbacks=[checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpred=[]\n",
    "act=[]\n",
    "m=0\n",
    "for i in range(467):\n",
    "    r=model.predict(np.expand_dims(x_testdim[i,:], axis=0))\n",
    "#     pred.append(r[0][0])\n",
    "#     act.append(y_test[i])\n",
    "#     print((r[0]-y_test[i])/y_test[i], r[0][0], y_test[i] )\n",
    "#     print('predicted: ', y_test[i],' actual: ', r, 'diff:', (r[0]-y_test[i])/y_test[i]*100)\n",
    "\n",
    "    if (np.max((r[0]-y_test[i])/y_test[i]*100)>10):\n",
    "        print('predicted: ', y_test[i],' actual: ', r, 'diff:', (r[0]-y_test[i])/y_test[i]*100)\n",
    "        m=m+1\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748.5"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minloss=round(min(history3.history['val_loss']), 1)\n",
    "minloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_hist=pd.DataFrame(history3.history)\n",
    "df_hist.to_csv(\"E:\\\\Simulations\\\\Silvaco\\\\2D HEMT\\\\EDL\\\\DATA for modeling\\\\historyforVth.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(list(zip(pred, act)), columns=['Pred', 'Act'])\n",
    "df1.to_csv('act_pred_SS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(history3.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"E:\\\\Simulations\\\\Silvaco\\\\\\\\2D HEMT\\\\EDL\\\\DATA for modeling\\\\new_models_and_their_history\\\\L32_L32_L256_2D64_D3_46.csv\")\n",
    "model.save(\"E:\\\\Simulations\\\\Silvaco\\\\2D HEMT\\\\EDL\\\\DATA for modeling\\\\new_models_and_their_history\\\\L32_L32_L256_2D64_D3_46.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(50):\n",
    "r=model.predict(x_test[1,:])\n",
    "#     print(y_test[i])\n",
    "print('predicted: ', y_test[1],' actual: ', r )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_test)):\n",
    "    print(r[i]*1000,y_test[i]*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "adam=optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=1, activation='relu', input_shape=(x_traindim[0].shape)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=adam, metrics=['MSE'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filepath=\"E:\\\\Simulations\\\\Silvaco\\\\2D HEMT\\\\To prepare paper 2 \\\\InAlGaN-AlN-GaN HEMT\\\\Machine Leaning Data\\\\lstmmodel.hdf5\"\n",
    "checkpointer = ModelCheckpoint( monitor='val_loss',filepath=filepath, verbose=1, save_best_only=True)\n",
    "history=model.fit(x_traindim, y_traindim, validation_data=(x_testdim, y_testdim), epochs=100, batch_size=16, callbacks=[checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"E:\\\\Simulations\\\\Silvaco\\\\2D HEMT\\\\EDL\\\\DATA for modeling\\\\fom23.37mse.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result= model.evaluate(x_testdim, y_testdim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(X_test)):\n",
    "    print(r[i]*1000,y_test[i]*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as nd\n",
    "xdim=np.expand_dims((X[42:83]), axis=1)\n",
    "xdim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_id=model.predict(xdim)\n",
    "pred_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pred_id)):\n",
    "    print(pred_id[i][0]*1000, y[42:83][i]*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0:41][2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "b=[]\n",
    "c=[]\n",
    "for i in range(len(pred_id)):\n",
    "    a.append(pred_id[i][0])\n",
    "    b.append(y[42:83][i])\n",
    "    c.append(X[42:83][i][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "q={'vd':c, 'pred_id':a, 'id':b }\n",
    "df=pd.DataFrame(q)\n",
    "df.to_csv('modelfile1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_id=model.predict(x_testdim)\n",
    "pred_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pred_id)):\n",
    "    print(pred_id[i][0]*1000 - y_testdim[i][0]*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
